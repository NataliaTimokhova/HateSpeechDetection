{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e76a0e7-e90e-457e-8dc4-81cc472f2f1e",
   "metadata": {},
   "source": [
    "The goal of this project is to use the pretrained RoBERTa transformer as a feature extractor with a costum classification head to determine if text messages are offensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbb6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper_functions import AttentionPooling, HateSpeechDataset\n",
    "from helper_functions import train_model, test_model, unfreeze_last_n_layers, get_class_distribution, oversample_dataset, undersample_dataset\n",
    "from models import CustomClassifier, LargeCustomClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33448265-13a5-44f5-9ba4-0fb9cc41448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data path: /Project/data/cleaned\n",
      "Processed data path: /Project/data/processed\n"
     ]
    }
   ],
   "source": [
    "from paths import DATA_CLEANED, DATA_PROCESSED\n",
    "print(\"Cleaned data path:\", DATA_CLEANED)\n",
    "print(\"Processed data path:\", DATA_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f24224-26ee-49a1-adf0-48e3e6d38544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040a974",
   "metadata": {},
   "source": [
    "## Using RoBERTa as a feature extractor with a costum classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4da52",
   "metadata": {},
   "source": [
    "Found this pretrained model online: cardiffnlp/twitter-roberta-base-sentiment-latest (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest). It is already pretrained on twitter messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc731c7",
   "metadata": {},
   "source": [
    "Define which pretrained model is used and initilise tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base' \n",
    "#cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "#roberta-base\n",
    "#roberta-large\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb86e8",
   "metadata": {},
   "source": [
    "## Load HASOC dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181465c-ef90-409f-9cb4-39f7db6f2e93",
   "metadata": {},
   "source": [
    "Define experiment scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479a3f53-d232-42b2-8dd3-169bce3efd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using the labels of the first task of the HASOC dataset, which is a binary classification\n",
    "label = \"task_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f76fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "clean_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_train_cleaned.tsv\", sep='\\t')\n",
    "# test_df = pd.read_csv(DATA_PROCESSED / \"hasoc_2019_en_test.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_test_cleaned.tsv\", sep='\\t')\n",
    "\n",
    "# Split clean dataset in training and validation set\n",
    "train_df, val_df = train_test_split(clean_df, test_size=0.3, random_state=42, stratify=clean_df[label])\n",
    "\n",
    "# Automatically map string labels to integers\n",
    "label_list = sorted(train_df[label].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "train_df[label] = train_df[label].map(label_map)\n",
    "val_df[label] = val_df[label].map(label_map)\n",
    "test_df[label] = test_df[label].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fb66be-035e-46e1-9e43-5de03957c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which technique to use to cope with data imbalance\n",
    "handling_imbalance = \"class_weighting\"\n",
    "# when choosing 'class_weighting' dataset is not touched but classes gets weighted depending on label/class distribution\n",
    "\n",
    "if handling_imbalance == 'oversampling':\n",
    "    # Oversample dataset\n",
    "    train_df = oversample_dataset(train_df, label)\n",
    "    # val_df = oversample_dataset(val_df, label) # over and undersampling only useful for training dataset\n",
    "    # test_df = oversample_dataset(test_df, label)\n",
    "elif handling_imbalance == 'undersampling':\n",
    "    # Undersample dataset\n",
    "    train_df = undersample_dataset(train_df, label)\n",
    "    # val_df = undersample_dataset(val_df, label)\n",
    "    # test_df = undersample_dataset(test_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae20628-d358-4fe0-95fd-fb79e925436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2513, 0: 1583}\n"
     ]
    }
   ],
   "source": [
    "# Create PyTorch Datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(train_df, tokenizer, label=label)\n",
    "val_dataset = HateSpeechDataset(val_df, tokenizer, label=label)\n",
    "test_dataset = HateSpeechDataset(test_df, tokenizer, label=label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(get_class_distribution(train_df, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197592e6-249f-4274-97a2-ca3625e089f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_df[label]),\n",
    "    y=train_df[label]\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd402e6",
   "metadata": {},
   "source": [
    "## Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456ec3ec-d7e1-47ad-a9f1-57dac6011ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:57:55.219366: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-20 13:57:55.235428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747742275.256200  107330 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747742275.262443  107330 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747742275.277411  107330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747742275.277427  107330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747742275.277429  107330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747742275.277430  107330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-20 13:57:55.282508: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Decide what pooling to use (cls, mean or attention_pooling)\n",
    "pooling = \"attention_pooling\"\n",
    "\n",
    "# Initialize model\n",
    "model = LargeCustomClassifier(model_name, class_weights_tensor, device, pooling=pooling).to(device)\n",
    "\n",
    "best_model_path = 'best_model_partialy_frozen.pt'\n",
    "\n",
    "# Unfreeze the last 2 layers of the transformer\n",
    "unfrozen_last_layers = 1\n",
    "unfreeze_last_n_layers(model, n_layers=unfrozen_last_layers)\n",
    "\n",
    "# Set learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Optimizer only for the classification head\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=learning_rate)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5445349-d36a-4138-bc0f-f2dd004fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250520_135758-ztgs95n7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/ztgs95n7' target=\"_blank\">floral-dawn-72</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/ztgs95n7' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/ztgs95n7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/ztgs95n7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff3e9dfff50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"roberta-classifier\", config={\n",
    "    \"model\": model_name,\n",
    "    \"frozen_base\": True if unfrozen_last_layers == 0 else f\"last {unfrozen_last_layers} layers unfrozen\",\n",
    "    \"pooling\": pooling,\n",
    "    \"classifier_head\": model.__class__.__name__,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": learning_rate,\n",
    "    \"handling_imbalance\": handling_imbalance\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781a9824-c9d1-44a9-ae3a-70399e220e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6926\n",
      "Train Accuracy: 0.5789\n",
      "Train F1 (macro): 0.4906\n",
      "\n",
      "Val Loss: 0.6890\n",
      "Val Accuracy: 0.6179\n",
      "Val F1 (macro): 0.4046\n",
      "\n",
      "New best model saved (F1: 0.4046, Acc: 0.6179)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6891\n",
      "Train Accuracy: 0.5710\n",
      "Train F1 (macro): 0.5301\n",
      "\n",
      "Val Loss: 0.6859\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6016\n",
      "\n",
      "New best model saved (F1: 0.6016, Acc: 0.6412)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6871\n",
      "Train Accuracy: 0.5811\n",
      "Train F1 (macro): 0.5512\n",
      "\n",
      "Val Loss: 0.6827\n",
      "Val Accuracy: 0.6179\n",
      "Val F1 (macro): 0.5992\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.6847\n",
      "Train Accuracy: 0.5935\n",
      "Train F1 (macro): 0.5663\n",
      "\n",
      "Val Loss: 0.6796\n",
      "Val Accuracy: 0.5985\n",
      "Val F1 (macro): 0.5914\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.6805\n",
      "Train Accuracy: 0.6042\n",
      "Train F1 (macro): 0.5770\n",
      "\n",
      "Val Loss: 0.6765\n",
      "Val Accuracy: 0.5854\n",
      "Val F1 (macro): 0.5841\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.6765\n",
      "Train Accuracy: 0.5959\n",
      "Train F1 (macro): 0.5859\n",
      "\n",
      "Val Loss: 0.6726\n",
      "Val Accuracy: 0.5917\n",
      "Val F1 (macro): 0.5887\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.6719\n",
      "Train Accuracy: 0.6160\n",
      "Train F1 (macro): 0.6044\n",
      "\n",
      "Val Loss: 0.6690\n",
      "Val Accuracy: 0.5877\n",
      "Val F1 (macro): 0.5855\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.6668\n",
      "Train Accuracy: 0.6230\n",
      "Train F1 (macro): 0.6086\n",
      "\n",
      "Val Loss: 0.6654\n",
      "Val Accuracy: 0.5928\n",
      "Val F1 (macro): 0.5904\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.6616\n",
      "Train Accuracy: 0.6235\n",
      "Train F1 (macro): 0.6144\n",
      "\n",
      "Val Loss: 0.6615\n",
      "Val Accuracy: 0.6019\n",
      "Val F1 (macro): 0.5964\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.6577\n",
      "Train Accuracy: 0.6309\n",
      "Train F1 (macro): 0.6205\n",
      "\n",
      "Val Loss: 0.6585\n",
      "Val Accuracy: 0.6031\n",
      "Val F1 (macro): 0.5988\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.6552\n",
      "Train Accuracy: 0.6248\n",
      "Train F1 (macro): 0.6130\n",
      "\n",
      "Val Loss: 0.6566\n",
      "Val Accuracy: 0.5951\n",
      "Val F1 (macro): 0.5930\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.6548\n",
      "Train Accuracy: 0.6157\n",
      "Train F1 (macro): 0.6058\n",
      "\n",
      "Val Loss: 0.6542\n",
      "Val Accuracy: 0.6008\n",
      "Val F1 (macro): 0.5982\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.6510\n",
      "Train Accuracy: 0.6213\n",
      "Train F1 (macro): 0.6129\n",
      "\n",
      "Val Loss: 0.6514\n",
      "Val Accuracy: 0.6150\n",
      "Val F1 (macro): 0.6094\n",
      "\n",
      "New best model saved (F1: 0.6094, Acc: 0.6150)\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.6495\n",
      "Train Accuracy: 0.6345\n",
      "Train F1 (macro): 0.6238\n",
      "\n",
      "Val Loss: 0.6502\n",
      "Val Accuracy: 0.6099\n",
      "Val F1 (macro): 0.6062\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.6468\n",
      "Train Accuracy: 0.6360\n",
      "Train F1 (macro): 0.6266\n",
      "\n",
      "Val Loss: 0.6484\n",
      "Val Accuracy: 0.6139\n",
      "Val F1 (macro): 0.6094\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.6429\n",
      "Train Accuracy: 0.6379\n",
      "Train F1 (macro): 0.6266\n",
      "\n",
      "Val Loss: 0.6472\n",
      "Val Accuracy: 0.6145\n",
      "Val F1 (macro): 0.6109\n",
      "\n",
      "New best model saved (F1: 0.6109, Acc: 0.6145)\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.6417\n",
      "Train Accuracy: 0.6299\n",
      "Train F1 (macro): 0.6200\n",
      "\n",
      "Val Loss: 0.6459\n",
      "Val Accuracy: 0.6156\n",
      "Val F1 (macro): 0.6117\n",
      "\n",
      "New best model saved (F1: 0.6117, Acc: 0.6156)\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.6409\n",
      "Train Accuracy: 0.6304\n",
      "Train F1 (macro): 0.6209\n",
      "\n",
      "Val Loss: 0.6451\n",
      "Val Accuracy: 0.6128\n",
      "Val F1 (macro): 0.6096\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.6399\n",
      "Train Accuracy: 0.6367\n",
      "Train F1 (macro): 0.6280\n",
      "\n",
      "Val Loss: 0.6431\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6217\n",
      "\n",
      "New best model saved (F1: 0.6217, Acc: 0.6276)\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.6388\n",
      "Train Accuracy: 0.6326\n",
      "Train F1 (macro): 0.6219\n",
      "\n",
      "Val Loss: 0.6433\n",
      "Val Accuracy: 0.6133\n",
      "Val F1 (macro): 0.6099\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.6346\n",
      "Train Accuracy: 0.6367\n",
      "Train F1 (macro): 0.6283\n",
      "\n",
      "Val Loss: 0.6411\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6251\n",
      "\n",
      "New best model saved (F1: 0.6251, Acc: 0.6310)\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.6370\n",
      "Train Accuracy: 0.6394\n",
      "Train F1 (macro): 0.6293\n",
      "\n",
      "Val Loss: 0.6408\n",
      "Val Accuracy: 0.6298\n",
      "Val F1 (macro): 0.6249\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.6343\n",
      "Train Accuracy: 0.6406\n",
      "Train F1 (macro): 0.6306\n",
      "\n",
      "Val Loss: 0.6414\n",
      "Val Accuracy: 0.6139\n",
      "Val F1 (macro): 0.6114\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.6332\n",
      "Train Accuracy: 0.6443\n",
      "Train F1 (macro): 0.6346\n",
      "\n",
      "Val Loss: 0.6393\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6234\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.6313\n",
      "Train Accuracy: 0.6355\n",
      "Train F1 (macro): 0.6263\n",
      "\n",
      "Val Loss: 0.6384\n",
      "Val Accuracy: 0.6304\n",
      "Val F1 (macro): 0.6252\n",
      "\n",
      "New best model saved (F1: 0.6252, Acc: 0.6304)\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.6276\n",
      "Train Accuracy: 0.6453\n",
      "Train F1 (macro): 0.6368\n",
      "\n",
      "Val Loss: 0.6373\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6309\n",
      "\n",
      "New best model saved (F1: 0.6309, Acc: 0.6372)\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.6276\n",
      "Train Accuracy: 0.6479\n",
      "Train F1 (macro): 0.6361\n",
      "\n",
      "Val Loss: 0.6374\n",
      "Val Accuracy: 0.6293\n",
      "Val F1 (macro): 0.6247\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.6249\n",
      "Train Accuracy: 0.6482\n",
      "Train F1 (macro): 0.6385\n",
      "\n",
      "Val Loss: 0.6369\n",
      "Val Accuracy: 0.6298\n",
      "Val F1 (macro): 0.6256\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.6245\n",
      "Train Accuracy: 0.6399\n",
      "Train F1 (macro): 0.6299\n",
      "\n",
      "Val Loss: 0.6353\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6363\n",
      "\n",
      "New best model saved (F1: 0.6363, Acc: 0.6429)\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.6266\n",
      "Train Accuracy: 0.6482\n",
      "Train F1 (macro): 0.6379\n",
      "\n",
      "Val Loss: 0.6354\n",
      "Val Accuracy: 0.6355\n",
      "Val F1 (macro): 0.6301\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.6246\n",
      "Train Accuracy: 0.6545\n",
      "Train F1 (macro): 0.6453\n",
      "\n",
      "Val Loss: 0.6351\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6314\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.6228\n",
      "Train Accuracy: 0.6504\n",
      "Train F1 (macro): 0.6411\n",
      "\n",
      "Val Loss: 0.6336\n",
      "Val Accuracy: 0.6498\n",
      "Val F1 (macro): 0.6427\n",
      "\n",
      "New best model saved (F1: 0.6427, Acc: 0.6498)\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.6253\n",
      "Train Accuracy: 0.6506\n",
      "Train F1 (macro): 0.6398\n",
      "\n",
      "Val Loss: 0.6349\n",
      "Val Accuracy: 0.6355\n",
      "Val F1 (macro): 0.6318\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.6191\n",
      "Train Accuracy: 0.6541\n",
      "Train F1 (macro): 0.6456\n",
      "\n",
      "Val Loss: 0.6326\n",
      "Val Accuracy: 0.6532\n",
      "Val F1 (macro): 0.6451\n",
      "\n",
      "New best model saved (F1: 0.6451, Acc: 0.6532)\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.6173\n",
      "Train Accuracy: 0.6575\n",
      "Train F1 (macro): 0.6464\n",
      "\n",
      "Val Loss: 0.6322\n",
      "Val Accuracy: 0.6521\n",
      "Val F1 (macro): 0.6442\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.6197\n",
      "Train Accuracy: 0.6558\n",
      "Train F1 (macro): 0.6447\n",
      "\n",
      "Val Loss: 0.6326\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6390\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.6182\n",
      "Train Accuracy: 0.6558\n",
      "Train F1 (macro): 0.6447\n",
      "\n",
      "Val Loss: 0.6325\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6408\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.6172\n",
      "Train Accuracy: 0.6523\n",
      "Train F1 (macro): 0.6440\n",
      "\n",
      "Val Loss: 0.6311\n",
      "Val Accuracy: 0.6583\n",
      "Val F1 (macro): 0.6498\n",
      "\n",
      "New best model saved (F1: 0.6498, Acc: 0.6583)\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.6185\n",
      "Train Accuracy: 0.6606\n",
      "Train F1 (macro): 0.6509\n",
      "\n",
      "Val Loss: 0.6309\n",
      "Val Accuracy: 0.6583\n",
      "Val F1 (macro): 0.6500\n",
      "\n",
      "New best model saved (F1: 0.6500, Acc: 0.6583)\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.6147\n",
      "Train Accuracy: 0.6592\n",
      "Train F1 (macro): 0.6492\n",
      "\n",
      "Val Loss: 0.6310\n",
      "Val Accuracy: 0.6503\n",
      "Val F1 (macro): 0.6439\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.6165\n",
      "Train Accuracy: 0.6562\n",
      "Train F1 (macro): 0.6462\n",
      "\n",
      "Val Loss: 0.6313\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6406\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.6191\n",
      "Train Accuracy: 0.6597\n",
      "Train F1 (macro): 0.6491\n",
      "\n",
      "Val Loss: 0.6315\n",
      "Val Accuracy: 0.6435\n",
      "Val F1 (macro): 0.6388\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.6170\n",
      "Train Accuracy: 0.6528\n",
      "Train F1 (macro): 0.6444\n",
      "\n",
      "Val Loss: 0.6296\n",
      "Val Accuracy: 0.6640\n",
      "Val F1 (macro): 0.6552\n",
      "\n",
      "New best model saved (F1: 0.6552, Acc: 0.6640)\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.6180\n",
      "Train Accuracy: 0.6682\n",
      "Train F1 (macro): 0.6570\n",
      "\n",
      "Val Loss: 0.6299\n",
      "Val Accuracy: 0.6549\n",
      "Val F1 (macro): 0.6482\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.6160\n",
      "Train Accuracy: 0.6589\n",
      "Train F1 (macro): 0.6486\n",
      "\n",
      "Val Loss: 0.6307\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6410\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.6140\n",
      "Train Accuracy: 0.6670\n",
      "Train F1 (macro): 0.6569\n",
      "\n",
      "Val Loss: 0.6301\n",
      "Val Accuracy: 0.6464\n",
      "Val F1 (macro): 0.6408\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.6103\n",
      "Train Accuracy: 0.6621\n",
      "Train F1 (macro): 0.6516\n",
      "\n",
      "Val Loss: 0.6291\n",
      "Val Accuracy: 0.6651\n",
      "Val F1 (macro): 0.6572\n",
      "\n",
      "New best model saved (F1: 0.6572, Acc: 0.6651)\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.6165\n",
      "Train Accuracy: 0.6548\n",
      "Train F1 (macro): 0.6449\n",
      "\n",
      "Val Loss: 0.6289\n",
      "Val Accuracy: 0.6634\n",
      "Val F1 (macro): 0.6557\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.6089\n",
      "Train Accuracy: 0.6714\n",
      "Train F1 (macro): 0.6599\n",
      "\n",
      "Val Loss: 0.6307\n",
      "Val Accuracy: 0.6435\n",
      "Val F1 (macro): 0.6401\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.6094\n",
      "Train Accuracy: 0.6621\n",
      "Train F1 (macro): 0.6528\n",
      "\n",
      "Val Loss: 0.6286\n",
      "Val Accuracy: 0.6606\n",
      "Val F1 (macro): 0.6526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, device, epochs, best_model_path=best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4b0a",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c821845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5482\n",
      "Test Accuracy: 0.7658\n",
      "Test F1 (macro): 0.7261\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▂▁▂▃▃▄▅▅▅▅▅▆▆▆▅▆▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇▇▇██▇█</td></tr><tr><td>train_f1_macro</td><td>▁▃▄▄▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇████▇███▇█</td></tr><tr><td>train_f1_weighted</td><td>▁▂▃▄▄▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_precision_macro</td><td>▁▂▃▄▄▅▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████</td></tr><tr><td>train_recall_macro</td><td>▁▂▃▄▄▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇██████▇█</td></tr><tr><td>val_accuracy</td><td>▄▆▄▂▁▁▂▂▃▂▄▃▄▄▄▅▃▅▅▄▅▆▅▆▅▇▅▇▇▆▇▇▇▆▆▇▆▆█▆</td></tr><tr><td>val_f1_macro</td><td>▁▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇███▇██████</td></tr><tr><td>val_f1_weighted</td><td>▁▇▆▆▅▅▆▆▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇██▇▇█▇▇▇█▇▇███</td></tr><tr><td>val_loss</td><td>██▇▇▇▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▄▃▁▁▂▁▂▂▂▂▃▃▃▄▄▄▄▅▅▄▅▅▅▅▆▆▆▇▆▇▇▇▇▆█▇▇███</td></tr><tr><td>val_recall_macro</td><td>▁▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>1e-05</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>scheduler</td><td></td></tr><tr><td>test_accuracy</td><td>0.76583</td></tr><tr><td>test_f1_macro</td><td>0.72613</td></tr><tr><td>test_f1_weighted</td><td>0.77831</td></tr><tr><td>test_loss</td><td>0.54817</td></tr><tr><td>test_precision_macro</td><td>0.71517</td></tr><tr><td>test_recall_macro</td><td>0.7675</td></tr><tr><td>train_accuracy</td><td>0.66211</td></tr><tr><td>train_f1_macro</td><td>0.65282</td></tr><tr><td>train_f1_weighted</td><td>0.66571</td></tr><tr><td>train_loss</td><td>0.60944</td></tr><tr><td>train_precision_macro</td><td>0.65227</td></tr><tr><td>train_recall_macro</td><td>0.65894</td></tr><tr><td>val_accuracy</td><td>0.66059</td></tr><tr><td>val_f1_macro</td><td>0.65262</td></tr><tr><td>val_f1_weighted</td><td>0.66461</td></tr><tr><td>val_loss</td><td>0.62856</td></tr><tr><td>val_precision_macro</td><td>0.65289</td></tr><tr><td>val_recall_macro</td><td>0.66035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-dawn-72</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/ztgs95n7' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/ztgs95n7</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_135758-ztgs95n7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7261253747730247, 'accuracy': 0.7658282740676496}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFfCAYAAACBao/8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKGdJREFUeJzt3Xt0FPX5x/FP7kBgNwZINhGDoCBEURQwrCKtmho02AIBRSNGRVBMEIhcjCIqKrGgolQh6k8NtuIFWxBRsIgFVCKXUBS5o2jAuAlIk0hqNpfd3x+UbVcuZjckmXHfr545x8x8Z+aZc2yfPt95vrNBbrfbLQAAYEjBzR0AAAA4MRI1AAAGRqIGAMDASNQAABgYiRoAAAMjUQMAYGAkagAADIxEDQCAgYU2dwBH3XHmsOYOAWh0LxWvbe4QgEZXW/1do1275uDXfp8b1q7zKYyk6RgmUQMA8Itcdc0dQZNj6hsAAAOjogYAmIfb1dwRNDkSNQDAPFwkagAADMtNRQ0AgIFRUQMAYGABWFHT9Q0AgIFRUQMAzCMA11GTqAEA5hGAU98kagCAedBMBgCAcQXi8iyayQAAMDAqagCAeTD1DQCAgQXg1DeJGgBgHizPAgDAwKioAQAwsAB8R03XNwAABkZFDQAwD6a+AQAwsACc+iZRAwBMw+2m6xsAAONi6hsAAAMLwKlvur4BADAwKmoAgHkw9Q0AgIEF4CdEmfoGAJiH2+X/5qPvvvtON910k9q2bauWLVuqR48e2rhx439Dcbs1bdo0xcXFqWXLlkpOTtbu3bu9rnHo0CGlp6fLYrEoKipKI0eO1OHDh32Kg0QNADAPl8v/zQf/+te/dOmllyosLEzLli3Ttm3b9OSTT+q0007zjJk5c6bmzJmjvLw8rVu3TpGRkUpJSVFVVZVnTHp6urZu3aoVK1Zo6dKlWrNmjUaPHu1TLEFut9vt0xmN5I4zhzV3CECje6l4bXOHADS62urvGu3aVQWv+31uC/sN9R5777336tNPP9XHH3983ONut1vx8fG65557NHHiRElSeXm5YmNjlZ+fr+HDh2v79u1KTEzUhg0b1Lt3b0nS8uXLdc0112j//v2Kj4+vVyxU1ACAgOB0OlVRUeG1OZ3O445dsmSJevfurWHDhikmJkYXXnihXnzxRc/xvXv3yuFwKDk52bPParUqKSlJBQUFkqSCggJFRUV5krQkJScnKzg4WOvWrat33CRqAIB5NGDqOzc3V1ar1WvLzc097m2+/vprzZs3T126dNEHH3ygMWPG6O6779b8+fMlSQ6HQ5IUGxvrdV5sbKznmMPhUExMjNfx0NBQRUdHe8bUB13fAADzaMAHT3JycpSdne21LyIi4gS3cal3796aMWOGJOnCCy/Ul19+qby8PGVkZPgdgz+oqAEApuF21/m9RUREyGKxeG0nStRxcXFKTEz02te9e3cVFRVJkmw2mySppKTEa0xJSYnnmM1mU2lpqdfx2tpaHTp0yDOmPkjUAADzaKKu70svvVQ7d+702rdr1y517NhRktSpUyfZbDatXLnSc7yiokLr1q2T3W6XJNntdpWVlamwsNAz5qOPPpLL5VJSUlK9Y2HqGwBgHk30ZbIJEybokksu0YwZM3Tddddp/fr1euGFF/TCCy9IkoKCgjR+/Hg9+uij6tKlizp16qQHHnhA8fHxGjRokKQjFfiAAQM0atQo5eXlqaamRllZWRo+fHi9O74lEjUAAMfo06ePFi1apJycHE2fPl2dOnXS008/rfT0dM+YyZMnq7KyUqNHj1ZZWZn69eun5cuXq0WLFp4xr732mrKysnTllVcqODhYaWlpmjNnjk+xsI4aaEKso0YgaMx11D+tfMHvc1te6duHRoyCihoAYB78KAcAAAYWgL9HTaIGAJgHFTUAAAYWgBU166gBADAwKmoAgHkEYEVNogYAmAfvqAEAMDAqagAADIyKGgAAAwvAipqubwAADIyKGgBgHkx9AwBgYAE49U2iBgCYB4kaAAADM8YvMzcpEjUAwDwCsKKm6xsAAAOjogYAmEcAVtQkagCAebA8CwAAA6OiBgDAwOj6BgDAwAKwoqbrGwAAA6OiBgCYRwBW1CRqAIB50PUNAIBxuV00kwEAYFxMfQMAYGABOPVN1zcAAAZGRQ0AMA/eUQMAYGC8owYAwMBI1AAAGBjf+oaZDbhrkC5MSZLtrNNVXVWtrzft1N8ef00lXxdLklpZW+v3E65T98suUPTp7XT4hwpt/vt6vfPUm6r68d+SpA7dOyplzCCd3bubWkdb9MP+Uq15bYU+euX95nw04KTi423KnXGfBqRcoVatWmjPV9/o9tuzVbjpC8+Ybt3OVu6M+9X/sr4KDQ3Vtu27dN31o7RvX3EzRg6fUVHDzLomnatVf/5A33y+RyGhIRo06UaNe3WqHvrdBFX/5FRU7Gmyxp6mv854VcW796vt6e2V/tgoWWOj9cJdT0qSEs7rrB9/qNDLE/6kfxUf1Fm9ztFNuXfIVefSqleXN/MTAseKirJqzarFWrV6rQZee5MOHPxBXc7upH+VlXvGdO7cUav/sViv5L+uh6c/oYqKw0pM7KqqKmczRg7UT5DbbYx5hDvOHNbcIfzqtI626MlNL+mJ66Zp9/rtxx1z0TV9ddvsu3V34k1y1R3//6neMH2kbGd30OwbH27McAPCS8VrmzuEX50Zj+XoEnsf/faKIScc89pf5qqmpla33Hp3E0YWuGqrv2u0a//7idv9PrfVxP87hZE0HZ/XUR88eFAzZ87U4MGDZbfbZbfbNXjwYM2aNUsHDhxojBjhp5ZtWkmSKssOn3RM1eGfTpikj4452TWA5jRw4FUqLPxCb7z+vIr3f64N6z/QyNtu9BwPCgrSNVdfqd27v9b7S19T8f7PtfaTd/X736c0Y9Twm9vl/2ZSPiXqDRs2qGvXrpozZ46sVqv69++v/v37y2q1as6cOerWrZs2btz4i9dxOp2qqKjw2urcdX4/BI4VFBSk66bdoj0bdqh4177jjok8rY1Sxw7Vx69/eMLrdL6oq3oPvEQfv76isUIFGqRzpwTdcccI7dmzV9cMvFHPP/+qnp49XSNGHJmli4lppzZtWmvypEx98PdVujr1Ri1+Z7nefuv/1P+yvs0cPXzmcvu/mZRP76jHjh2rYcOGKS8vT0FBQV7H3G637rzzTo0dO1YFBQUnvU5ubq4efth7GvUia3f1jjrXl3BwEjc8crvizzlDs4Y+cNzjLVq31NhXcvT9nv169+m3jjsmvusZuuvFKVr6zEJt//iL444BmltwcLAKC7/Q1AcelyRt3rxV5557ju4YNUJ//vNCBQcfqUeWvPuBnpnzoiTp88+3ym7vrdGjR2jNx581W+zwnTsAm8l8qqg///xzTZgw4ZgkLR2p4CZMmKDNmzf/4nVycnJUXl7utV1o7eZLKDiJ4Q+PVI8rLtJTwx9WmePQMccjIlvo7vn3q+rwT5p3xyy5ao+dzYg7u4MmvDZNH7/+od5/9m9NETbgl++/L9W27bu89u3YsUdnnBEvSTp48JBqamq0ffvun43ZrYQzTm+yOHGKUFGfnM1m0/r169Wt2/GT6vr16xUbG/uL14mIiFBERITXvpCgEF9CwQkMf3ikeqZcrKeGP6gf9pcec7xF65Ya9+pU1VTX6Lnb/6haZ80xY+K6dFD2ggdV8NfVeueJ15sibMBvaws26JyuZ3nt69qls4qKjjQ01dTUaOPGz9X1Z2O6dOmsb4v2N1mcgL98qqgnTpyo0aNHa9y4cVqyZInWrVundevWacmSJRo3bpzuvPNOTZ48ubFixS+44ZHblTT4Mr007hlVVVbJ0j5KlvZRCosIl/SfJP3nqQpvGaFXJ89TyzatPGOC/jM9GN/1DGW//pC2ffyFPnxpqed462hLcz4acELPPPOikpIu0r1Txuqss87U8OGDdPvt6Zqbl+8Z88RT83TdsGs18rYbddZZZ+quMbdoYOrvlJc3v/kCh3+aqJnsoYceUlBQkNf2v0VqVVWVMjMz1bZtW7Vu3VppaWkqKSnxukZRUZFSU1PVqlUrxcTEaNKkSaqtrfX5kX2qqDMzM9WuXTvNnj1bc+fOVV3dkSnTkJAQ9erVS/n5+bruuut8DgKnxm9HHOlinfim9/v//InPqeDtVUo4r5M6X9hVkvTYmme9xtzX7y79sP+ALrqmryztrOo7pL/6DunvOX5wf6nu75fZyE8A+G5j4ecaOux2PfrovZp6/3jt/Wafsu95UK+/vsgz5p13luuuzHs1ZfJYPT17unbu+lrDrh+lT9duaMbI4ZcmnMI+99xz9eGH/222DQ39b8qcMGGC3nvvPS1cuFBWq1VZWVkaMmSIPv30U0lSXV2dUlNTZbPZtHbtWn3//fe6+eabFRYWphkzZvgUh9/rqGtqanTw4EFJUrt27RQWFubPZTxYR41AwDpqBILGXEdd+dANfp8b+VD9X+U99NBDWrx48XH7rsrLy9W+fXstWLBAQ4cOlSTt2LFD3bt3V0FBgfr27atly5Zp4MCBKi4u9rwSzsvL05QpU3TgwAGFh4fXOxa/f486LCxMcXFxiouLa3CSBgCgXhrQTHa8pcFO54m/Trd7927Fx8erc+fOSk9PV1FRkSSpsLBQNTU1Sk5O9ozt1q2bEhISPKueCgoK1KNHD6++rZSUFFVUVGjr1q0+PbLfiRoAgCbXgHfUubm5slqtXltubu5xb5OUlKT8/HwtX75c8+bN0969e3XZZZfpxx9/lMPhUHh4uKKiorzOiY2NlcPhkCQ5HI5jmquP/n10TH3xrW8AQEDIyclRdna2176fr0A66uqrr/b88/nnn6+kpCR17NhRb731llq2bNmocf4cFTUAwDwaMPUdEREhi8XitZ0oUf9cVFSUunbtqj179shms6m6ulplZWVeY0pKSmSz2SQdWc788y7wo38fHVNfJGoAgGm4XS6/t4Y4fPiwvvrqK8XFxalXr14KCwvTypUrPcd37typoqIi2e12SZLdbteWLVtUWvrf71msWLFCFotFiYmJPt2bqW8AgHk00fKsiRMn6tprr1XHjh1VXFysBx98UCEhIbrhhhtktVo1cuRIZWdnKzo6WhaLRWPHjpXdblffvke+H3/VVVcpMTFRI0aM0MyZM+VwODR16lRlZmbWu4o/ikQNADCPJkrU+/fv1w033KAffvhB7du3V79+/fTZZ5+pffv2kqTZs2crODhYaWlpcjqdSklJ0dy5cz3nh4SEaOnSpRozZozsdrsiIyOVkZGh6dOn+xwLv0cNNCHWUSMQNOY66sOTBvt9butZi355kAFRUQMAzMPEvyvtLxI1AMA8TPwrWP4iUQMATMNNogYAwMBI1AAAGFgD10ObER88AQDAwKioAQDmwdQ3AAAGRqIGAMC4DPKNriZFogYAmAcVNQAABhaAiZqubwAADIyKGgBgGnyZDAAAIyNRAwBgYIH3YTISNQDAPJj6BgDAyAIwUdP1DQCAgVFRAwDMg3fUAAAYF++oAQAwMipqAACMi4oaAAAjC8CKmq5vAAAMjIoaAGAa7gCsqEnUAADzIFEDAGBcVNQAABgZiRoAAOMKxIqarm8AAAyMihoAYBqBWFGTqAEApkGiBgDAyNxBzR1BkyNRAwBMg4oaAAADc7sCr6Km6xsAAAOjogYAmAZT3wAAGJibZjIAAIyLihoAAAMLxGYyEjUAwDTc7uaOoOnR9Q0AwC94/PHHFRQUpPHjx3v2VVVVKTMzU23btlXr1q2VlpamkpISr/OKioqUmpqqVq1aKSYmRpMmTVJtba1P9yZRAwBMw+0K8nvz14YNG/T888/r/PPP99o/YcIEvfvuu1q4cKFWr16t4uJiDRkyxHO8rq5Oqampqq6u1tq1azV//nzl5+dr2rRpPt2fRA0AMI2GJGqn06mKigqvzel0nvR+hw8fVnp6ul588UWddtppnv3l5eV66aWX9NRTT+mKK65Qr1699Morr2jt2rX67LPPJEl///vftW3bNv3lL39Rz549dfXVV+uRRx7Rc889p+rq6no/M4kaAGAabrf/W25urqxWq9eWm5t70vtlZmYqNTVVycnJXvsLCwtVU1Pjtb9bt25KSEhQQUGBJKmgoEA9evRQbGysZ0xKSooqKiq0devWej8zzWQAANNoyBR2Tk6OsrOzvfZFRESccPwbb7yhTZs2acOGDcccczgcCg8PV1RUlNf+2NhYORwOz5j/TdJHjx89Vl8kagCAaTTkgycREREnTcz/a9++fRo3bpxWrFihFi1a+H3PU4GpbwAAfqawsFClpaW66KKLFBoaqtDQUK1evVpz5sxRaGioYmNjVV1drbKyMq/zSkpKZLPZJEk2m+2YLvCjfx8dUx8kagCAabhd/m++uPLKK7VlyxZt3rzZs/Xu3Vvp6emefw4LC9PKlSs95+zcuVNFRUWy2+2SJLvdri1btqi0tNQzZsWKFbJYLEpMTKx3LEx9AwBMw9VE3/pu06aNzjvvPK99kZGRatu2rWf/yJEjlZ2drejoaFksFo0dO1Z2u119+/aVJF111VVKTEzUiBEjNHPmTDkcDk2dOlWZmZn1noKXSNQAABMx0o9yzJ49W8HBwUpLS5PT6VRKSormzp3rOR4SEqKlS5dqzJgxstvtioyMVEZGhqZPn+7TfYLcbmN8kO2OM4c1dwhAo3upeG1zhwA0utrq7xrt2ju6XuP3ud12vX8KI2k6VNQAANMwRmnZtGgmAwDAwKioAQCmwc9cAgBgYE3V9W0kJGoAgGkYqeu7qZCoAQCmEYjNZCRqAIBpBOLUN13fAAAYGBU1AMA0eEcNAICB8Y4aAAADC8R31IZJ1D+6a5s7BKDR/VT8cXOHAJgaU98AABhYIFbUdH0DAGBgVNQAANMIwF4yEjUAwDwCceqbRA0AMA2ayQAAMDBXcwfQDEjUAADTcCvwKmq6vgEAMDAqagCAabgCsO2bRA0AMA1XAE59k6gBAKYRiO+oSdQAANMIxK5vmskAADAwKmoAgGkw9Q0AgIEF4tQ3iRoAYBokagAADIypbwAADMwVeHmarm8AAIyMihoAYBp8mQwAAAMLwE99k6gBAOZB1zcAAAbmCmLqGwAAwwrEqW+6vgEAMDAqagCAafCOGgAAAwvED56QqAEAphGI66h5Rw0AMA13AzZfzJs3T+eff74sFossFovsdruWLVvmOV5VVaXMzEy1bdtWrVu3VlpamkpKSryuUVRUpNTUVLVq1UoxMTGaNGmSamtrfX5mEjUAwDRcQf5vvujQoYMef/xxFRYWauPGjbriiiv0hz/8QVu3bpUkTZgwQe+++64WLlyo1atXq7i4WEOGDPGcX1dXp9TUVFVXV2vt2rWaP3++8vPzNW3aNJ+fOcjtdhui2/3GjoObOwSg0c0vfLK5QwAaXVi7zo127VdPv8nvc2/+7i8Nund0dLRmzZqloUOHqn379lqwYIGGDh0qSdqxY4e6d++ugoIC9e3bV8uWLdPAgQNVXFys2NhYSVJeXp6mTJmiAwcOKDw8vN73paIGAJiGqwGb0+lURUWF1+Z0On/xnnV1dXrjjTdUWVkpu92uwsJC1dTUKDk52TOmW7duSkhIUEFBgSSpoKBAPXr08CRpSUpJSVFFRYWnKq8vEjUAwDQa8o46NzdXVqvVa8vNzT3hvbZs2aLWrVsrIiJCd955pxYtWqTExEQ5HA6Fh4crKirKa3xsbKwcDockyeFweCXpo8ePHvMFXd8AANNoyPKsnJwcZWdne+2LiIg44fhzzjlHmzdvVnl5ud5++21lZGRo9erV/gfgJxI1AMA0GvLBk4iIiJMm5p8LDw/X2WefLUnq1auXNmzYoGeeeUbXX3+9qqurVVZW5lVVl5SUyGazSZJsNpvWr1/vdb2jXeFHx9QXU98AANNoyDvqBt/b5ZLT6VSvXr0UFhamlStXeo7t3LlTRUVFstvtkiS73a4tW7aotLTUM2bFihWyWCxKTEz06b5U1AAA/ExOTo6uvvpqJSQk6Mcff9SCBQu0atUqffDBB7JarRo5cqSys7MVHR0ti8WisWPHym63q2/fvpKkq666SomJiRoxYoRmzpwph8OhqVOnKjMz06eqXiJRAwBMxN1EHyYrLS3VzTffrO+//15Wq1Xnn3++PvjgA/3ud7+TJM2ePVvBwcFKS0uT0+lUSkqK5s6d6zk/JCRES5cu1ZgxY2S32xUZGamMjAxNnz7d51hYRw00IdZRIxA05jrquWf4v476rn0NW0fdXKioAQCmwa9nAQBgYIaYAm5iJGoAgGkE4s9csjwLAAADo6IGAJgG76gBADAwEjUAAAZGMxkAAAYWiM1kJGoAgGkE4tQ3Xd8AABgYFTUAwDR4Rw0AgIG5AjBVk6gBAKYRiO+oSdQAANMIvHqaRA0AMJFArKjp+gYAwMCoqAEApsEHTwAAMDC6vgEAMLDAS9MkagCAiQRiMxmJGgBgGoE49U3XNwAABkZFDQAwjcCrp0nUAAAT4R01AAAGFojvqEnUAADTCLw0TaIGAJhIIE590/UNAICBUVEDAEzDHYCT3yRqAIBpBOLUN4kaAGAadH0DAGBggZemSdS/Kr+/a4j6DOir+LM6qLqqWrsLd+j1x1/V918Xe8aERYQpfeqtsl/bT2HhofpizWa9PPV5VRwsP+Z6raPaKHf5U2ob106390jXvyv+3ZSPAxxXyYGDemruy/rks42qqnIqoUO8Hrlvgs7r3tUz5qtvijR77svauHmL6urq1PnMBD392FTF2WIkSQvfeV/vrVil7Tv3qPLfP2nt8oWytGndXI8EH1BRw9S6J52rFa8u01ef71FIaIiun5yue//8oCYn3y3nT05J0ogHblPPK3rpmbtm6aeKSt3yyGhNeH6KHk6775jrjZ6ZqX07vlXbuHZN/SjAcZVX/KgRd96jiy+6QHlPPqLToqz6dt93Xkm2aH+xbh4zUUMGpijz9psU2aqVvtpbpPCIcM+Yqiqn+iX1Vr+k3no675XmeBSg3kjUvyJ/zHjE6++8e/6k5/85X516nKUd67epZZtW+u31V+rZcbO1be0WSdLzE/+kJz56Vmdf2FV7/rnLc27yTSlqZYnU3+a8pZ6X92rS5wBO5OXXFsoW016P3p/t2dch3uY1Zs4L83WZvY/uyRzp2ZfQId5rzIjrB0uS1m/6ohGjRWMIxGYy1lH/irVq00qSdLjssCSpU4+zFBoepi8/+dwzpvir73Rgf6m6XHSOZ9/pXTpo8LjrNC/7GbldgfhfCxjVPz75TOd266LsqY+pf+pwDb0lU28vWeY57nK5tGbtBp15xukaPeF+9U8drhtGjdfKNWubMWqcSu4G/MesTnmi3rdvn2677baTjnE6naqoqPDa6tx1pzqUgBYUFKQRD47Uzg3btX9XkSQpqn2Uapw1x7xrrjhYLmv7KElSaHiosuZka8GMV/VD8cGmDhs4qf3FDr25+D0ldDhdz89+VNcPTlXu7Dy98/4KSdKhf5Xp3z/9pJf+8pb6JfXWC7Mf05X9L9H4+x7Vhn9SPf8auBqwmdUpT9SHDh3S/PnzTzomNzdXVqvVa9tWvuuk58A3tz4yWmd0TdCfsp706bzhU0aoeM9+fbpodSNFBvjP5XKre9ezNf7OW9S969ka9odrlPb7AXpr8fue45J0+WV23Tx8sLp1PUu3j7hOv7nkYs8YmFsgVtQ+v6NesmTJSY9//fXXv3iNnJwcZWdne+0bdd5NvoaCE7hl+ihdeGVvTb/ufh1y/ODZX3agTGERYWplaeVVVVvaWVV+oEySlGjvoYRuCbr4mkskSUFBR8Y8/89XtfjZt/XX2W802XMAP9e+bbTOOjPBa1/nM8/Qh6s+lSSdFmVRaEjIccds+mJbk8WJxmPmythfPifqQYMGKSgoSG73if/fSdDR/3U/gYiICEVERHjtCwkK8TUUHMct00epd0qSHr3+AR3YV+p1bO+Wr1RbXaNzLz1fG5Z9JkmK6xyv9h1itHvTTknS03fOVHiL/3bHnnXB2brjibGaPux+lXzraLoHAY7jwvMT9U3Rfq993xZ951l2FRYWpnO7d9Xen435Zt93iv/PGMBsfJ76jouL09/+9je5XK7jbps2bWqMOFEPtz46WpcO+o2evXu2fqr8Sdb2UbK2j1LYf5al/PTjv7XqzZW6aeqtSrSfp07nddYdT4zVrsIdno7v0iKH9u8q8myl+0okSd/t2aeKH45daw00pRHXD9IXW3fohflvqGh/sd77+z/09pJlumHIQM+YW29M0/KVa/T2kmUq2l+sBW8v0epP12n44FTPmIM/HNKOXV+paP+Rbwzs/uob7dj1lcorfmzyZ4JvXG6335tZ+Zyoe/XqpcLCwhMe/6VqG43ndyOuVqQ1UtPeelTzNr7i2ezXXuoZ8+dHXtY/PyrU+LzJemDhYyo7UKbZd/yxGaMG6q9H93P0dO4DWvbhag0acafy8l/XlHF3aGDKFZ4xyb+5VNMmZenl197W4BFj9Nd3P9Dsx6bqogvO84x5c/H7Gnprlh764zOSpIzMSRp6a5b+8fFnTf5M8I27AZsvcnNz1adPH7Vp00YxMTEaNGiQdu7c6TWmqqpKmZmZatu2rVq3bq20tDSVlJR4jSkqKlJqaqpatWqlmJgYTZo0SbW1tT7FEuT2Mat+/PHHqqys1IABA457vLKyUhs3btRvfvMbnwK5seNgn8YDZjS/0LfmPsCMwtp1brRrNyRXLPh2Ub3HDhgwQMOHD1efPn1UW1ur++67T19++aW2bdumyMhISdKYMWP03nvvKT8/X1arVVlZWQoODtannx7pmairq1PPnj1ls9k0a9Ysff/997r55ps1atQozZgxo96x+JyoGwuJGoGARI1A0JiJ+oaOg/w+9/VvF/t97oEDBxQTE6PVq1erf//+Ki8vV/v27bVgwQINHTpUkrRjxw51795dBQUF6tu3r5YtW6aBAwequLhYsbGxkqS8vDxNmTJFBw4cUHh4+Mlu6cEHTwAAptGQddTH+4aH0+ms133Ly4/06ERHR0uSCgsLVVNTo+TkZM+Ybt26KSEhQQUFBZKkgoIC9ejRw5OkJSklJUUVFRXaunVrvZ+ZRA0ACAjH+4ZHbm7uL57ncrk0fvx4XXrppTrvvCO9Dg6HQ+Hh4YqKivIaGxsbK4fD4Rnzv0n66PGjx+qLb30DAEyjIb+edbxvePx8qfDxZGZm6ssvv9Qnn3zi970bgkQNADCNhnxh7Hjf8PglWVlZWrp0qdasWaMOHTp49ttsNlVXV6usrMyrqi4pKZHNZvOMWb9+vdf1jnaFHx1TH0x9AwBMo6m+9e12u5WVlaVFixbpo48+UqdOnbyO9+rVS2FhYVq5cqVn386dO1VUVCS73S5Jstvt2rJli0pL//vxqRUrVshisSgxMbHesVBRAwBMo6kWKmVmZmrBggV655131KZNG887ZavVqpYtW8pqtWrkyJHKzs5WdHS0LBaLxo4dK7vdrr59+0qSrrrqKiUmJmrEiBGaOXOmHA6Hpk6dqszMTJ8qexI1AAA/M2/ePEnSb3/7W6/9r7zyim655RZJ0uzZsxUcHKy0tDQ5nU6lpKRo7ty5nrEhISFaunSpxowZI7vdrsjISGVkZGj69Ok+xcI6aqAJsY4agaAx11H/IWHgLw86gXeKlp7CSJoOFTUAwDT49SwAAAzMzL8r7S8SNQDANBqyjtqsSNQAANMwSFtVk2IdNQAABkZFDQAwDZrJAAAwMJrJAAAwMJrJAAAwsEBsJiNRAwBMIxArarq+AQAwMCpqAIBp0EwGAICBuXhHDQCAcQVemiZRAwBMJBCbyUjUAADTCMRETdc3AAAGRkUNADANPngCAICBBeLUN4kaAGAarKMGAMDAmPoGAMDAAnHqm65vAAAMjIoaAGAaTH0DAGBggTj1TaIGAJgGXd8AABgYv54FAICBBWJFTdc3AAAGRkUNADANpr4BADCwQJz6JlEDAEyDihoAAAOjogYAwMACsaKm6xsAAAOjogYAmAZT3wAAGJjb7WruEJociRoAYBr8KAcAAAbGz1wCAGBggVhR0/UNAICBkagBAKbhdrv93ny1Zs0aXXvttYqPj1dQUJAWL158TCzTpk1TXFycWrZsqeTkZO3evdtrzKFDh5Seni6LxaKoqCiNHDlShw8f9ikOEjUAwDRcbrffm68qKyt1wQUX6Lnnnjvu8ZkzZ2rOnDnKy8vTunXrFBkZqZSUFFVVVXnGpKena+vWrVqxYoWWLl2qNWvWaPTo0T7FEeQ2yJv5GzsObu4QgEY3v/DJ5g4BaHRh7To32rVtUd39PtdRtt3vc4OCgrRo0SINGjRI0pFqOj4+Xvfcc48mTpwoSSovL1dsbKzy8/M1fPhwbd++XYmJidqwYYN69+4tSVq+fLmuueYa7d+/X/Hx8fW6NxU1AMA0GjL17XQ6VVFR4bU5nU6/4ti7d68cDoeSk5M9+6xWq5KSklRQUCBJKigoUFRUlCdJS1JycrKCg4O1bt26et+LRA0AMA2X3H5vubm5slqtXltubq5fcTgcDklSbGys1/7Y2FjPMYfDoZiYGK/joaGhio6O9oypD5ZnAQACQk5OjrKzs732RURENFM09UeiBgCYRkPaqiIiIk5ZYrbZbJKkkpISxcXFefaXlJSoZ8+enjGlpaVe59XW1urQoUOe8+uDqW8AgGk0Zdf3yXTq1Ek2m00rV6707KuoqNC6detkt9slSXa7XWVlZSosLPSM+eijj+RyuZSUlFTve1FRAwBMoykXKh0+fFh79uzx/L13715t3rxZ0dHRSkhI0Pjx4/Xoo4+qS5cu6tSpkx544AHFx8d7OsO7d++uAQMGaNSoUcrLy1NNTY2ysrI0fPjwend8SyRqAICJNOUnRDdu3KjLL7/c8/fR99sZGRnKz8/X5MmTVVlZqdGjR6usrEz9+vXT8uXL1aJFC885r732mrKysnTllVcqODhYaWlpmjNnjk9xsI4aaEKso0YgaMx11JZI/69dUfn1KYyk6fCOGgAAA2PqGwBgGqe6KcwMSNQAANNwB+DPXJKoAQCmQUUNAICBGaT/uUmRqAEAphGIU990fQMAYGBU1AAA02DqGwAAAyNRAwBgYIGXpg30CVE0LafTqdzcXOXk5Jji91gBf/DvOX4NSNQBqqKiQlarVeXl5bJYLM0dDtAo+PccvwZ0fQMAYGAkagAADIxEDQCAgZGoA1RERIQefPBBGmzwq8a/5/g1oJkMAAADo6IGAMDASNQAABgYiRoAAAMjUQMAYGAkagAADIxEHYCee+45nXnmmWrRooWSkpK0fv365g4JOKXWrFmja6+9VvHx8QoKCtLixYubOyTAbyTqAPPmm28qOztbDz74oDZt2qQLLrhAKSkpKi0tbe7QgFOmsrJSF1xwgZ577rnmDgVoMNZRB5ikpCT16dNHzz77rCTJ5XLpjDPO0NixY3Xvvfc2c3TAqRcUFKRFixZp0KBBzR0K4Bcq6gBSXV2twsJCJScne/YFBwcrOTlZBQUFzRgZAOBESNQB5ODBg6qrq1NsbKzX/tjYWDkcjmaKCgBwMiRqAAAMjEQdQNq1a6eQkBCVlJR47S8pKZHNZmumqAAAJ0OiDiDh4eHq1auXVq5c6dnncrm0cuVK2e32ZowMAHAioc0dAJpWdna2MjIy1Lt3b1188cV6+umnVVlZqVtvvbW5QwNOmcOHD2vPnj2ev/fu3avNmzcrOjpaCQkJzRgZ4DuWZwWgZ599VrNmzZLD4VDPnj01Z84cJSUlNXdYwCmzatUqXX755cfsz8jIUH5+ftMHBDQAiRoAAAPjHTUAAAZGogYAwMBI1AAAGBiJGgAAAyNRAwBgYCRqAAAMjEQNAICBkagBADAwEjUAAAZGogYAwMBI1AAAGNj/A2izh4v0p9OSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "# Test model on test set\n",
    "test_model(model, test_loader, device, phase = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42663d-0907-4ab8-a5e9-955732ab0539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
