{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e76a0e7-e90e-457e-8dc4-81cc472f2f1e",
   "metadata": {},
   "source": [
    "The goal of this project is to use the pretrained RoBERTa transformer as a feature extractor with a costum classification head to determine if text messages are offensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbb6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "from paths import DATA_CLEANED\n",
    "from paths import DATA_PROCESSED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040a974",
   "metadata": {},
   "source": [
    "## Using RoBERTa as a feature extractor with a costum classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4da52",
   "metadata": {},
   "source": [
    "Found this pretrained model online: cardiffnlp/twitter-roberta-base-sentiment-latest (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "It is already pretrained on twitter messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d5297-ec56-4954-91d1-7b650e5b16f0",
   "metadata": {},
   "source": [
    "Define experiment scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad28b13-1a6b-4331-bc4b-37b863df796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using the labels of the first task of the HASOC dataset, which is a binary classification\n",
    "label = \"task_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc731c7",
   "metadata": {},
   "source": [
    "Define which pretrained model is used and initilise tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20ed5c",
   "metadata": {},
   "source": [
    "Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, model_name, pooling='cls'):\n",
    "        super().__init__()\n",
    "        self.pooling = pooling.lower()\n",
    "        self.base = AutoModel.from_pretrained(model_name)\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_size = config.hidden_size  # Dynamically get the model's hidden size\n",
    "\n",
    "        \n",
    "        print(hidden_size)\n",
    "        \n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Custom classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Pooling strategy: either CLS token or mean pooling over token embeddings\n",
    "        if self.pooling == 'mean':\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "            sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1).clamp(min=1e-9)\n",
    "            pooled = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            pooled = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        # If labels are provided, calculate the loss\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb86e8",
   "metadata": {},
   "source": [
    "## Load HASOC dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f76fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "clean_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_train_cleaned.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_PROCESSED / \"hasoc_2019_en_test.tsv\", sep='\\t')\n",
    "\n",
    "# Split clean dataset in training and validation set\n",
    "train_df, val_df = train_test_split(clean_df, test_size=0.3, random_state=42, stratify=clean_df[label])\n",
    "\n",
    "# Automatically map string labels to integers\n",
    "label_list = sorted(train_df[label].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "train_df[label] = train_df[label].map(label_map)\n",
    "val_df[label] = val_df[label].map(label_map)\n",
    "test_df[label] = test_df[label].map(label_map)\n",
    "\n",
    "# Custom Dataset Class\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, label = 'label', max_len=128):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[label].tolist()\n",
    "        self.encodings = tokenizer(self.texts, padding=True, truncation=True, max_length=max_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create PyTorch Datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(train_df, tokenizer, label=label)\n",
    "val_dataset = HateSpeechDataset(val_df, tokenizer, label=label)\n",
    "test_dataset = HateSpeechDataset(test_df, tokenizer, label=label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd402e6",
   "metadata": {},
   "source": [
    "## Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456ec3ec-d7e1-47ad-a9f1-57dac6011ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 16:25:45.202669: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 16:25:45.219672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746800745.239150   32020 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746800745.245105   32020 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746800745.259528   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746800745.259542   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746800745.259544   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746800745.259545   32020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-09 16:25:45.264929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = CustomClassifier(model_name, pooling=\"cls\").to(device)\n",
    "\n",
    "# Optimizer only for the classification head\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=2e-4)\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5445349-d36a-4138-bc0f-f2dd004fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250509_162548-zcl5qkjk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/zcl5qkjk' target=\"_blank\">hopeful-lion-5</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/zcl5qkjk' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/zcl5qkjk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/zcl5qkjk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0a0d0ab390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"roberta-classifier\", config={\n",
    "    \"model\": model_name,\n",
    "    \"pooling\": \"cls\",\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": 2e-4,\n",
    "    \"frozen_base\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f92b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Train Loss: 0.6228\n",
      "Train Accuracy: 0.6143\n",
      "Train F1 (macro): 0.3847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6139\n",
      "Test F1 (macro): 0.3804\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.7563\n",
      "Train Accuracy: 0.6155\n",
      "Train F1 (macro): 0.3915\n",
      "\n",
      "Test Accuracy: 0.6179\n",
      "Test F1 (macro): 0.3942\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.7277\n",
      "Train Accuracy: 0.6184\n",
      "Train F1 (macro): 0.4261\n",
      "\n",
      "Test Accuracy: 0.6247\n",
      "Test F1 (macro): 0.4152\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.6249\n",
      "Train Accuracy: 0.6284\n",
      "Train F1 (macro): 0.4633\n",
      "\n",
      "Test Accuracy: 0.6526\n",
      "Test F1 (macro): 0.5311\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.5811\n",
      "Train Accuracy: 0.6350\n",
      "Train F1 (macro): 0.5116\n",
      "\n",
      "Test Accuracy: 0.6646\n",
      "Test F1 (macro): 0.5975\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.5545\n",
      "Train Accuracy: 0.6436\n",
      "Train F1 (macro): 0.5272\n",
      "\n",
      "Test Accuracy: 0.6566\n",
      "Test F1 (macro): 0.5518\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.6039\n",
      "Train Accuracy: 0.6519\n",
      "Train F1 (macro): 0.5501\n",
      "\n",
      "Test Accuracy: 0.6623\n",
      "Test F1 (macro): 0.5842\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.7521\n",
      "Train Accuracy: 0.6582\n",
      "Train F1 (macro): 0.5720\n",
      "\n",
      "Test Accuracy: 0.6600\n",
      "Test F1 (macro): 0.5678\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.5310\n",
      "Train Accuracy: 0.6643\n",
      "Train F1 (macro): 0.5888\n",
      "\n",
      "Test Accuracy: 0.6532\n",
      "Test F1 (macro): 0.5441\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.7514\n",
      "Train Accuracy: 0.6594\n",
      "Train F1 (macro): 0.5839\n",
      "\n",
      "Test Accuracy: 0.6674\n",
      "Test F1 (macro): 0.6225\n",
      "\n",
      "Epoch 11\n",
      "Train Loss: 0.6784\n",
      "Train Accuracy: 0.6560\n",
      "Train F1 (macro): 0.5839\n",
      "\n",
      "Test Accuracy: 0.6708\n",
      "Test F1 (macro): 0.6257\n",
      "\n",
      "Epoch 12\n",
      "Train Loss: 0.5048\n",
      "Train Accuracy: 0.6580\n",
      "Train F1 (macro): 0.5952\n",
      "\n",
      "Test Accuracy: 0.6629\n",
      "Test F1 (macro): 0.6430\n",
      "\n",
      "Epoch 13\n",
      "Train Loss: 0.4645\n",
      "Train Accuracy: 0.6721\n",
      "Train F1 (macro): 0.6140\n",
      "\n",
      "Test Accuracy: 0.6697\n",
      "Test F1 (macro): 0.6270\n",
      "\n",
      "Epoch 14\n",
      "Train Loss: 0.7787\n",
      "Train Accuracy: 0.6682\n",
      "Train F1 (macro): 0.6048\n",
      "\n",
      "Test Accuracy: 0.6572\n",
      "Test F1 (macro): 0.5604\n",
      "\n",
      "Epoch 15\n",
      "Train Loss: 0.5186\n",
      "Train Accuracy: 0.6682\n",
      "Train F1 (macro): 0.6075\n",
      "\n",
      "Test Accuracy: 0.6640\n",
      "Test F1 (macro): 0.6292\n",
      "\n",
      "Epoch 16\n",
      "Train Loss: 0.7488\n",
      "Train Accuracy: 0.6736\n",
      "Train F1 (macro): 0.6203\n",
      "\n",
      "Test Accuracy: 0.6697\n",
      "Test F1 (macro): 0.6267\n",
      "\n",
      "Epoch 17\n",
      "Train Loss: 0.6834\n",
      "Train Accuracy: 0.6726\n",
      "Train F1 (macro): 0.6196\n",
      "\n",
      "Test Accuracy: 0.6686\n",
      "Test F1 (macro): 0.5855\n",
      "\n",
      "Epoch 18\n",
      "Train Loss: 0.5866\n",
      "Train Accuracy: 0.6721\n",
      "Train F1 (macro): 0.6156\n",
      "\n",
      "Test Accuracy: 0.6623\n",
      "Test F1 (macro): 0.5707\n",
      "\n",
      "Epoch 19\n",
      "Train Loss: 0.5538\n",
      "Train Accuracy: 0.6650\n",
      "Train F1 (macro): 0.6085\n",
      "\n",
      "Test Accuracy: 0.6674\n",
      "Test F1 (macro): 0.6451\n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.4951\n",
      "Train Accuracy: 0.6753\n",
      "Train F1 (macro): 0.6223\n",
      "\n",
      "Test Accuracy: 0.6720\n",
      "Test F1 (macro): 0.6443\n",
      "\n",
      "Epoch 21\n",
      "Train Loss: 0.6705\n",
      "Train Accuracy: 0.6746\n",
      "Train F1 (macro): 0.6253\n",
      "\n",
      "Test Accuracy: 0.6737\n",
      "Test F1 (macro): 0.6291\n",
      "\n",
      "Epoch 22\n",
      "Train Loss: 0.6668\n",
      "Train Accuracy: 0.6689\n",
      "Train F1 (macro): 0.6178\n",
      "\n",
      "Test Accuracy: 0.6748\n",
      "Test F1 (macro): 0.6290\n",
      "\n",
      "Epoch 23\n",
      "Train Loss: 0.5050\n",
      "Train Accuracy: 0.6821\n",
      "Train F1 (macro): 0.6300\n",
      "\n",
      "Test Accuracy: 0.6777\n",
      "Test F1 (macro): 0.6279\n",
      "\n",
      "Epoch 24\n",
      "Train Loss: 0.5674\n",
      "Train Accuracy: 0.6816\n",
      "Train F1 (macro): 0.6340\n",
      "\n",
      "Test Accuracy: 0.6748\n",
      "Test F1 (macro): 0.6259\n",
      "\n",
      "Epoch 25\n",
      "Train Loss: 0.6034\n",
      "Train Accuracy: 0.6770\n",
      "Train F1 (macro): 0.6284\n",
      "\n",
      "Test Accuracy: 0.6777\n",
      "Test F1 (macro): 0.6239\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move batch to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(input_ids, attention_mask, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute training metrics\n",
    "    acc = accuracy_score(train_labels, train_preds)\n",
    "    prec = precision_score(train_labels, train_preds, average='macro')\n",
    "    rec = recall_score(train_labels, train_preds, average='macro')\n",
    "    f1 = f1_score(train_labels, train_preds, average='macro')\n",
    "    f1_weighted = f1_score(train_labels, train_preds, average='weighted')\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {loss.item():.4f}\")\n",
    "    print(f\"Train Accuracy: {acc:.4f}\")\n",
    "    print(f\"Train F1 (macro): {f1:.4f}\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": loss.item(),\n",
    "        \"train_accuracy\": acc,\n",
    "        \"train_precision_macro\": prec,\n",
    "        \"train_recall_macro\": rec,\n",
    "        \"train_f1_macro\": f1,\n",
    "        \"train_f1_weighted\": f1_weighted\n",
    "    })\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    # Compute test metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='macro')\n",
    "    rec = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "    print(f\"Test F1 (macro): {f1:.4f}\")\n",
    "\n",
    "\n",
    "    wandb.log({\n",
    "        \"val_accuracy\": acc,\n",
    "        \"val_precision_macro\": prec,\n",
    "        \"val_recall_macro\": rec,\n",
    "        \"val_f1_macro\": f1,\n",
    "        \"val_f1_weighted\": f1_weighted\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4b0a",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c821845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "Test Accuracy: 0.7971\n",
      "Test F1 (macro): 0.6619\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute test metrics\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, average='macro')\n",
    "rec = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"\\n--- Test Results ---\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test F1 (macro): {f1:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "        \"test_accuracy\": acc,\n",
    "        \"test_precision_macro\": prec,\n",
    "        \"test_recall_macro\": rec,\n",
    "        \"test_f1_macro\": f1,\n",
    "        \"test_f1_weighted\": f1_weighted\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3750aab3-4b20-43bc-b7cf-00d897c050d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▃▄▅▆▆▆▅▆▇▇▇▇▇▇▆▇▇▇██▇</td></tr><tr><td>train_f1_macro</td><td>▁▁▂▃▅▅▆▆▇▇▇▇▇▇▇██▇▇██████</td></tr><tr><td>train_f1_weighted</td><td>▁▁▂▃▅▅▆▆▇▇▇▇▇▇▇██▇▇██▇███</td></tr><tr><td>train_loss</td><td>▅█▇▅▄▃▄▇▂▇▆▂▁█▂▇▆▄▃▂▆▆▂▃▄</td></tr><tr><td>train_precision_macro</td><td>▄▄▁▄▃▅▆▆▇▆▅▅▇▇▆▇▇▇▆▇▇▆██▇</td></tr><tr><td>train_recall_macro</td><td>▁▁▂▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>val_accuracy</td><td>▁▁▂▅▇▆▆▆▅▇▇▆▇▆▆▇▇▆▇▇█████</td></tr><tr><td>val_f1_macro</td><td>▁▁▂▅▇▆▆▆▅▇▇██▆██▆▆█████▇▇</td></tr><tr><td>val_f1_weighted</td><td>▁▁▂▅▇▆▇▆▅▇███▆██▇▆███████</td></tr><tr><td>val_precision_macro</td><td>▁██▇▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_recall_macro</td><td>▁▁▂▄▆▅▆▅▄▇▇█▇▅▇▇▆▅██▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>test_accuracy</td><td>0.79705</td></tr><tr><td>test_f1_macro</td><td>0.66189</td></tr><tr><td>test_f1_weighted</td><td>0.76887</td></tr><tr><td>test_precision_macro</td><td>0.75438</td></tr><tr><td>test_recall_macro</td><td>0.64123</td></tr><tr><td>train_accuracy</td><td>0.677</td></tr><tr><td>train_f1_macro</td><td>0.62842</td></tr><tr><td>train_f1_weighted</td><td>0.65893</td></tr><tr><td>train_loss</td><td>0.60339</td></tr><tr><td>train_precision_macro</td><td>0.66008</td></tr><tr><td>train_recall_macro</td><td>0.62724</td></tr><tr><td>val_accuracy</td><td>0.67768</td></tr><tr><td>val_f1_macro</td><td>0.6239</td></tr><tr><td>val_f1_weighted</td><td>0.6563</td></tr><tr><td>val_precision_macro</td><td>0.66301</td></tr><tr><td>val_recall_macro</td><td>0.62392</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-lion-5</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/zcl5qkjk' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/zcl5qkjk</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250509_162548-zcl5qkjk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "wandb.log({\"confusion_matrix\": wandb.Image(fig)})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
