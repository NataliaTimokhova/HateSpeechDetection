{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e76a0e7-e90e-457e-8dc4-81cc472f2f1e",
   "metadata": {},
   "source": [
    "The goal of this project is to use the pretrained RoBERTa transformer as a feature extractor with a costum classification head to determine if text messages are offensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbb6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "from paths import DATA_CLEANED\n",
    "from paths import DATA_PROCESSED\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper_functions import train_model, test_model, get_class_distribution, oversample_dataset, undersample_dataset, AttentionPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f24224-26ee-49a1-adf0-48e3e6d38544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040a974",
   "metadata": {},
   "source": [
    "## Using RoBERTa as a feature extractor with a costum classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4da52",
   "metadata": {},
   "source": [
    "Found this pretrained model online: cardiffnlp/twitter-roberta-base-sentiment-latest (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "It is already pretrained on twitter messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc731c7",
   "metadata": {},
   "source": [
    "Define which pretrained model is used and initilise tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20ed5c",
   "metadata": {},
   "source": [
    "Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, model_name, pooling='cls'):\n",
    "        super().__init__()\n",
    "        self.pooling = pooling.lower()\n",
    "        self.base = AutoModel.from_pretrained(model_name)\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_size = config.hidden_size  # Dynamically get the model's hidden size\n",
    "\n",
    "        if pooling == 'attention_pooling'\n",
    "            # Replace CLS pooling with attention\n",
    "            self.attention_pool = AttentionPooling(hidden_size)\n",
    "        \n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Custom classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, class_weights_tensor = None, labels=None):\n",
    "        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Pooling strategy: either CLS token or mean pooling over token embeddings\n",
    "        if self.pooling == 'mean':\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "            sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1).clamp(min=1e-9)\n",
    "            pooled = sum_embeddings / sum_mask\n",
    "        if else self.pooling == 'attention_pooling':\n",
    "            pooled = self.attention_pool(outputs.last_hidden_state, attention_mask)\n",
    "        else:\n",
    "            pooled = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        # If labels are provided, calculate the loss\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb86e8",
   "metadata": {},
   "source": [
    "## Load HASOC dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f133729a-b5db-4e99-809d-12a6ba529ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, label = 'label', max_len=128):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[label].tolist()\n",
    "        self.encodings = tokenizer(self.texts, padding=True, truncation=True, max_length=max_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181465c-ef90-409f-9cb4-39f7db6f2e93",
   "metadata": {},
   "source": [
    "Define experiment scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479a3f53-d232-42b2-8dd3-169bce3efd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using the labels of the first task of the HASOC dataset, which is a binary classification\n",
    "label = \"task_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f76fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1583, 0: 1583}\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "clean_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_train_cleaned.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_PROCESSED / \"hasoc_2019_en_test.tsv\", sep='\\t')\n",
    "\n",
    "# Split clean dataset in training and validation set\n",
    "train_df, val_df = train_test_split(clean_df, test_size=0.3, random_state=42, stratify=clean_df[label])\n",
    "\n",
    "# Automatically map string labels to integers\n",
    "label_list = sorted(train_df[label].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "train_df[label] = train_df[label].map(label_map)\n",
    "val_df[label] = val_df[label].map(label_map)\n",
    "test_df[label] = test_df[label].map(label_map)\n",
    "\n",
    "# Oversample dataset\n",
    "# os_train_df = oversample_dataset(train_df, label)\n",
    "# os_val_df = oversample_dataset(val_df, label)\n",
    "# os_test_df = oversample_dataset(test_df, label)\n",
    "\n",
    "# Undersample dataset\n",
    "us_train_df = undersample_dataset(train_df, label)\n",
    "us_val_df = undersample_dataset(val_df, label)\n",
    "us_test_df = undersample_dataset(test_df, label)\n",
    "\n",
    "# Create PyTorch Datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(us_train_df, tokenizer, label=label)\n",
    "val_dataset = HateSpeechDataset(us_val_df, tokenizer, label=label)\n",
    "test_dataset = HateSpeechDataset(us_test_df, tokenizer, label=label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(get_class_distribution(us_train_df, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197592e6-249f-4274-97a2-ca3625e089f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(us_train_df[label]),\n",
    "    y=us_train_df[label]\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd402e6",
   "metadata": {},
   "source": [
    "## Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456ec3ec-d7e1-47ad-a9f1-57dac6011ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 12:23:46.463051: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-13 12:23:46.479042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747131826.498346   54737 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747131826.504173   54737 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747131826.518742   54737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747131826.518757   54737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747131826.518759   54737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747131826.518760   54737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-13 12:23:46.524020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Decide what pooling to use\n",
    "pooling = \"cls\"\n",
    "\n",
    "# Initialize model\n",
    "model = CustomClassifier(model_name, pooling=pooling).to(device)\n",
    "\n",
    "# Optimizer only for the classification head\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=2e-4)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5445349-d36a-4138-bc0f-f2dd004fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250513_122349-djxm8big</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/djxm8big' target=\"_blank\">warm-glade-25</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/djxm8big' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/djxm8big</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/djxm8big?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa88f2037d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"roberta-classifier\", config={\n",
    "    \"model\": model_name,\n",
    "    \"frozen_base\": True,\n",
    "    \"pooling\": pooling,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": 2e-4,\n",
    "    \"handling_imbalance\": \"undersampling\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "781a9824-c9d1-44a9-ae3a-70399e220e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6919\n",
      "Train Accuracy: 0.5193\n",
      "Train F1 (macro): 0.5147\n",
      "\n",
      "Val Loss: 0.6873\n",
      "Val Accuracy: 0.5192\n",
      "Val F1 (macro): 0.3857\n",
      "\n",
      "New best model saved (F1: 0.3857, Acc: 0.5192)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6829\n",
      "Train Accuracy: 0.5872\n",
      "Train F1 (macro): 0.5863\n",
      "\n",
      "Val Loss: 0.6782\n",
      "Val Accuracy: 0.5863\n",
      "Val F1 (macro): 0.5543\n",
      "\n",
      "New best model saved (F1: 0.5543, Acc: 0.5863)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6753\n",
      "Train Accuracy: 0.5963\n",
      "Train F1 (macro): 0.5962\n",
      "\n",
      "Val Loss: 0.6701\n",
      "Val Accuracy: 0.6114\n",
      "Val F1 (macro): 0.6013\n",
      "\n",
      "New best model saved (F1: 0.6013, Acc: 0.6114)\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.6671\n",
      "Train Accuracy: 0.6077\n",
      "Train F1 (macro): 0.6077\n",
      "\n",
      "Val Loss: 0.6672\n",
      "Val Accuracy: 0.6025\n",
      "Val F1 (macro): 0.5801\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.6609\n",
      "Train Accuracy: 0.6175\n",
      "Train F1 (macro): 0.6175\n",
      "\n",
      "Val Loss: 0.6598\n",
      "Val Accuracy: 0.6069\n",
      "Val F1 (macro): 0.5976\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.6580\n",
      "Train Accuracy: 0.6222\n",
      "Train F1 (macro): 0.6222\n",
      "\n",
      "Val Loss: 0.6543\n",
      "Val Accuracy: 0.6246\n",
      "Val F1 (macro): 0.6227\n",
      "\n",
      "New best model saved (F1: 0.6227, Acc: 0.6246)\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.6561\n",
      "Train Accuracy: 0.6200\n",
      "Train F1 (macro): 0.6200\n",
      "\n",
      "Val Loss: 0.6529\n",
      "Val Accuracy: 0.6180\n",
      "Val F1 (macro): 0.6102\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.6462\n",
      "Train Accuracy: 0.6257\n",
      "Train F1 (macro): 0.6257\n",
      "\n",
      "Val Loss: 0.6489\n",
      "Val Accuracy: 0.6209\n",
      "Val F1 (macro): 0.6165\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.6453\n",
      "Train Accuracy: 0.6270\n",
      "Train F1 (macro): 0.6269\n",
      "\n",
      "Val Loss: 0.6452\n",
      "Val Accuracy: 0.6335\n",
      "Val F1 (macro): 0.6331\n",
      "\n",
      "New best model saved (F1: 0.6331, Acc: 0.6335)\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.6444\n",
      "Train Accuracy: 0.6383\n",
      "Train F1 (macro): 0.6383\n",
      "\n",
      "Val Loss: 0.6442\n",
      "Val Accuracy: 0.6313\n",
      "Val F1 (macro): 0.6291\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.6418\n",
      "Train Accuracy: 0.6301\n",
      "Train F1 (macro): 0.6301\n",
      "\n",
      "Val Loss: 0.6419\n",
      "Val Accuracy: 0.6298\n",
      "Val F1 (macro): 0.6294\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.6425\n",
      "Train Accuracy: 0.6314\n",
      "Train F1 (macro): 0.6314\n",
      "\n",
      "Val Loss: 0.6415\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6336\n",
      "\n",
      "New best model saved (F1: 0.6336, Acc: 0.6350)\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.6428\n",
      "Train Accuracy: 0.6393\n",
      "Train F1 (macro): 0.6392\n",
      "\n",
      "Val Loss: 0.6407\n",
      "Val Accuracy: 0.6423\n",
      "Val F1 (macro): 0.6419\n",
      "\n",
      "New best model saved (F1: 0.6419, Acc: 0.6423)\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.6325\n",
      "Train Accuracy: 0.6453\n",
      "Train F1 (macro): 0.6452\n",
      "\n",
      "Val Loss: 0.6382\n",
      "Val Accuracy: 0.6475\n",
      "Val F1 (macro): 0.6475\n",
      "\n",
      "New best model saved (F1: 0.6475, Acc: 0.6475)\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.6350\n",
      "Train Accuracy: 0.6368\n",
      "Train F1 (macro): 0.6368\n",
      "\n",
      "Val Loss: 0.6368\n",
      "Val Accuracy: 0.6490\n",
      "Val F1 (macro): 0.6487\n",
      "\n",
      "New best model saved (F1: 0.6487, Acc: 0.6490)\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.6386\n",
      "Train Accuracy: 0.6377\n",
      "Train F1 (macro): 0.6377\n",
      "\n",
      "Val Loss: 0.6375\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6408\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.6315\n",
      "Train Accuracy: 0.6298\n",
      "Train F1 (macro): 0.6298\n",
      "\n",
      "Val Loss: 0.6360\n",
      "Val Accuracy: 0.6460\n",
      "Val F1 (macro): 0.6460\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.6348\n",
      "Train Accuracy: 0.6371\n",
      "Train F1 (macro): 0.6370\n",
      "\n",
      "Val Loss: 0.6367\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6406\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.6344\n",
      "Train Accuracy: 0.6377\n",
      "Train F1 (macro): 0.6375\n",
      "\n",
      "Val Loss: 0.6364\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6407\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.6316\n",
      "Train Accuracy: 0.6491\n",
      "Train F1 (macro): 0.6491\n",
      "\n",
      "Val Loss: 0.6361\n",
      "Val Accuracy: 0.6386\n",
      "Val F1 (macro): 0.6378\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.6308\n",
      "Train Accuracy: 0.6434\n",
      "Train F1 (macro): 0.6434\n",
      "\n",
      "Val Loss: 0.6373\n",
      "Val Accuracy: 0.6291\n",
      "Val F1 (macro): 0.6268\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.6334\n",
      "Train Accuracy: 0.6434\n",
      "Train F1 (macro): 0.6434\n",
      "\n",
      "Val Loss: 0.6350\n",
      "Val Accuracy: 0.6460\n",
      "Val F1 (macro): 0.6460\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.6356\n",
      "Train Accuracy: 0.6396\n",
      "Train F1 (macro): 0.6396\n",
      "\n",
      "Val Loss: 0.6345\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6414\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.6302\n",
      "Train Accuracy: 0.6513\n",
      "Train F1 (macro): 0.6513\n",
      "\n",
      "Val Loss: 0.6369\n",
      "Val Accuracy: 0.6305\n",
      "Val F1 (macro): 0.6285\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.6264\n",
      "Train Accuracy: 0.6466\n",
      "Train F1 (macro): 0.6465\n",
      "\n",
      "Val Loss: 0.6345\n",
      "Val Accuracy: 0.6386\n",
      "Val F1 (macro): 0.6378\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.6286\n",
      "Train Accuracy: 0.6371\n",
      "Train F1 (macro): 0.6370\n",
      "\n",
      "Val Loss: 0.6338\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6415\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.6265\n",
      "Train Accuracy: 0.6475\n",
      "Train F1 (macro): 0.6475\n",
      "\n",
      "Val Loss: 0.6332\n",
      "Val Accuracy: 0.6423\n",
      "Val F1 (macro): 0.6422\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.6251\n",
      "Train Accuracy: 0.6507\n",
      "Train F1 (macro): 0.6505\n",
      "\n",
      "Val Loss: 0.6356\n",
      "Val Accuracy: 0.6379\n",
      "Val F1 (macro): 0.6358\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.6272\n",
      "Train Accuracy: 0.6459\n",
      "Train F1 (macro): 0.6459\n",
      "\n",
      "Val Loss: 0.6496\n",
      "Val Accuracy: 0.6150\n",
      "Val F1 (macro): 0.5987\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.6246\n",
      "Train Accuracy: 0.6459\n",
      "Train F1 (macro): 0.6459\n",
      "\n",
      "Val Loss: 0.6385\n",
      "Val Accuracy: 0.6268\n",
      "Val F1 (macro): 0.6222\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.6234\n",
      "Train Accuracy: 0.6485\n",
      "Train F1 (macro): 0.6485\n",
      "\n",
      "Val Loss: 0.6339\n",
      "Val Accuracy: 0.6431\n",
      "Val F1 (macro): 0.6419\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.6223\n",
      "Train Accuracy: 0.6453\n",
      "Train F1 (macro): 0.6452\n",
      "\n",
      "Val Loss: 0.6341\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6344\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.6195\n",
      "Train Accuracy: 0.6500\n",
      "Train F1 (macro): 0.6500\n",
      "\n",
      "Val Loss: 0.6319\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6362\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.6143\n",
      "Train Accuracy: 0.6592\n",
      "Train F1 (macro): 0.6592\n",
      "\n",
      "Val Loss: 0.6318\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6369\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.6208\n",
      "Train Accuracy: 0.6462\n",
      "Train F1 (macro): 0.6462\n",
      "\n",
      "Val Loss: 0.6359\n",
      "Val Accuracy: 0.6320\n",
      "Val F1 (macro): 0.6293\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.6199\n",
      "Train Accuracy: 0.6507\n",
      "Train F1 (macro): 0.6506\n",
      "\n",
      "Val Loss: 0.6364\n",
      "Val Accuracy: 0.6335\n",
      "Val F1 (macro): 0.6306\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.6214\n",
      "Train Accuracy: 0.6450\n",
      "Train F1 (macro): 0.6450\n",
      "\n",
      "Val Loss: 0.6317\n",
      "Val Accuracy: 0.6394\n",
      "Val F1 (macro): 0.6394\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.6203\n",
      "Train Accuracy: 0.6507\n",
      "Train F1 (macro): 0.6507\n",
      "\n",
      "Val Loss: 0.6318\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6341\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.6167\n",
      "Train Accuracy: 0.6620\n",
      "Train F1 (macro): 0.6619\n",
      "\n",
      "Val Loss: 0.6361\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6340\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.6171\n",
      "Train Accuracy: 0.6503\n",
      "Train F1 (macro): 0.6503\n",
      "\n",
      "Val Loss: 0.6324\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6410\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.6110\n",
      "Train Accuracy: 0.6608\n",
      "Train F1 (macro): 0.6606\n",
      "\n",
      "Val Loss: 0.6342\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6383\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.6169\n",
      "Train Accuracy: 0.6608\n",
      "Train F1 (macro): 0.6608\n",
      "\n",
      "Val Loss: 0.6321\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6412\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.6189\n",
      "Train Accuracy: 0.6522\n",
      "Train F1 (macro): 0.6522\n",
      "\n",
      "Val Loss: 0.6333\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6392\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.6205\n",
      "Train Accuracy: 0.6529\n",
      "Train F1 (macro): 0.6529\n",
      "\n",
      "Val Loss: 0.6315\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6398\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.6137\n",
      "Train Accuracy: 0.6535\n",
      "Train F1 (macro): 0.6534\n",
      "\n",
      "Val Loss: 0.6326\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6396\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.6119\n",
      "Train Accuracy: 0.6541\n",
      "Train F1 (macro): 0.6541\n",
      "\n",
      "Val Loss: 0.6315\n",
      "Val Accuracy: 0.6409\n",
      "Val F1 (macro): 0.6405\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.6119\n",
      "Train Accuracy: 0.6573\n",
      "Train F1 (macro): 0.6573\n",
      "\n",
      "Val Loss: 0.6317\n",
      "Val Accuracy: 0.6409\n",
      "Val F1 (macro): 0.6402\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.6148\n",
      "Train Accuracy: 0.6538\n",
      "Train F1 (macro): 0.6538\n",
      "\n",
      "Val Loss: 0.6347\n",
      "Val Accuracy: 0.6342\n",
      "Val F1 (macro): 0.6315\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.6149\n",
      "Train Accuracy: 0.6567\n",
      "Train F1 (macro): 0.6566\n",
      "\n",
      "Val Loss: 0.6319\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6357\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.6175\n",
      "Train Accuracy: 0.6510\n",
      "Train F1 (macro): 0.6510\n",
      "\n",
      "Val Loss: 0.6312\n",
      "Val Accuracy: 0.6394\n",
      "Val F1 (macro): 0.6394\n",
      "\n",
      "\n",
      "Epoch 51\n",
      "Training Loss: 0.6090\n",
      "Train Accuracy: 0.6573\n",
      "Train F1 (macro): 0.6571\n",
      "\n",
      "Val Loss: 0.6307\n",
      "Val Accuracy: 0.6453\n",
      "Val F1 (macro): 0.6453\n",
      "\n",
      "\n",
      "Epoch 52\n",
      "Training Loss: 0.6072\n",
      "Train Accuracy: 0.6563\n",
      "Train F1 (macro): 0.6563\n",
      "\n",
      "Val Loss: 0.6303\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6395\n",
      "\n",
      "\n",
      "Epoch 53\n",
      "Training Loss: 0.6121\n",
      "Train Accuracy: 0.6598\n",
      "Train F1 (macro): 0.6597\n",
      "\n",
      "Val Loss: 0.6312\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6414\n",
      "\n",
      "\n",
      "Epoch 54\n",
      "Training Loss: 0.6070\n",
      "Train Accuracy: 0.6636\n",
      "Train F1 (macro): 0.6636\n",
      "\n",
      "Val Loss: 0.6342\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6343\n",
      "\n",
      "\n",
      "Epoch 55\n",
      "Training Loss: 0.6118\n",
      "Train Accuracy: 0.6522\n",
      "Train F1 (macro): 0.6522\n",
      "\n",
      "Val Loss: 0.6291\n",
      "Val Accuracy: 0.6468\n",
      "Val F1 (macro): 0.6465\n",
      "\n",
      "\n",
      "Epoch 56\n",
      "Training Loss: 0.6075\n",
      "Train Accuracy: 0.6611\n",
      "Train F1 (macro): 0.6611\n",
      "\n",
      "Val Loss: 0.6307\n",
      "Val Accuracy: 0.6409\n",
      "Val F1 (macro): 0.6407\n",
      "\n",
      "\n",
      "Epoch 57\n",
      "Training Loss: 0.6093\n",
      "Train Accuracy: 0.6601\n",
      "Train F1 (macro): 0.6601\n",
      "\n",
      "Val Loss: 0.6326\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6345\n",
      "\n",
      "\n",
      "Epoch 58\n",
      "Training Loss: 0.6098\n",
      "Train Accuracy: 0.6633\n",
      "Train F1 (macro): 0.6631\n",
      "\n",
      "Val Loss: 0.6338\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6323\n",
      "\n",
      "\n",
      "Epoch 59\n",
      "Training Loss: 0.6103\n",
      "Train Accuracy: 0.6652\n",
      "Train F1 (macro): 0.6652\n",
      "\n",
      "Val Loss: 0.6294\n",
      "Val Accuracy: 0.6490\n",
      "Val F1 (macro): 0.6487\n",
      "\n",
      "\n",
      "Epoch 60\n",
      "Training Loss: 0.6075\n",
      "Train Accuracy: 0.6573\n",
      "Train F1 (macro): 0.6573\n",
      "\n",
      "Val Loss: 0.6318\n",
      "Val Accuracy: 0.6379\n",
      "Val F1 (macro): 0.6372\n",
      "\n",
      "\n",
      "Epoch 61\n",
      "Training Loss: 0.6097\n",
      "Train Accuracy: 0.6601\n",
      "Train F1 (macro): 0.6601\n",
      "\n",
      "Val Loss: 0.6297\n",
      "Val Accuracy: 0.6475\n",
      "Val F1 (macro): 0.6474\n",
      "\n",
      "\n",
      "Epoch 62\n",
      "Training Loss: 0.6135\n",
      "Train Accuracy: 0.6605\n",
      "Train F1 (macro): 0.6604\n",
      "\n",
      "Val Loss: 0.6330\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6350\n",
      "\n",
      "\n",
      "Epoch 63\n",
      "Training Loss: 0.6062\n",
      "Train Accuracy: 0.6573\n",
      "Train F1 (macro): 0.6573\n",
      "\n",
      "Val Loss: 0.6320\n",
      "Val Accuracy: 0.6460\n",
      "Val F1 (macro): 0.6455\n",
      "\n",
      "\n",
      "Epoch 64\n",
      "Training Loss: 0.6078\n",
      "Train Accuracy: 0.6526\n",
      "Train F1 (macro): 0.6525\n",
      "\n",
      "Val Loss: 0.6330\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6367\n",
      "\n",
      "\n",
      "Epoch 65\n",
      "Training Loss: 0.6099\n",
      "Train Accuracy: 0.6541\n",
      "Train F1 (macro): 0.6541\n",
      "\n",
      "Val Loss: 0.6353\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6330\n",
      "\n",
      "\n",
      "Epoch 66\n",
      "Training Loss: 0.6066\n",
      "Train Accuracy: 0.6601\n",
      "Train F1 (macro): 0.6601\n",
      "\n",
      "Val Loss: 0.6316\n",
      "Val Accuracy: 0.6379\n",
      "Val F1 (macro): 0.6371\n",
      "\n",
      "\n",
      "Epoch 67\n",
      "Training Loss: 0.6084\n",
      "Train Accuracy: 0.6601\n",
      "Train F1 (macro): 0.6601\n",
      "\n",
      "Val Loss: 0.6309\n",
      "Val Accuracy: 0.6445\n",
      "Val F1 (macro): 0.6445\n",
      "\n",
      "\n",
      "Epoch 68\n",
      "Training Loss: 0.6130\n",
      "Train Accuracy: 0.6595\n",
      "Train F1 (macro): 0.6594\n",
      "\n",
      "Val Loss: 0.6299\n",
      "Val Accuracy: 0.6460\n",
      "Val F1 (macro): 0.6459\n",
      "\n",
      "\n",
      "Epoch 69\n",
      "Training Loss: 0.6061\n",
      "Train Accuracy: 0.6570\n",
      "Train F1 (macro): 0.6569\n",
      "\n",
      "Val Loss: 0.6350\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6332\n",
      "\n",
      "\n",
      "Epoch 70\n",
      "Training Loss: 0.6066\n",
      "Train Accuracy: 0.6595\n",
      "Train F1 (macro): 0.6594\n",
      "\n",
      "Val Loss: 0.6306\n",
      "Val Accuracy: 0.6482\n",
      "Val F1 (macro): 0.6482\n",
      "\n",
      "\n",
      "Epoch 71\n",
      "Training Loss: 0.6053\n",
      "Train Accuracy: 0.6557\n",
      "Train F1 (macro): 0.6557\n",
      "\n",
      "Val Loss: 0.6310\n",
      "Val Accuracy: 0.6320\n",
      "Val F1 (macro): 0.6306\n",
      "\n",
      "\n",
      "Epoch 72\n",
      "Training Loss: 0.6005\n",
      "Train Accuracy: 0.6725\n",
      "Train F1 (macro): 0.6723\n",
      "\n",
      "Val Loss: 0.6365\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6319\n",
      "\n",
      "\n",
      "Epoch 73\n",
      "Training Loss: 0.6063\n",
      "Train Accuracy: 0.6655\n",
      "Train F1 (macro): 0.6654\n",
      "\n",
      "Val Loss: 0.6333\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6354\n",
      "\n",
      "\n",
      "Epoch 74\n",
      "Training Loss: 0.6053\n",
      "Train Accuracy: 0.6560\n",
      "Train F1 (macro): 0.6560\n",
      "\n",
      "Val Loss: 0.6312\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6381\n",
      "\n",
      "\n",
      "Epoch 75\n",
      "Training Loss: 0.6056\n",
      "Train Accuracy: 0.6633\n",
      "Train F1 (macro): 0.6633\n",
      "\n",
      "Val Loss: 0.6425\n",
      "Val Accuracy: 0.6165\n",
      "Val F1 (macro): 0.6082\n",
      "\n",
      "\n",
      "Epoch 76\n",
      "Training Loss: 0.6026\n",
      "Train Accuracy: 0.6614\n",
      "Train F1 (macro): 0.6614\n",
      "\n",
      "Val Loss: 0.6297\n",
      "Val Accuracy: 0.6460\n",
      "Val F1 (macro): 0.6460\n",
      "\n",
      "\n",
      "Epoch 77\n",
      "Training Loss: 0.6011\n",
      "Train Accuracy: 0.6595\n",
      "Train F1 (macro): 0.6595\n",
      "\n",
      "Val Loss: 0.6337\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6338\n",
      "\n",
      "\n",
      "Epoch 78\n",
      "Training Loss: 0.6011\n",
      "Train Accuracy: 0.6671\n",
      "Train F1 (macro): 0.6671\n",
      "\n",
      "Val Loss: 0.6320\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6343\n",
      "\n",
      "\n",
      "Epoch 79\n",
      "Training Loss: 0.6028\n",
      "Train Accuracy: 0.6605\n",
      "Train F1 (macro): 0.6604\n",
      "\n",
      "Val Loss: 0.6324\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6335\n",
      "\n",
      "\n",
      "Epoch 80\n",
      "Training Loss: 0.6056\n",
      "Train Accuracy: 0.6601\n",
      "Train F1 (macro): 0.6601\n",
      "\n",
      "Val Loss: 0.6311\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6393\n",
      "\n",
      "\n",
      "Epoch 81\n",
      "Training Loss: 0.5985\n",
      "Train Accuracy: 0.6668\n",
      "Train F1 (macro): 0.6668\n",
      "\n",
      "Val Loss: 0.6315\n",
      "Val Accuracy: 0.6386\n",
      "Val F1 (macro): 0.6383\n",
      "\n",
      "\n",
      "Epoch 82\n",
      "Training Loss: 0.5973\n",
      "Train Accuracy: 0.6636\n",
      "Train F1 (macro): 0.6636\n",
      "\n",
      "Val Loss: 0.6300\n",
      "Val Accuracy: 0.6431\n",
      "Val F1 (macro): 0.6429\n",
      "\n",
      "\n",
      "Epoch 83\n",
      "Training Loss: 0.6017\n",
      "Train Accuracy: 0.6627\n",
      "Train F1 (macro): 0.6627\n",
      "\n",
      "Val Loss: 0.6302\n",
      "Val Accuracy: 0.6394\n",
      "Val F1 (macro): 0.6393\n",
      "\n",
      "\n",
      "Epoch 84\n",
      "Training Loss: 0.5968\n",
      "Train Accuracy: 0.6623\n",
      "Train F1 (macro): 0.6622\n",
      "\n",
      "Val Loss: 0.6323\n",
      "Val Accuracy: 0.6453\n",
      "Val F1 (macro): 0.6453\n",
      "\n",
      "\n",
      "Epoch 85\n",
      "Training Loss: 0.5988\n",
      "Train Accuracy: 0.6652\n",
      "Train F1 (macro): 0.6651\n",
      "\n",
      "Val Loss: 0.6326\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6401\n",
      "\n",
      "\n",
      "Epoch 86\n",
      "Training Loss: 0.5967\n",
      "Train Accuracy: 0.6744\n",
      "Train F1 (macro): 0.6743\n",
      "\n",
      "Val Loss: 0.6350\n",
      "Val Accuracy: 0.6180\n",
      "Val F1 (macro): 0.6138\n",
      "\n",
      "\n",
      "Epoch 87\n",
      "Training Loss: 0.5989\n",
      "Train Accuracy: 0.6671\n",
      "Train F1 (macro): 0.6671\n",
      "\n",
      "Val Loss: 0.6304\n",
      "Val Accuracy: 0.6394\n",
      "Val F1 (macro): 0.6393\n",
      "\n",
      "\n",
      "Epoch 88\n",
      "Training Loss: 0.5986\n",
      "Train Accuracy: 0.6655\n",
      "Train F1 (macro): 0.6655\n",
      "\n",
      "Val Loss: 0.6315\n",
      "Val Accuracy: 0.6386\n",
      "Val F1 (macro): 0.6385\n",
      "\n",
      "\n",
      "Epoch 89\n",
      "Training Loss: 0.6018\n",
      "Train Accuracy: 0.6598\n",
      "Train F1 (macro): 0.6598\n",
      "\n",
      "Val Loss: 0.6298\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6364\n",
      "\n",
      "\n",
      "Epoch 90\n",
      "Training Loss: 0.5945\n",
      "Train Accuracy: 0.6699\n",
      "Train F1 (macro): 0.6699\n",
      "\n",
      "Val Loss: 0.6306\n",
      "Val Accuracy: 0.6416\n",
      "Val F1 (macro): 0.6416\n",
      "\n",
      "\n",
      "Epoch 91\n",
      "Training Loss: 0.5997\n",
      "Train Accuracy: 0.6652\n",
      "Train F1 (macro): 0.6651\n",
      "\n",
      "Val Loss: 0.6332\n",
      "Val Accuracy: 0.6445\n",
      "Val F1 (macro): 0.6444\n",
      "\n",
      "\n",
      "Epoch 92\n",
      "Training Loss: 0.5977\n",
      "Train Accuracy: 0.6595\n",
      "Train F1 (macro): 0.6594\n",
      "\n",
      "Val Loss: 0.6297\n",
      "Val Accuracy: 0.6409\n",
      "Val F1 (macro): 0.6405\n",
      "\n",
      "\n",
      "Epoch 93\n",
      "Training Loss: 0.5998\n",
      "Train Accuracy: 0.6614\n",
      "Train F1 (macro): 0.6614\n",
      "\n",
      "Val Loss: 0.6401\n",
      "Val Accuracy: 0.6158\n",
      "Val F1 (macro): 0.6083\n",
      "\n",
      "\n",
      "Epoch 94\n",
      "Training Loss: 0.6021\n",
      "Train Accuracy: 0.6684\n",
      "Train F1 (macro): 0.6682\n",
      "\n",
      "Val Loss: 0.6315\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6358\n",
      "\n",
      "\n",
      "Epoch 95\n",
      "Training Loss: 0.5959\n",
      "Train Accuracy: 0.6747\n",
      "Train F1 (macro): 0.6744\n",
      "\n",
      "Val Loss: 0.6493\n",
      "Val Accuracy: 0.6084\n",
      "Val F1 (macro): 0.5967\n",
      "\n",
      "\n",
      "Epoch 96\n",
      "Training Loss: 0.5983\n",
      "Train Accuracy: 0.6737\n",
      "Train F1 (macro): 0.6737\n",
      "\n",
      "Val Loss: 0.6394\n",
      "Val Accuracy: 0.6217\n",
      "Val F1 (macro): 0.6181\n",
      "\n",
      "\n",
      "Epoch 97\n",
      "Training Loss: 0.6005\n",
      "Train Accuracy: 0.6605\n",
      "Train F1 (macro): 0.6604\n",
      "\n",
      "Val Loss: 0.6287\n",
      "Val Accuracy: 0.6335\n",
      "Val F1 (macro): 0.6334\n",
      "\n",
      "\n",
      "Epoch 98\n",
      "Training Loss: 0.5968\n",
      "Train Accuracy: 0.6617\n",
      "Train F1 (macro): 0.6617\n",
      "\n",
      "Val Loss: 0.6323\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6361\n",
      "\n",
      "\n",
      "Epoch 99\n",
      "Training Loss: 0.5984\n",
      "Train Accuracy: 0.6642\n",
      "Train F1 (macro): 0.6642\n",
      "\n",
      "Val Loss: 0.6301\n",
      "Val Accuracy: 0.6357\n",
      "Val F1 (macro): 0.6351\n",
      "\n",
      "\n",
      "Epoch 100\n",
      "Training Loss: 0.5953\n",
      "Train Accuracy: 0.6649\n",
      "Train F1 (macro): 0.6649\n",
      "\n",
      "Val Loss: 0.6313\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, device, class_weights_tensor, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4b0a",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c821845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5856\n",
      "Test Accuracy: 0.7378\n",
      "Test F1 (macro): 0.7358\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▆▇▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇█▇████</td></tr><tr><td>train_f1_macro</td><td>▁▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█▇██▇▇▇▇███</td></tr><tr><td>train_f1_weighted</td><td>▁▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇██▇██▇</td></tr><tr><td>train_loss</td><td>▅▄▄▂▄▄▃▅▆▅▄▄▄▃▄▄▄▆▅▄█▇▃▃▇▄▆▆▄▄▃▃▅▂▃▄▁▃▄▅</td></tr><tr><td>train_precision_macro</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇██████▇▇█▇█</td></tr><tr><td>train_recall_macro</td><td>▁▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇██▇▇███</td></tr><tr><td>val_accuracy</td><td>▁▂▅▅▆█▇█▇▅▇▇▆▃▆▆▇▇▇▇▇▇▆▆▆▇▆▇▆▅▆▃▆▆▃▇▃▂▄▆</td></tr><tr><td>val_f1_macro</td><td>▁▆▇▆▇████████▇█████████████████████▇█▇▇█</td></tr><tr><td>val_f1_weighted</td><td>▁▅▃▄▆█▇▇▇█▇▄▇▇▇▇▇▇▇██▇▇▇█▇▇█▇▇▅▇▇▇█▇▅▆▇▇</td></tr><tr><td>val_loss</td><td>█▆▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▃▂▁</td></tr><tr><td>val_precision_macro</td><td>▇▁▃▅▅█▇▇▇▇▄▄▅▅▅▆▆▆▆▆▆▇▆█▆▆█▅▇▆▇█▅▅▆▆▇▇▂▅</td></tr><tr><td>val_recall_macro</td><td>▁▄▅▆▆█▇█▇▇▄▆▇▇▇▇▇▇▇▇▇▆▇▇█▇██▆▇▇▇▇▇█▅▇▇▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>test_accuracy</td><td>0.73785</td></tr><tr><td>test_f1_macro</td><td>0.73578</td></tr><tr><td>test_f1_weighted</td><td>0.73578</td></tr><tr><td>test_loss</td><td>0.58559</td></tr><tr><td>test_precision_macro</td><td>0.74555</td></tr><tr><td>test_recall_macro</td><td>0.73785</td></tr><tr><td>train_accuracy</td><td>0.66488</td></tr><tr><td>train_f1_macro</td><td>0.66486</td></tr><tr><td>train_f1_weighted</td><td>0.66486</td></tr><tr><td>train_loss</td><td>0.57778</td></tr><tr><td>train_precision_macro</td><td>0.6649</td></tr><tr><td>train_recall_macro</td><td>0.66488</td></tr><tr><td>val_accuracy</td><td>0.63717</td></tr><tr><td>val_f1_macro</td><td>0.63563</td></tr><tr><td>val_f1_weighted</td><td>0.63563</td></tr><tr><td>val_loss</td><td>0.63133</td></tr><tr><td>val_precision_macro</td><td>0.63952</td></tr><tr><td>val_recall_macro</td><td>0.63717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-glade-25</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/djxm8big' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/djxm8big</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250513_122349-djxm8big/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7357758031442242, 'accuracy': 0.7378472222222222}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_model.pt\", weights_only=True))\n",
    "# Test model on test set\n",
    "test_model(model, test_loader, device, class_weights_tensor, phase = \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
