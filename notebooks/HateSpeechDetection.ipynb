{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e76a0e7-e90e-457e-8dc4-81cc472f2f1e",
   "metadata": {},
   "source": [
    "The goal of this project is to use the pretrained RoBERTa transformer as a feature extractor with a costum classification head to determine if text messages are offensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbb6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "from paths import DATA_CLEANED\n",
    "from paths import DATA_PROCESSED\n",
    "\n",
    "from helper_functions import train_model\n",
    "from helper_functions import test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040a974",
   "metadata": {},
   "source": [
    "## Using RoBERTa as a feature extractor with a costum classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4da52",
   "metadata": {},
   "source": [
    "Found this pretrained model online: cardiffnlp/twitter-roberta-base-sentiment-latest (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "It is already pretrained on twitter messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d5297-ec56-4954-91d1-7b650e5b16f0",
   "metadata": {},
   "source": [
    "Define experiment scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad28b13-1a6b-4331-bc4b-37b863df796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using the labels of the first task of the HASOC dataset, which is a binary classification\n",
    "label = \"task_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc731c7",
   "metadata": {},
   "source": [
    "Define which pretrained model is used and initilise tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20ed5c",
   "metadata": {},
   "source": [
    "Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, model_name, pooling='cls'):\n",
    "        super().__init__()\n",
    "        self.pooling = pooling.lower()\n",
    "        self.base = AutoModel.from_pretrained(model_name)\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_size = config.hidden_size  # Dynamically get the model's hidden size\n",
    "\n",
    "        \n",
    "        print(hidden_size)\n",
    "        \n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Custom classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Pooling strategy: either CLS token or mean pooling over token embeddings\n",
    "        if self.pooling == 'mean':\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "            sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1).clamp(min=1e-9)\n",
    "            pooled = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            pooled = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        # If labels are provided, calculate the loss\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb86e8",
   "metadata": {},
   "source": [
    "## Load HASOC dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f76fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "clean_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_train_cleaned.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_PROCESSED / \"hasoc_2019_en_test.tsv\", sep='\\t')\n",
    "\n",
    "# Split clean dataset in training and validation set\n",
    "train_df, val_df = train_test_split(clean_df, test_size=0.3, random_state=42, stratify=clean_df[label])\n",
    "\n",
    "# Automatically map string labels to integers\n",
    "label_list = sorted(train_df[label].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "train_df[label] = train_df[label].map(label_map)\n",
    "val_df[label] = val_df[label].map(label_map)\n",
    "test_df[label] = test_df[label].map(label_map)\n",
    "\n",
    "# Custom Dataset Class\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, label = 'label', max_len=128):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[label].tolist()\n",
    "        self.encodings = tokenizer(self.texts, padding=True, truncation=True, max_length=max_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create PyTorch Datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(train_df, tokenizer, label=label)\n",
    "val_dataset = HateSpeechDataset(val_df, tokenizer, label=label)\n",
    "test_dataset = HateSpeechDataset(test_df, tokenizer, label=label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd402e6",
   "metadata": {},
   "source": [
    "## Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456ec3ec-d7e1-47ad-a9f1-57dac6011ebd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 17:27:53.302279: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 17:27:53.318066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746804473.337081   35336 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746804473.343054   35336 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746804473.357381   35336 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804473.357396   35336 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804473.357397   35336 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804473.357399   35336 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-09 17:27:53.362521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = CustomClassifier(model_name, pooling=\"cls\").to(device)\n",
    "\n",
    "# Optimizer only for the classification head\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=2e-4)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5445349-d36a-4138-bc0f-f2dd004fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250509_172756-pn9x3qo0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/pn9x3qo0' target=\"_blank\">snowy-microwave-14</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/pn9x3qo0' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/pn9x3qo0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/pn9x3qo0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7eff19e4ea10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"roberta-classifier\", config={\n",
    "    \"model\": model_name,\n",
    "    \"pooling\": \"cls\",\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": 2e-4,\n",
    "    \"frozen_base\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781a9824-c9d1-44a9-ae3a-70399e220e96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6681\n",
      "Train Accuracy: 0.6074\n",
      "Train F1 (macro): 0.3964\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6584\n",
      "Val Accuracy: 0.6139\n",
      "Val F1 (macro): 0.3804\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6569\n",
      "Train Accuracy: 0.6150\n",
      "Train F1 (macro): 0.4160\n",
      "\n",
      "Val Loss: 0.6510\n",
      "Val Accuracy: 0.6253\n",
      "Val F1 (macro): 0.4411\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6458\n",
      "Train Accuracy: 0.6233\n",
      "Train F1 (macro): 0.4527\n",
      "\n",
      "Val Loss: 0.6414\n",
      "Val Accuracy: 0.6247\n",
      "Val F1 (macro): 0.4261\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.6392\n",
      "Train Accuracy: 0.6272\n",
      "Train F1 (macro): 0.4687\n",
      "\n",
      "Val Loss: 0.6355\n",
      "Val Accuracy: 0.6543\n",
      "Val F1 (macro): 0.5456\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.6386\n",
      "Train Accuracy: 0.6362\n",
      "Train F1 (macro): 0.5024\n",
      "\n",
      "Val Loss: 0.6340\n",
      "Val Accuracy: 0.6629\n",
      "Val F1 (macro): 0.5938\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.6281\n",
      "Train Accuracy: 0.6531\n",
      "Train F1 (macro): 0.5460\n",
      "\n",
      "Val Loss: 0.6282\n",
      "Val Accuracy: 0.6663\n",
      "Val F1 (macro): 0.6024\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.6271\n",
      "Train Accuracy: 0.6492\n",
      "Train F1 (macro): 0.5457\n",
      "\n",
      "Val Loss: 0.6239\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.5077\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.6222\n",
      "Train Accuracy: 0.6553\n",
      "Train F1 (macro): 0.5655\n",
      "\n",
      "Val Loss: 0.6209\n",
      "Val Accuracy: 0.6640\n",
      "Val F1 (macro): 0.5992\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.6183\n",
      "Train Accuracy: 0.6543\n",
      "Train F1 (macro): 0.5697\n",
      "\n",
      "Val Loss: 0.6178\n",
      "Val Accuracy: 0.6680\n",
      "Val F1 (macro): 0.6108\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.6179\n",
      "Train Accuracy: 0.6663\n",
      "Train F1 (macro): 0.5992\n",
      "\n",
      "Val Loss: 0.6162\n",
      "Val Accuracy: 0.6612\n",
      "Val F1 (macro): 0.5634\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.6164\n",
      "Train Accuracy: 0.6614\n",
      "Train F1 (macro): 0.5910\n",
      "\n",
      "Val Loss: 0.6157\n",
      "Val Accuracy: 0.6686\n",
      "Val F1 (macro): 0.6286\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.6154\n",
      "Train Accuracy: 0.6643\n",
      "Train F1 (macro): 0.6007\n",
      "\n",
      "Val Loss: 0.6149\n",
      "Val Accuracy: 0.6720\n",
      "Val F1 (macro): 0.6343\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.6102\n",
      "Train Accuracy: 0.6670\n",
      "Train F1 (macro): 0.6052\n",
      "\n",
      "Val Loss: 0.6118\n",
      "Val Accuracy: 0.6691\n",
      "Val F1 (macro): 0.5989\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.6076\n",
      "Train Accuracy: 0.6716\n",
      "Train F1 (macro): 0.6170\n",
      "\n",
      "Val Loss: 0.6162\n",
      "Val Accuracy: 0.6669\n",
      "Val F1 (macro): 0.6378\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.6068\n",
      "Train Accuracy: 0.6758\n",
      "Train F1 (macro): 0.6206\n",
      "\n",
      "Val Loss: 0.6142\n",
      "Val Accuracy: 0.6606\n",
      "Val F1 (macro): 0.5653\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.6042\n",
      "Train Accuracy: 0.6697\n",
      "Train F1 (macro): 0.6108\n",
      "\n",
      "Val Loss: 0.6117\n",
      "Val Accuracy: 0.6697\n",
      "Val F1 (macro): 0.6377\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.6063\n",
      "Train Accuracy: 0.6711\n",
      "Train F1 (macro): 0.6187\n",
      "\n",
      "Val Loss: 0.6121\n",
      "Val Accuracy: 0.6708\n",
      "Val F1 (macro): 0.6397\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.6083\n",
      "Train Accuracy: 0.6731\n",
      "Train F1 (macro): 0.6198\n",
      "\n",
      "Val Loss: 0.6087\n",
      "Val Accuracy: 0.6754\n",
      "Val F1 (macro): 0.6165\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.6035\n",
      "Train Accuracy: 0.6831\n",
      "Train F1 (macro): 0.6319\n",
      "\n",
      "Val Loss: 0.6077\n",
      "Val Accuracy: 0.6743\n",
      "Val F1 (macro): 0.6168\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.6053\n",
      "Train Accuracy: 0.6672\n",
      "Train F1 (macro): 0.6147\n",
      "\n",
      "Val Loss: 0.6087\n",
      "Val Accuracy: 0.6748\n",
      "Val F1 (macro): 0.6434\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.6030\n",
      "Train Accuracy: 0.6802\n",
      "Train F1 (macro): 0.6333\n",
      "\n",
      "Val Loss: 0.6120\n",
      "Val Accuracy: 0.6743\n",
      "Val F1 (macro): 0.6494\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.6054\n",
      "Train Accuracy: 0.6626\n",
      "Train F1 (macro): 0.6130\n",
      "\n",
      "Val Loss: 0.6075\n",
      "Val Accuracy: 0.6760\n",
      "Val F1 (macro): 0.6343\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.6007\n",
      "Train Accuracy: 0.6760\n",
      "Train F1 (macro): 0.6261\n",
      "\n",
      "Val Loss: 0.6080\n",
      "Val Accuracy: 0.6800\n",
      "Val F1 (macro): 0.6463\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.6015\n",
      "Train Accuracy: 0.6772\n",
      "Train F1 (macro): 0.6294\n",
      "\n",
      "Val Loss: 0.6082\n",
      "Val Accuracy: 0.6748\n",
      "Val F1 (macro): 0.6364\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.6016\n",
      "Train Accuracy: 0.6758\n",
      "Train F1 (macro): 0.6305\n",
      "\n",
      "Val Loss: 0.6068\n",
      "Val Accuracy: 0.6760\n",
      "Val F1 (macro): 0.6293\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.6033\n",
      "Train Accuracy: 0.6721\n",
      "Train F1 (macro): 0.6237\n",
      "\n",
      "Val Loss: 0.6108\n",
      "Val Accuracy: 0.6714\n",
      "Val F1 (macro): 0.5899\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.5997\n",
      "Train Accuracy: 0.6790\n",
      "Train F1 (macro): 0.6299\n",
      "\n",
      "Val Loss: 0.6062\n",
      "Val Accuracy: 0.6805\n",
      "Val F1 (macro): 0.6442\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.5992\n",
      "Train Accuracy: 0.6833\n",
      "Train F1 (macro): 0.6365\n",
      "\n",
      "Val Loss: 0.6088\n",
      "Val Accuracy: 0.6697\n",
      "Val F1 (macro): 0.6421\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.6019\n",
      "Train Accuracy: 0.6743\n",
      "Train F1 (macro): 0.6253\n",
      "\n",
      "Val Loss: 0.6060\n",
      "Val Accuracy: 0.6805\n",
      "Val F1 (macro): 0.6425\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.5973\n",
      "Train Accuracy: 0.6833\n",
      "Train F1 (macro): 0.6351\n",
      "\n",
      "Val Loss: 0.6065\n",
      "Val Accuracy: 0.6760\n",
      "Val F1 (macro): 0.6403\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.5954\n",
      "Train Accuracy: 0.6855\n",
      "Train F1 (macro): 0.6404\n",
      "\n",
      "Val Loss: 0.6060\n",
      "Val Accuracy: 0.6805\n",
      "Val F1 (macro): 0.6445\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.5961\n",
      "Train Accuracy: 0.6802\n",
      "Train F1 (macro): 0.6355\n",
      "\n",
      "Val Loss: 0.6075\n",
      "Val Accuracy: 0.6731\n",
      "Val F1 (macro): 0.6075\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.6024\n",
      "Train Accuracy: 0.6777\n",
      "Train F1 (macro): 0.6331\n",
      "\n",
      "Val Loss: 0.6055\n",
      "Val Accuracy: 0.6800\n",
      "Val F1 (macro): 0.6350\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.5975\n",
      "Train Accuracy: 0.6846\n",
      "Train F1 (macro): 0.6371\n",
      "\n",
      "Val Loss: 0.6076\n",
      "Val Accuracy: 0.6731\n",
      "Val F1 (macro): 0.6453\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.5952\n",
      "Train Accuracy: 0.6760\n",
      "Train F1 (macro): 0.6295\n",
      "\n",
      "Val Loss: 0.6111\n",
      "Val Accuracy: 0.6708\n",
      "Val F1 (macro): 0.6490\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.5974\n",
      "Train Accuracy: 0.6812\n",
      "Train F1 (macro): 0.6356\n",
      "\n",
      "Val Loss: 0.6093\n",
      "Val Accuracy: 0.6737\n",
      "Val F1 (macro): 0.5958\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.5991\n",
      "Train Accuracy: 0.6807\n",
      "Train F1 (macro): 0.6369\n",
      "\n",
      "Val Loss: 0.6061\n",
      "Val Accuracy: 0.6760\n",
      "Val F1 (macro): 0.6174\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.5888\n",
      "Train Accuracy: 0.6887\n",
      "Train F1 (macro): 0.6453\n",
      "\n",
      "Val Loss: 0.6063\n",
      "Val Accuracy: 0.6737\n",
      "Val F1 (macro): 0.6131\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.5933\n",
      "Train Accuracy: 0.6802\n",
      "Train F1 (macro): 0.6352\n",
      "\n",
      "Val Loss: 0.6084\n",
      "Val Accuracy: 0.6714\n",
      "Val F1 (macro): 0.6471\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.5917\n",
      "Train Accuracy: 0.6831\n",
      "Train F1 (macro): 0.6370\n",
      "\n",
      "Val Loss: 0.6047\n",
      "Val Accuracy: 0.6811\n",
      "Val F1 (macro): 0.6370\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.5932\n",
      "Train Accuracy: 0.6763\n",
      "Train F1 (macro): 0.6313\n",
      "\n",
      "Val Loss: 0.6072\n",
      "Val Accuracy: 0.6737\n",
      "Val F1 (macro): 0.6048\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.5881\n",
      "Train Accuracy: 0.6846\n",
      "Train F1 (macro): 0.6395\n",
      "\n",
      "Val Loss: 0.6061\n",
      "Val Accuracy: 0.6782\n",
      "Val F1 (macro): 0.6205\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.5917\n",
      "Train Accuracy: 0.6860\n",
      "Train F1 (macro): 0.6446\n",
      "\n",
      "Val Loss: 0.6051\n",
      "Val Accuracy: 0.6777\n",
      "Val F1 (macro): 0.6394\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.5927\n",
      "Train Accuracy: 0.6819\n",
      "Train F1 (macro): 0.6401\n",
      "\n",
      "Val Loss: 0.6041\n",
      "Val Accuracy: 0.6811\n",
      "Val F1 (macro): 0.6393\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.5905\n",
      "Train Accuracy: 0.6765\n",
      "Train F1 (macro): 0.6323\n",
      "\n",
      "Val Loss: 0.6044\n",
      "Val Accuracy: 0.6788\n",
      "Val F1 (macro): 0.6264\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.5930\n",
      "Train Accuracy: 0.6768\n",
      "Train F1 (macro): 0.6300\n",
      "\n",
      "Val Loss: 0.6076\n",
      "Val Accuracy: 0.6754\n",
      "Val F1 (macro): 0.6423\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.5918\n",
      "Train Accuracy: 0.6897\n",
      "Train F1 (macro): 0.6461\n",
      "\n",
      "Val Loss: 0.6079\n",
      "Val Accuracy: 0.6737\n",
      "Val F1 (macro): 0.6495\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.5915\n",
      "Train Accuracy: 0.6802\n",
      "Train F1 (macro): 0.6377\n",
      "\n",
      "Val Loss: 0.6046\n",
      "Val Accuracy: 0.6765\n",
      "Val F1 (macro): 0.6146\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.5956\n",
      "Train Accuracy: 0.6858\n",
      "Train F1 (macro): 0.6433\n",
      "\n",
      "Val Loss: 0.6030\n",
      "Val Accuracy: 0.6737\n",
      "Val F1 (macro): 0.6191\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.5880\n",
      "Train Accuracy: 0.6924\n",
      "Train F1 (macro): 0.6510\n",
      "\n",
      "Val Loss: 0.6044\n",
      "Val Accuracy: 0.6782\n",
      "Val F1 (macro): 0.6459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4b0a",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c821845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4985\n",
      "Test Accuracy: 0.7875\n",
      "Test F1 (macro): 0.7128\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▂▃▃▅▅▆▅▆▆▇▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>train_f1_macro</td><td>▁▂▃▃▄▅▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇█▇████▇██▇██▇▇███</td></tr><tr><td>train_f1_weighted</td><td>▁▂▃▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇████▇██▇▇███</td></tr><tr><td>train_loss</td><td>▅▄▆▅▆▃▆▄▅▆▅▃▅▃▅█▂▄▂▇▂▃▄▄▆▄▄▄▂▆▃▁▆▅▂▁▅▁▅▃</td></tr><tr><td>train_precision_macro</td><td>▁▃▄▅▆▆▆▆▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>train_recall_macro</td><td>▁▁▂▂▃▅▅▆▆▆▇▇▆▇▇▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██▇▇█▇█</td></tr><tr><td>val_accuracy</td><td>▁▂▂▅▆▄▆▇▆▇▇▇▆▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇█▇███▇▇██</td></tr><tr><td>val_f1_macro</td><td>▁▃▂▅▇▄▇▇▆▇█▆██▇████▇████████▇▇██▇▇█▇██▇█</td></tr><tr><td>val_f1_weighted</td><td>▁▃▂▅▇▄▇▇▆▇▇███▇█████▇████▇██▇▇██▇▇████▇█</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision_macro</td><td>▁▇████████▇█████████████████████████████</td></tr><tr><td>val_recall_macro</td><td>▁▂▂▄▆▄▆▆▅▇▆▇▅▇▇▇█▇█▇▆████▆▇██▆▆█▇▆▇▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>test_accuracy</td><td>0.78751</td></tr><tr><td>test_f1_macro</td><td>0.71282</td></tr><tr><td>test_f1_weighted</td><td>0.78611</td></tr><tr><td>test_loss</td><td>0.4985</td></tr><tr><td>test_precision_macro</td><td>0.71575</td></tr><tr><td>test_recall_macro</td><td>0.71015</td></tr><tr><td>train_accuracy</td><td>0.69238</td></tr><tr><td>train_f1_macro</td><td>0.65103</td></tr><tr><td>train_f1_weighted</td><td>0.67831</td></tr><tr><td>train_loss</td><td>0.54682</td></tr><tr><td>train_precision_macro</td><td>0.67787</td></tr><tr><td>train_recall_macro</td><td>0.64761</td></tr><tr><td>val_accuracy</td><td>0.67825</td></tr><tr><td>val_f1_macro</td><td>0.64586</td></tr><tr><td>val_f1_weighted</td><td>0.67026</td></tr><tr><td>val_loss</td><td>0.60444</td></tr><tr><td>val_precision_macro</td><td>0.65772</td></tr><tr><td>val_recall_macro</td><td>0.64271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">snowy-microwave-14</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/pn9x3qo0' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/pn9x3qo0</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250509_172756-pn9x3qo0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(model, test_loader, device, phase = \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
