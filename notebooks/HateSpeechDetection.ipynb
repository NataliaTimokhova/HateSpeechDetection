{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e76a0e7-e90e-457e-8dc4-81cc472f2f1e",
   "metadata": {},
   "source": [
    "The goal of this project is to use the pretrained RoBERTa transformer as a feature extractor with a costum classification head to determine if text messages are offensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbb6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "from paths import DATA_CLEANED\n",
    "from paths import DATA_PROCESSED\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper_functions import get_class_distribution, oversample_dataset\n",
    "from helper_functions import train_model\n",
    "from helper_functions import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f24224-26ee-49a1-adf0-48e3e6d38544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040a974",
   "metadata": {},
   "source": [
    "## Using RoBERTa as a feature extractor with a costum classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4da52",
   "metadata": {},
   "source": [
    "Found this pretrained model online: cardiffnlp/twitter-roberta-base-sentiment-latest (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "It is already pretrained on twitter messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc731c7",
   "metadata": {},
   "source": [
    "Define which pretrained model is used and initilise tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20ed5c",
   "metadata": {},
   "source": [
    "Classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "197cc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, model_name, pooling='cls'):\n",
    "        super().__init__()\n",
    "        self.pooling = pooling.lower()\n",
    "        self.base = AutoModel.from_pretrained(model_name)\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_size = config.hidden_size  # Dynamically get the model's hidden size\n",
    "\n",
    "        \n",
    "        print(hidden_size)\n",
    "        \n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Custom classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, class_weights_tensor = None, labels=None):\n",
    "        outputs = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Pooling strategy: either CLS token or mean pooling over token embeddings\n",
    "        if self.pooling == 'mean':\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "            sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1).clamp(min=1e-9)\n",
    "            pooled = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            pooled = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        # If labels are provided, calculate the loss\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return logits, loss\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb86e8",
   "metadata": {},
   "source": [
    "## Load HASOC dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f133729a-b5db-4e99-809d-12a6ba529ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, label = 'label', max_len=128):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[label].tolist()\n",
    "        self.encodings = tokenizer(self.texts, padding=True, truncation=True, max_length=max_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181465c-ef90-409f-9cb4-39f7db6f2e93",
   "metadata": {},
   "source": [
    "Define experiment scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "479a3f53-d232-42b2-8dd3-169bce3efd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using the labels of the first task of the HASOC dataset, which is a binary classification\n",
    "label = \"task_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f76fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2513, 0: 2513}\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "clean_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_train_cleaned.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_PROCESSED / \"hasoc_2019_en_test.tsv\", sep='\\t')\n",
    "\n",
    "# Split clean dataset in training and validation set\n",
    "train_df, val_df = train_test_split(clean_df, test_size=0.3, random_state=42, stratify=clean_df[label])\n",
    "\n",
    "# Automatically map string labels to integers\n",
    "label_list = sorted(train_df[label].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "train_df[label] = train_df[label].map(label_map)\n",
    "val_df[label] = val_df[label].map(label_map)\n",
    "test_df[label] = test_df[label].map(label_map)\n",
    "\n",
    "# Oversample dataset\n",
    "os_train_df = oversample_dataset(train_df, label)\n",
    "os_val_df = oversample_dataset(val_df, label)\n",
    "os_test_df = oversample_dataset(test_df, label)\n",
    "\n",
    "# Create PyTorch Datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(os_train_df, tokenizer, label=label)\n",
    "val_dataset = HateSpeechDataset(os_val_df, tokenizer, label=label)\n",
    "test_dataset = HateSpeechDataset(os_test_df, tokenizer, label=label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(get_class_distribution(os_train_df, label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "197592e6-249f-4274-97a2-ca3625e089f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(os_train_df[label]),\n",
    "    y=os_train_df[label]\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd402e6",
   "metadata": {},
   "source": [
    "## Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "456ec3ec-d7e1-47ad-a9f1-57dac6011ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = CustomClassifier(model_name, pooling=\"cls\").to(device)\n",
    "\n",
    "# Optimizer only for the classification head\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=2e-4)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5445349-d36a-4138-bc0f-f2dd004fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250512_161108-mckgqjp6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mckgqjp6' target=\"_blank\">skilled-darkness-20</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mckgqjp6' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mckgqjp6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mckgqjp6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0042327c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"roberta-classifier\", config={\n",
    "    \"model\": model_name,\n",
    "    \"pooling\": \"cls\",\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": 2e-4,\n",
    "    \"frozen_base\": True,\n",
    "    \"weighted_classes\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "781a9824-c9d1-44a9-ae3a-70399e220e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6889\n",
      "Train Accuracy: 0.5470\n",
      "Train F1 (macro): 0.5467\n",
      "\n",
      "Val Loss: 0.6818\n",
      "Val Accuracy: 0.5872\n",
      "Val F1 (macro): 0.5838\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6766\n",
      "Train Accuracy: 0.5947\n",
      "Train F1 (macro): 0.5946\n",
      "\n",
      "Val Loss: 0.6759\n",
      "Val Accuracy: 0.5645\n",
      "Val F1 (macro): 0.5168\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6662\n",
      "Train Accuracy: 0.6154\n",
      "Train F1 (macro): 0.6152\n",
      "\n",
      "Val Loss: 0.6624\n",
      "Val Accuracy: 0.5974\n",
      "Val F1 (macro): 0.5947\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.6552\n",
      "Train Accuracy: 0.6208\n",
      "Train F1 (macro): 0.6208\n",
      "\n",
      "Val Loss: 0.6555\n",
      "Val Accuracy: 0.6183\n",
      "Val F1 (macro): 0.6173\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.6493\n",
      "Train Accuracy: 0.6327\n",
      "Train F1 (macro): 0.6327\n",
      "\n",
      "Val Loss: 0.6501\n",
      "Val Accuracy: 0.6113\n",
      "Val F1 (macro): 0.6111\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.6439\n",
      "Train Accuracy: 0.6234\n",
      "Train F1 (macro): 0.6233\n",
      "\n",
      "Val Loss: 0.6461\n",
      "Val Accuracy: 0.6132\n",
      "Val F1 (macro): 0.6131\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.6406\n",
      "Train Accuracy: 0.6345\n",
      "Train F1 (macro): 0.6345\n",
      "\n",
      "Val Loss: 0.6454\n",
      "Val Accuracy: 0.6257\n",
      "Val F1 (macro): 0.6220\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.6424\n",
      "Train Accuracy: 0.6329\n",
      "Train F1 (macro): 0.6329\n",
      "\n",
      "Val Loss: 0.6421\n",
      "Val Accuracy: 0.6187\n",
      "Val F1 (macro): 0.6187\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.6346\n",
      "Train Accuracy: 0.6399\n",
      "Train F1 (macro): 0.6399\n",
      "\n",
      "Val Loss: 0.6428\n",
      "Val Accuracy: 0.6234\n",
      "Val F1 (macro): 0.6203\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.6315\n",
      "Train Accuracy: 0.6448\n",
      "Train F1 (macro): 0.6448\n",
      "\n",
      "Val Loss: 0.6385\n",
      "Val Accuracy: 0.6201\n",
      "Val F1 (macro): 0.6201\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.6305\n",
      "Train Accuracy: 0.6419\n",
      "Train F1 (macro): 0.6417\n",
      "\n",
      "Val Loss: 0.6500\n",
      "Val Accuracy: 0.6067\n",
      "Val F1 (macro): 0.5919\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.6345\n",
      "Train Accuracy: 0.6343\n",
      "Train F1 (macro): 0.6343\n",
      "\n",
      "Val Loss: 0.6383\n",
      "Val Accuracy: 0.6308\n",
      "Val F1 (macro): 0.6306\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.6309\n",
      "Train Accuracy: 0.6480\n",
      "Train F1 (macro): 0.6480\n",
      "\n",
      "Val Loss: 0.6406\n",
      "Val Accuracy: 0.6285\n",
      "Val F1 (macro): 0.6248\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.6304\n",
      "Train Accuracy: 0.6448\n",
      "Train F1 (macro): 0.6448\n",
      "\n",
      "Val Loss: 0.6364\n",
      "Val Accuracy: 0.6294\n",
      "Val F1 (macro): 0.6293\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.6231\n",
      "Train Accuracy: 0.6496\n",
      "Train F1 (macro): 0.6496\n",
      "\n",
      "Val Loss: 0.6363\n",
      "Val Accuracy: 0.6299\n",
      "Val F1 (macro): 0.6299\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.6214\n",
      "Train Accuracy: 0.6486\n",
      "Train F1 (macro): 0.6486\n",
      "\n",
      "Val Loss: 0.6468\n",
      "Val Accuracy: 0.6262\n",
      "Val F1 (macro): 0.6176\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.6252\n",
      "Train Accuracy: 0.6504\n",
      "Train F1 (macro): 0.6504\n",
      "\n",
      "Val Loss: 0.6404\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6289\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.6232\n",
      "Train Accuracy: 0.6504\n",
      "Train F1 (macro): 0.6504\n",
      "\n",
      "Val Loss: 0.6368\n",
      "Val Accuracy: 0.6303\n",
      "Val F1 (macro): 0.6296\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.6256\n",
      "Train Accuracy: 0.6488\n",
      "Train F1 (macro): 0.6488\n",
      "\n",
      "Val Loss: 0.6359\n",
      "Val Accuracy: 0.6303\n",
      "Val F1 (macro): 0.6303\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.6212\n",
      "Train Accuracy: 0.6476\n",
      "Train F1 (macro): 0.6476\n",
      "\n",
      "Val Loss: 0.6443\n",
      "Val Accuracy: 0.6201\n",
      "Val F1 (macro): 0.6131\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.6218\n",
      "Train Accuracy: 0.6506\n",
      "Train F1 (macro): 0.6506\n",
      "\n",
      "Val Loss: 0.6398\n",
      "Val Accuracy: 0.6308\n",
      "Val F1 (macro): 0.6269\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.6162\n",
      "Train Accuracy: 0.6514\n",
      "Train F1 (macro): 0.6513\n",
      "\n",
      "Val Loss: 0.6366\n",
      "Val Accuracy: 0.6303\n",
      "Val F1 (macro): 0.6289\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.6130\n",
      "Train Accuracy: 0.6610\n",
      "Train F1 (macro): 0.6609\n",
      "\n",
      "Val Loss: 0.6395\n",
      "Val Accuracy: 0.6248\n",
      "Val F1 (macro): 0.6218\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.6168\n",
      "Train Accuracy: 0.6490\n",
      "Train F1 (macro): 0.6490\n",
      "\n",
      "Val Loss: 0.6358\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6326\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.6148\n",
      "Train Accuracy: 0.6616\n",
      "Train F1 (macro): 0.6615\n",
      "\n",
      "Val Loss: 0.6391\n",
      "Val Accuracy: 0.6359\n",
      "Val F1 (macro): 0.6339\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.6196\n",
      "Train Accuracy: 0.6554\n",
      "Train F1 (macro): 0.6554\n",
      "\n",
      "Val Loss: 0.6386\n",
      "Val Accuracy: 0.6238\n",
      "Val F1 (macro): 0.6218\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.6136\n",
      "Train Accuracy: 0.6558\n",
      "Train F1 (macro): 0.6558\n",
      "\n",
      "Val Loss: 0.6510\n",
      "Val Accuracy: 0.6141\n",
      "Val F1 (macro): 0.6015\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.6134\n",
      "Train Accuracy: 0.6590\n",
      "Train F1 (macro): 0.6590\n",
      "\n",
      "Val Loss: 0.6361\n",
      "Val Accuracy: 0.6359\n",
      "Val F1 (macro): 0.6356\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.6114\n",
      "Train Accuracy: 0.6675\n",
      "Train F1 (macro): 0.6675\n",
      "\n",
      "Val Loss: 0.6357\n",
      "Val Accuracy: 0.6322\n",
      "Val F1 (macro): 0.6320\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.6146\n",
      "Train Accuracy: 0.6486\n",
      "Train F1 (macro): 0.6486\n",
      "\n",
      "Val Loss: 0.6413\n",
      "Val Accuracy: 0.6271\n",
      "Val F1 (macro): 0.6237\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.6146\n",
      "Train Accuracy: 0.6590\n",
      "Train F1 (macro): 0.6590\n",
      "\n",
      "Val Loss: 0.6371\n",
      "Val Accuracy: 0.6280\n",
      "Val F1 (macro): 0.6258\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.6107\n",
      "Train Accuracy: 0.6570\n",
      "Train F1 (macro): 0.6570\n",
      "\n",
      "Val Loss: 0.6357\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6350\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.6090\n",
      "Train Accuracy: 0.6643\n",
      "Train F1 (macro): 0.6643\n",
      "\n",
      "Val Loss: 0.6368\n",
      "Val Accuracy: 0.6368\n",
      "Val F1 (macro): 0.6357\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.6107\n",
      "Train Accuracy: 0.6526\n",
      "Train F1 (macro): 0.6526\n",
      "\n",
      "Val Loss: 0.6373\n",
      "Val Accuracy: 0.6262\n",
      "Val F1 (macro): 0.6245\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.6087\n",
      "Train Accuracy: 0.6586\n",
      "Train F1 (macro): 0.6586\n",
      "\n",
      "Val Loss: 0.6400\n",
      "Val Accuracy: 0.6243\n",
      "Val F1 (macro): 0.6218\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.6123\n",
      "Train Accuracy: 0.6612\n",
      "Train F1 (macro): 0.6611\n",
      "\n",
      "Val Loss: 0.6349\n",
      "Val Accuracy: 0.6331\n",
      "Val F1 (macro): 0.6326\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.6141\n",
      "Train Accuracy: 0.6584\n",
      "Train F1 (macro): 0.6584\n",
      "\n",
      "Val Loss: 0.6359\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6318\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.6093\n",
      "Train Accuracy: 0.6590\n",
      "Train F1 (macro): 0.6590\n",
      "\n",
      "Val Loss: 0.6437\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6212\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.6091\n",
      "Train Accuracy: 0.6552\n",
      "Train F1 (macro): 0.6552\n",
      "\n",
      "Val Loss: 0.6359\n",
      "Val Accuracy: 0.6391\n",
      "Val F1 (macro): 0.6391\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.6038\n",
      "Train Accuracy: 0.6628\n",
      "Train F1 (macro): 0.6628\n",
      "\n",
      "Val Loss: 0.6337\n",
      "Val Accuracy: 0.6354\n",
      "Val F1 (macro): 0.6353\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.6107\n",
      "Train Accuracy: 0.6558\n",
      "Train F1 (macro): 0.6558\n",
      "\n",
      "Val Loss: 0.6342\n",
      "Val Accuracy: 0.6345\n",
      "Val F1 (macro): 0.6338\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.6096\n",
      "Train Accuracy: 0.6566\n",
      "Train F1 (macro): 0.6566\n",
      "\n",
      "Val Loss: 0.6332\n",
      "Val Accuracy: 0.6391\n",
      "Val F1 (macro): 0.6390\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.6122\n",
      "Train Accuracy: 0.6532\n",
      "Train F1 (macro): 0.6532\n",
      "\n",
      "Val Loss: 0.6335\n",
      "Val Accuracy: 0.6433\n",
      "Val F1 (macro): 0.6432\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.6091\n",
      "Train Accuracy: 0.6560\n",
      "Train F1 (macro): 0.6560\n",
      "\n",
      "Val Loss: 0.6344\n",
      "Val Accuracy: 0.6391\n",
      "Val F1 (macro): 0.6391\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.6092\n",
      "Train Accuracy: 0.6576\n",
      "Train F1 (macro): 0.6576\n",
      "\n",
      "Val Loss: 0.6340\n",
      "Val Accuracy: 0.6336\n",
      "Val F1 (macro): 0.6330\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.6065\n",
      "Train Accuracy: 0.6598\n",
      "Train F1 (macro): 0.6597\n",
      "\n",
      "Val Loss: 0.6357\n",
      "Val Accuracy: 0.6373\n",
      "Val F1 (macro): 0.6373\n",
      "\n",
      "\n",
      "Epoch 54\n",
      "Training Loss: 0.6030\n",
      "Train Accuracy: 0.6610\n",
      "Train F1 (macro): 0.6610\n",
      "\n",
      "Val Loss: 0.6318\n",
      "Val Accuracy: 0.6433\n",
      "Val F1 (macro): 0.6433\n",
      "\n",
      "\n",
      "Epoch 55\n",
      "Training Loss: 0.6028\n",
      "Train Accuracy: 0.6610\n",
      "Train F1 (macro): 0.6609\n",
      "\n",
      "Val Loss: 0.6342\n",
      "Val Accuracy: 0.6415\n",
      "Val F1 (macro): 0.6415\n",
      "\n",
      "\n",
      "Epoch 56\n",
      "Training Loss: 0.5993\n",
      "Train Accuracy: 0.6691\n",
      "Train F1 (macro): 0.6691\n",
      "\n",
      "Val Loss: 0.6396\n",
      "Val Accuracy: 0.6266\n",
      "Val F1 (macro): 0.6247\n",
      "\n",
      "\n",
      "Epoch 57\n",
      "Training Loss: 0.5986\n",
      "Train Accuracy: 0.6645\n",
      "Train F1 (macro): 0.6645\n",
      "\n",
      "Val Loss: 0.6348\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6421\n",
      "\n",
      "\n",
      "Epoch 58\n",
      "Training Loss: 0.6033\n",
      "Train Accuracy: 0.6622\n",
      "Train F1 (macro): 0.6621\n",
      "\n",
      "Val Loss: 0.6345\n",
      "Val Accuracy: 0.6382\n",
      "Val F1 (macro): 0.6382\n",
      "\n",
      "\n",
      "Epoch 59\n",
      "Training Loss: 0.5955\n",
      "Train Accuracy: 0.6713\n",
      "Train F1 (macro): 0.6713\n",
      "\n",
      "Val Loss: 0.6387\n",
      "Val Accuracy: 0.6224\n",
      "Val F1 (macro): 0.6176\n",
      "\n",
      "\n",
      "Epoch 60\n",
      "Training Loss: 0.5959\n",
      "Train Accuracy: 0.6711\n",
      "Train F1 (macro): 0.6711\n",
      "\n",
      "Val Loss: 0.6396\n",
      "Val Accuracy: 0.6373\n",
      "Val F1 (macro): 0.6340\n",
      "\n",
      "\n",
      "Epoch 61\n",
      "Training Loss: 0.5975\n",
      "Train Accuracy: 0.6705\n",
      "Train F1 (macro): 0.6705\n",
      "\n",
      "Val Loss: 0.6354\n",
      "Val Accuracy: 0.6378\n",
      "Val F1 (macro): 0.6373\n",
      "\n",
      "\n",
      "Epoch 62\n",
      "Training Loss: 0.5949\n",
      "Train Accuracy: 0.6701\n",
      "Train F1 (macro): 0.6701\n",
      "\n",
      "Val Loss: 0.6375\n",
      "Val Accuracy: 0.6299\n",
      "Val F1 (macro): 0.6283\n",
      "\n",
      "\n",
      "Epoch 63\n",
      "Training Loss: 0.5980\n",
      "Train Accuracy: 0.6657\n",
      "Train F1 (macro): 0.6657\n",
      "\n",
      "Val Loss: 0.6331\n",
      "Val Accuracy: 0.6368\n",
      "Val F1 (macro): 0.6368\n",
      "\n",
      "\n",
      "Epoch 64\n",
      "Training Loss: 0.5950\n",
      "Train Accuracy: 0.6697\n",
      "Train F1 (macro): 0.6697\n",
      "\n",
      "Val Loss: 0.6361\n",
      "Val Accuracy: 0.6285\n",
      "Val F1 (macro): 0.6279\n",
      "\n",
      "\n",
      "Epoch 65\n",
      "Training Loss: 0.5979\n",
      "Train Accuracy: 0.6635\n",
      "Train F1 (macro): 0.6635\n",
      "\n",
      "Val Loss: 0.6351\n",
      "Val Accuracy: 0.6331\n",
      "Val F1 (macro): 0.6326\n",
      "\n",
      "\n",
      "Epoch 66\n",
      "Training Loss: 0.5971\n",
      "Train Accuracy: 0.6727\n",
      "Train F1 (macro): 0.6727\n",
      "\n",
      "Val Loss: 0.6359\n",
      "Val Accuracy: 0.6424\n",
      "Val F1 (macro): 0.6414\n",
      "\n",
      "\n",
      "Epoch 67\n",
      "Training Loss: 0.5939\n",
      "Train Accuracy: 0.6723\n",
      "Train F1 (macro): 0.6723\n",
      "\n",
      "Val Loss: 0.6339\n",
      "Val Accuracy: 0.6378\n",
      "Val F1 (macro): 0.6378\n",
      "\n",
      "\n",
      "Epoch 68\n",
      "Training Loss: 0.5968\n",
      "Train Accuracy: 0.6637\n",
      "Train F1 (macro): 0.6637\n",
      "\n",
      "Val Loss: 0.6398\n",
      "Val Accuracy: 0.6438\n",
      "Val F1 (macro): 0.6426\n",
      "\n",
      "\n",
      "Epoch 69\n",
      "Training Loss: 0.5946\n",
      "Train Accuracy: 0.6697\n",
      "Train F1 (macro): 0.6697\n",
      "\n",
      "Val Loss: 0.6339\n",
      "Val Accuracy: 0.6419\n",
      "Val F1 (macro): 0.6419\n",
      "\n",
      "\n",
      "Epoch 70\n",
      "Training Loss: 0.5909\n",
      "Train Accuracy: 0.6685\n",
      "Train F1 (macro): 0.6685\n",
      "\n",
      "Val Loss: 0.6385\n",
      "Val Accuracy: 0.6308\n",
      "Val F1 (macro): 0.6303\n",
      "\n",
      "\n",
      "Epoch 71\n",
      "Training Loss: 0.5965\n",
      "Train Accuracy: 0.6731\n",
      "Train F1 (macro): 0.6731\n",
      "\n",
      "Val Loss: 0.6359\n",
      "Val Accuracy: 0.6373\n",
      "Val F1 (macro): 0.6360\n",
      "\n",
      "\n",
      "Epoch 72\n",
      "Training Loss: 0.5926\n",
      "Train Accuracy: 0.6671\n",
      "Train F1 (macro): 0.6671\n",
      "\n",
      "Val Loss: 0.6339\n",
      "Val Accuracy: 0.6303\n",
      "Val F1 (macro): 0.6288\n",
      "\n",
      "\n",
      "Epoch 73\n",
      "Training Loss: 0.5838\n",
      "Train Accuracy: 0.6836\n",
      "Train F1 (macro): 0.6836\n",
      "\n",
      "Val Loss: 0.6436\n",
      "Val Accuracy: 0.6285\n",
      "Val F1 (macro): 0.6239\n",
      "\n",
      "\n",
      "Epoch 74\n",
      "Training Loss: 0.5943\n",
      "Train Accuracy: 0.6699\n",
      "Train F1 (macro): 0.6699\n",
      "\n",
      "Val Loss: 0.6349\n",
      "Val Accuracy: 0.6252\n",
      "Val F1 (macro): 0.6237\n",
      "\n",
      "\n",
      "Epoch 75\n",
      "Training Loss: 0.5911\n",
      "Train Accuracy: 0.6771\n",
      "Train F1 (macro): 0.6771\n",
      "\n",
      "Val Loss: 0.6354\n",
      "Val Accuracy: 0.6354\n",
      "Val F1 (macro): 0.6326\n",
      "\n",
      "\n",
      "Epoch 76\n",
      "Training Loss: 0.5963\n",
      "Train Accuracy: 0.6699\n",
      "Train F1 (macro): 0.6699\n",
      "\n",
      "Val Loss: 0.6324\n",
      "Val Accuracy: 0.6317\n",
      "Val F1 (macro): 0.6298\n",
      "\n",
      "\n",
      "Epoch 77\n",
      "Training Loss: 0.5962\n",
      "Train Accuracy: 0.6663\n",
      "Train F1 (macro): 0.6663\n",
      "\n",
      "Val Loss: 0.6340\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6417\n",
      "\n",
      "\n",
      "Epoch 78\n",
      "Training Loss: 0.5940\n",
      "Train Accuracy: 0.6703\n",
      "Train F1 (macro): 0.6703\n",
      "\n",
      "Val Loss: 0.6332\n",
      "Val Accuracy: 0.6433\n",
      "Val F1 (macro): 0.6432\n",
      "\n",
      "\n",
      "Epoch 79\n",
      "Training Loss: 0.5888\n",
      "Train Accuracy: 0.6751\n",
      "Train F1 (macro): 0.6751\n",
      "\n",
      "Val Loss: 0.6345\n",
      "Val Accuracy: 0.6438\n",
      "Val F1 (macro): 0.6435\n",
      "\n",
      "\n",
      "Epoch 80\n",
      "Training Loss: 0.5930\n",
      "Train Accuracy: 0.6755\n",
      "Train F1 (macro): 0.6755\n",
      "\n",
      "Val Loss: 0.6426\n",
      "Val Accuracy: 0.6396\n",
      "Val F1 (macro): 0.6380\n",
      "\n",
      "\n",
      "Epoch 81\n",
      "Training Loss: 0.5925\n",
      "Train Accuracy: 0.6667\n",
      "Train F1 (macro): 0.6667\n",
      "\n",
      "Val Loss: 0.6400\n",
      "Val Accuracy: 0.6387\n",
      "Val F1 (macro): 0.6379\n",
      "\n",
      "\n",
      "Epoch 82\n",
      "Training Loss: 0.5899\n",
      "Train Accuracy: 0.6725\n",
      "Train F1 (macro): 0.6724\n",
      "\n",
      "Val Loss: 0.6416\n",
      "Val Accuracy: 0.6452\n",
      "Val F1 (macro): 0.6441\n",
      "\n",
      "\n",
      "Epoch 83\n",
      "Training Loss: 0.5876\n",
      "Train Accuracy: 0.6695\n",
      "Train F1 (macro): 0.6695\n",
      "\n",
      "Val Loss: 0.6362\n",
      "Val Accuracy: 0.6313\n",
      "Val F1 (macro): 0.6299\n",
      "\n",
      "\n",
      "Epoch 84\n",
      "Training Loss: 0.5881\n",
      "Train Accuracy: 0.6733\n",
      "Train F1 (macro): 0.6733\n",
      "\n",
      "Val Loss: 0.6379\n",
      "Val Accuracy: 0.6308\n",
      "Val F1 (macro): 0.6301\n",
      "\n",
      "\n",
      "Epoch 85\n",
      "Training Loss: 0.5871\n",
      "Train Accuracy: 0.6848\n",
      "Train F1 (macro): 0.6848\n",
      "\n",
      "Val Loss: 0.6372\n",
      "Val Accuracy: 0.6136\n",
      "Val F1 (macro): 0.6096\n",
      "\n",
      "\n",
      "Epoch 86\n",
      "Training Loss: 0.5931\n",
      "Train Accuracy: 0.6771\n",
      "Train F1 (macro): 0.6771\n",
      "\n",
      "Val Loss: 0.6367\n",
      "Val Accuracy: 0.6299\n",
      "Val F1 (macro): 0.6292\n",
      "\n",
      "\n",
      "Epoch 87\n",
      "Training Loss: 0.5924\n",
      "Train Accuracy: 0.6765\n",
      "Train F1 (macro): 0.6764\n",
      "\n",
      "Val Loss: 0.6385\n",
      "Val Accuracy: 0.6373\n",
      "Val F1 (macro): 0.6373\n",
      "\n",
      "\n",
      "Epoch 88\n",
      "Training Loss: 0.5890\n",
      "Train Accuracy: 0.6785\n",
      "Train F1 (macro): 0.6784\n",
      "\n",
      "Val Loss: 0.6365\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6400\n",
      "\n",
      "\n",
      "Epoch 89\n",
      "Training Loss: 0.5884\n",
      "Train Accuracy: 0.6755\n",
      "Train F1 (macro): 0.6755\n",
      "\n",
      "Val Loss: 0.6351\n",
      "Val Accuracy: 0.6359\n",
      "Val F1 (macro): 0.6355\n",
      "\n",
      "\n",
      "Epoch 90\n",
      "Training Loss: 0.5864\n",
      "Train Accuracy: 0.6743\n",
      "Train F1 (macro): 0.6742\n",
      "\n",
      "Val Loss: 0.6396\n",
      "Val Accuracy: 0.6438\n",
      "Val F1 (macro): 0.6427\n",
      "\n",
      "\n",
      "Epoch 91\n",
      "Training Loss: 0.5866\n",
      "Train Accuracy: 0.6815\n",
      "Train F1 (macro): 0.6814\n",
      "\n",
      "Val Loss: 0.6352\n",
      "Val Accuracy: 0.6229\n",
      "Val F1 (macro): 0.6218\n",
      "\n",
      "\n",
      "Epoch 92\n",
      "Training Loss: 0.5833\n",
      "Train Accuracy: 0.6825\n",
      "Train F1 (macro): 0.6824\n",
      "\n",
      "Val Loss: 0.6449\n",
      "Val Accuracy: 0.6364\n",
      "Val F1 (macro): 0.6354\n",
      "\n",
      "\n",
      "Epoch 93\n",
      "Training Loss: 0.5893\n",
      "Train Accuracy: 0.6729\n",
      "Train F1 (macro): 0.6729\n",
      "\n",
      "Val Loss: 0.6446\n",
      "Val Accuracy: 0.6336\n",
      "Val F1 (macro): 0.6331\n",
      "\n",
      "\n",
      "Epoch 94\n",
      "Training Loss: 0.5783\n",
      "Train Accuracy: 0.6777\n",
      "Train F1 (macro): 0.6777\n",
      "\n",
      "Val Loss: 0.6392\n",
      "Val Accuracy: 0.6378\n",
      "Val F1 (macro): 0.6378\n",
      "\n",
      "\n",
      "Epoch 95\n",
      "Training Loss: 0.5847\n",
      "Train Accuracy: 0.6787\n",
      "Train F1 (macro): 0.6786\n",
      "\n",
      "Val Loss: 0.6381\n",
      "Val Accuracy: 0.6438\n",
      "Val F1 (macro): 0.6429\n",
      "\n",
      "\n",
      "Epoch 96\n",
      "Training Loss: 0.5779\n",
      "Train Accuracy: 0.6882\n",
      "Train F1 (macro): 0.6882\n",
      "\n",
      "Val Loss: 0.6376\n",
      "Val Accuracy: 0.6280\n",
      "Val F1 (macro): 0.6271\n",
      "\n",
      "\n",
      "Epoch 97\n",
      "Training Loss: 0.5874\n",
      "Train Accuracy: 0.6697\n",
      "Train F1 (macro): 0.6697\n",
      "\n",
      "Val Loss: 0.6358\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6349\n",
      "\n",
      "\n",
      "Epoch 98\n",
      "Training Loss: 0.5787\n",
      "Train Accuracy: 0.6827\n",
      "Train F1 (macro): 0.6826\n",
      "\n",
      "Val Loss: 0.6420\n",
      "Val Accuracy: 0.6461\n",
      "Val F1 (macro): 0.6452\n",
      "\n",
      "\n",
      "Epoch 99\n",
      "Training Loss: 0.5794\n",
      "Train Accuracy: 0.6896\n",
      "Train F1 (macro): 0.6896\n",
      "\n",
      "Val Loss: 0.6372\n",
      "Val Accuracy: 0.6308\n",
      "Val F1 (macro): 0.6295\n",
      "\n",
      "\n",
      "Epoch 100\n",
      "Training Loss: 0.5790\n",
      "Train Accuracy: 0.6858\n",
      "Train F1 (macro): 0.6858\n",
      "\n",
      "Val Loss: 0.6410\n",
      "Val Accuracy: 0.6266\n",
      "Val F1 (macro): 0.6266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, device, class_weights_tensor, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4b0a",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c821845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5290\n",
      "Test Accuracy: 0.7439\n",
      "Test F1 (macro): 0.7425\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▄▃▄▅▄▅▆▅▄▅▅▆▅▅▅▅▆▅▅▅▆▆▆▆▇▆▆▆▇▇▆▇█▇▇▇▇█</td></tr><tr><td>train_f1_macro</td><td>▁▃▆▆▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇██▇█▇██</td></tr><tr><td>train_f1_weighted</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇███▇█▇██████</td></tr><tr><td>train_loss</td><td>▄▄▄▅▅▅▃▄▅▃▃▅▄▄▂▄▆▅█▂▂▆▂▃▄▃▇▂▃▄▄▇▆▁▂▅▄▃▃▁</td></tr><tr><td>train_precision_macro</td><td>▁▄▅▅▆▅▆▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇██</td></tr><tr><td>train_recall_macro</td><td>▁▅▅▅▅▆▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇██</td></tr><tr><td>val_accuracy</td><td>▁▄▅▅▆▆▆▆▆▅▆▇▇█▇▆▆▇██▇▅▇▇▆▇██▆▇▆██▇█▅▇▇▆▆</td></tr><tr><td>val_f1_macro</td><td>▃▁▃▅▃▅▄▆▄▆▄▄▆▇▇▅▇█▅▃█▄▇▃▆▇█▆▅▄▁▅▇▇▆▆▆▇▅▅</td></tr><tr><td>val_f1_weighted</td><td>▅▁▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▇███▇▇██▇▇███▇███▇</td></tr><tr><td>val_loss</td><td>█▄▃▂▄▂▂▂▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▁▁▂▁▁▁▁▂▂▂▂▃▂▂</td></tr><tr><td>val_precision_macro</td><td>▁▄▄▅▆▆▇▆▇▅▆▆▆▆▇▇▆▆▇▇▇▇▇▆█▇▇▆▇▆▇█▆▇█▇▆▇▇█</td></tr><tr><td>val_recall_macro</td><td>▁▄▆▅▅▅▇▇▇▆▆▇▆▅▇▆▇▆▆▇▇▇█▆█▇▇▇▇█▇▇██▇▇▇▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>test_accuracy</td><td>0.74393</td></tr><tr><td>test_f1_macro</td><td>0.74245</td></tr><tr><td>test_f1_weighted</td><td>0.74245</td></tr><tr><td>test_loss</td><td>0.52898</td></tr><tr><td>test_precision_macro</td><td>0.74966</td></tr><tr><td>test_recall_macro</td><td>0.74393</td></tr><tr><td>train_accuracy</td><td>0.68583</td></tr><tr><td>train_f1_macro</td><td>0.68581</td></tr><tr><td>train_f1_weighted</td><td>0.68581</td></tr><tr><td>train_loss</td><td>0.10722</td></tr><tr><td>train_precision_macro</td><td>0.68589</td></tr><tr><td>train_recall_macro</td><td>0.68583</td></tr><tr><td>val_accuracy</td><td>0.62662</td></tr><tr><td>val_f1_macro</td><td>0.62656</td></tr><tr><td>val_f1_weighted</td><td>0.62656</td></tr><tr><td>val_loss</td><td>0.64097</td></tr><tr><td>val_precision_macro</td><td>0.62672</td></tr><tr><td>val_recall_macro</td><td>0.62662</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-darkness-20</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mckgqjp6' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mckgqjp6</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250512_161108-mckgqjp6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(model, test_loader, device, class_weights_tensor, phase = \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
