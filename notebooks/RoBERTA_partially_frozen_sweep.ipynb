{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b896fff3-8280-4197-a693-1006a0ef9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 18 13:16:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.52.04              Driver Version: 555.52.04      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:24:00.0 Off |                  N/A |\n",
      "| 37%   48C    P0             30W /  250W |       1MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ff690d-a645-43c3-9113-1b966e4e31e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367912e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sweep_runner import sweep_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ac943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_f1_macro\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"model_name\": {\n",
    "            \"values\": [\n",
    "                \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                \"roberta-base\",\n",
    "                #\"roberta-large\"\n",
    "            ]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"min\": 1e-5,\n",
    "            \"max\": 1e-4\n",
    "        },\n",
    "        \"unfrozen_last_layers\": {\n",
    "            \"values\": [0, 1, 2, 3, 4]\n",
    "        },\n",
    "        \"pooling\": {\n",
    "            \"values\": [\"cls\", \"attention_pooling\"]\n",
    "        },\n",
    "        \"epochs\": {\n",
    "            \"value\": 50\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef90031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: grjxlksx\n",
      "Sweep URL: https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx\n",
      "Sweep ID: grjxlksx\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"roberta-sweep\")\n",
    "print(\"Sweep ID:\", sweep_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a2d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: grwyr31i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.0947817208299e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling: cls\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_last_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'roberta-sweep' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250518_131655-grwyr31i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/grwyr31i' target=\"_blank\">zany-sweep-1</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/grwyr31i' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/grwyr31i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 13:17:00.118878: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-18 13:17:00.136281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747567020.157492   96887 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747567020.164021   96887 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747567020.180484   96887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747567020.180501   96887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747567020.180503   96887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747567020.180504   96887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-18 13:17:00.186121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6482\n",
      "Train Accuracy: 0.6128\n",
      "Train F1 (macro): 0.6092\n",
      "\n",
      "Val Loss: 0.6479\n",
      "Val Accuracy: 0.6657\n",
      "Val F1 (macro): 0.5698\n",
      "\n",
      "New best model saved (F1: 0.5698, Acc: 0.6657)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6199\n",
      "Train Accuracy: 0.6545\n",
      "Train F1 (macro): 0.6472\n",
      "\n",
      "Val Loss: 0.5990\n",
      "Val Accuracy: 0.6737\n",
      "Val F1 (macro): 0.6686\n",
      "\n",
      "New best model saved (F1: 0.6686, Acc: 0.6737)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.5956\n",
      "Train Accuracy: 0.6638\n",
      "Train F1 (macro): 0.6540\n",
      "\n",
      "Val Loss: 0.5933\n",
      "Val Accuracy: 0.6965\n",
      "Val F1 (macro): 0.6808\n",
      "\n",
      "New best model saved (F1: 0.6808, Acc: 0.6965)\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.5739\n",
      "Train Accuracy: 0.6895\n",
      "Train F1 (macro): 0.6806\n",
      "\n",
      "Val Loss: 0.5997\n",
      "Val Accuracy: 0.6896\n",
      "Val F1 (macro): 0.6793\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.5429\n",
      "Train Accuracy: 0.7073\n",
      "Train F1 (macro): 0.6966\n",
      "\n",
      "Val Loss: 0.6384\n",
      "Val Accuracy: 0.6896\n",
      "Val F1 (macro): 0.6766\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.5227\n",
      "Train Accuracy: 0.7373\n",
      "Train F1 (macro): 0.7251\n",
      "\n",
      "Val Loss: 0.6524\n",
      "Val Accuracy: 0.7010\n",
      "Val F1 (macro): 0.6684\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.4656\n",
      "Train Accuracy: 0.7708\n",
      "Train F1 (macro): 0.7626\n",
      "\n",
      "Val Loss: 0.7055\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6390\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.4204\n",
      "Train Accuracy: 0.8044\n",
      "Train F1 (macro): 0.7975\n",
      "\n",
      "Val Loss: 0.7461\n",
      "Val Accuracy: 0.6333\n",
      "Val F1 (macro): 0.6313\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.3584\n",
      "Train Accuracy: 0.8428\n",
      "Train F1 (macro): 0.8367\n",
      "\n",
      "Val Loss: 0.7765\n",
      "Val Accuracy: 0.6634\n",
      "Val F1 (macro): 0.6522\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.3069\n",
      "Train Accuracy: 0.8682\n",
      "Train F1 (macro): 0.8629\n",
      "\n",
      "Val Loss: 0.8431\n",
      "Val Accuracy: 0.6521\n",
      "Val F1 (macro): 0.6415\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.2411\n",
      "Train Accuracy: 0.9058\n",
      "Train F1 (macro): 0.9014\n",
      "\n",
      "Val Loss: 0.9649\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6260\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.1985\n",
      "Train Accuracy: 0.9236\n",
      "Train F1 (macro): 0.9198\n",
      "\n",
      "Val Loss: 0.9107\n",
      "Val Accuracy: 0.6640\n",
      "Val F1 (macro): 0.6323\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.1939\n",
      "Train Accuracy: 0.9270\n",
      "Train F1 (macro): 0.9235\n",
      "\n",
      "Val Loss: 1.2243\n",
      "Val Accuracy: 0.6464\n",
      "Val F1 (macro): 0.6355\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.1422\n",
      "Train Accuracy: 0.9492\n",
      "Train F1 (macro): 0.9467\n",
      "\n",
      "Val Loss: 1.1906\n",
      "Val Accuracy: 0.6589\n",
      "Val F1 (macro): 0.6411\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.1341\n",
      "Train Accuracy: 0.9478\n",
      "Train F1 (macro): 0.9452\n",
      "\n",
      "Val Loss: 1.5241\n",
      "Val Accuracy: 0.6566\n",
      "Val F1 (macro): 0.6267\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.1040\n",
      "Train Accuracy: 0.9656\n",
      "Train F1 (macro): 0.9639\n",
      "\n",
      "Val Loss: 1.2642\n",
      "Val Accuracy: 0.6515\n",
      "Val F1 (macro): 0.6223\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.1102\n",
      "Train Accuracy: 0.9614\n",
      "Train F1 (macro): 0.9596\n",
      "\n",
      "Val Loss: 1.4895\n",
      "Val Accuracy: 0.6623\n",
      "Val F1 (macro): 0.6366\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.1020\n",
      "Train Accuracy: 0.9648\n",
      "Train F1 (macro): 0.9631\n",
      "\n",
      "Val Loss: 1.4806\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6358\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.0928\n",
      "Train Accuracy: 0.9653\n",
      "Train F1 (macro): 0.9636\n",
      "\n",
      "Val Loss: 1.4172\n",
      "Val Accuracy: 0.6646\n",
      "Val F1 (macro): 0.6475\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.0769\n",
      "Train Accuracy: 0.9736\n",
      "Train F1 (macro): 0.9723\n",
      "\n",
      "Val Loss: 1.7572\n",
      "Val Accuracy: 0.6333\n",
      "Val F1 (macro): 0.6228\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.0835\n",
      "Train Accuracy: 0.9695\n",
      "Train F1 (macro): 0.9680\n",
      "\n",
      "Val Loss: 1.2920\n",
      "Val Accuracy: 0.6452\n",
      "Val F1 (macro): 0.6333\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.0785\n",
      "Train Accuracy: 0.9724\n",
      "Train F1 (macro): 0.9710\n",
      "\n",
      "Val Loss: 1.3937\n",
      "Val Accuracy: 0.6583\n",
      "Val F1 (macro): 0.6348\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.0761\n",
      "Train Accuracy: 0.9692\n",
      "Train F1 (macro): 0.9677\n",
      "\n",
      "Val Loss: 1.7181\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6362\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.0654\n",
      "Train Accuracy: 0.9753\n",
      "Train F1 (macro): 0.9741\n",
      "\n",
      "Val Loss: 1.5835\n",
      "Val Accuracy: 0.6247\n",
      "Val F1 (macro): 0.6194\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.0635\n",
      "Train Accuracy: 0.9746\n",
      "Train F1 (macro): 0.9733\n",
      "\n",
      "Val Loss: 1.6306\n",
      "Val Accuracy: 0.6714\n",
      "Val F1 (macro): 0.6440\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.0792\n",
      "Train Accuracy: 0.9734\n",
      "Train F1 (macro): 0.9720\n",
      "\n",
      "Val Loss: 1.5808\n",
      "Val Accuracy: 0.6395\n",
      "Val F1 (macro): 0.6240\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.0490\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9777\n",
      "\n",
      "Val Loss: 1.7947\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6300\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.0563\n",
      "Train Accuracy: 0.9775\n",
      "Train F1 (macro): 0.9764\n",
      "\n",
      "Val Loss: 1.9193\n",
      "Val Accuracy: 0.6128\n",
      "Val F1 (macro): 0.6113\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.0738\n",
      "Train Accuracy: 0.9739\n",
      "Train F1 (macro): 0.9725\n",
      "\n",
      "Val Loss: 1.6239\n",
      "Val Accuracy: 0.6560\n",
      "Val F1 (macro): 0.6428\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.0622\n",
      "Train Accuracy: 0.9766\n",
      "Train F1 (macro): 0.9753\n",
      "\n",
      "Val Loss: 1.8805\n",
      "Val Accuracy: 0.6555\n",
      "Val F1 (macro): 0.6386\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.0556\n",
      "Train Accuracy: 0.9751\n",
      "Train F1 (macro): 0.9739\n",
      "\n",
      "Val Loss: 2.0273\n",
      "Val Accuracy: 0.6549\n",
      "Val F1 (macro): 0.6430\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.0477\n",
      "Train Accuracy: 0.9790\n",
      "Train F1 (macro): 0.9779\n",
      "\n",
      "Val Loss: 2.0848\n",
      "Val Accuracy: 0.6498\n",
      "Val F1 (macro): 0.6384\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.0432\n",
      "Train Accuracy: 0.9817\n",
      "Train F1 (macro): 0.9808\n",
      "\n",
      "Val Loss: 2.1055\n",
      "Val Accuracy: 0.6566\n",
      "Val F1 (macro): 0.6411\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.0584\n",
      "Train Accuracy: 0.9766\n",
      "Train F1 (macro): 0.9754\n",
      "\n",
      "Val Loss: 1.9098\n",
      "Val Accuracy: 0.6538\n",
      "Val F1 (macro): 0.6386\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.0598\n",
      "Train Accuracy: 0.9734\n",
      "Train F1 (macro): 0.9721\n",
      "\n",
      "Val Loss: 1.8200\n",
      "Val Accuracy: 0.6435\n",
      "Val F1 (macro): 0.6250\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.0533\n",
      "Train Accuracy: 0.9805\n",
      "Train F1 (macro): 0.9795\n",
      "\n",
      "Val Loss: 1.7875\n",
      "Val Accuracy: 0.6549\n",
      "Val F1 (macro): 0.6376\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.0467\n",
      "Train Accuracy: 0.9832\n",
      "Train F1 (macro): 0.9822\n",
      "\n",
      "Val Loss: 1.7323\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6201\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.0442\n",
      "Train Accuracy: 0.9812\n",
      "Train F1 (macro): 0.9803\n",
      "\n",
      "Val Loss: 2.2544\n",
      "Val Accuracy: 0.6646\n",
      "Val F1 (macro): 0.6354\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.0414\n",
      "Train Accuracy: 0.9839\n",
      "Train F1 (macro): 0.9830\n",
      "\n",
      "Val Loss: 2.0155\n",
      "Val Accuracy: 0.6623\n",
      "Val F1 (macro): 0.6380\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.0382\n",
      "Train Accuracy: 0.9841\n",
      "Train F1 (macro): 0.9833\n",
      "\n",
      "Val Loss: 2.7984\n",
      "Val Accuracy: 0.6794\n",
      "Val F1 (macro): 0.6378\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.0491\n",
      "Train Accuracy: 0.9785\n",
      "Train F1 (macro): 0.9774\n",
      "\n",
      "Val Loss: 2.4017\n",
      "Val Accuracy: 0.6344\n",
      "Val F1 (macro): 0.6315\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.0590\n",
      "Train Accuracy: 0.9751\n",
      "Train F1 (macro): 0.9738\n",
      "\n",
      "Val Loss: 2.0341\n",
      "Val Accuracy: 0.6390\n",
      "Val F1 (macro): 0.6297\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.0441\n",
      "Train Accuracy: 0.9805\n",
      "Train F1 (macro): 0.9795\n",
      "\n",
      "Val Loss: 1.8644\n",
      "Val Accuracy: 0.6726\n",
      "Val F1 (macro): 0.6499\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.0398\n",
      "Train Accuracy: 0.9824\n",
      "Train F1 (macro): 0.9815\n",
      "\n",
      "Val Loss: 2.1572\n",
      "Val Accuracy: 0.6446\n",
      "Val F1 (macro): 0.6321\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.0409\n",
      "Train Accuracy: 0.9817\n",
      "Train F1 (macro): 0.9808\n",
      "\n",
      "Val Loss: 2.1589\n",
      "Val Accuracy: 0.6600\n",
      "Val F1 (macro): 0.6332\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.0310\n",
      "Train Accuracy: 0.9873\n",
      "Train F1 (macro): 0.9866\n",
      "\n",
      "Val Loss: 1.9979\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6199\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.0480\n",
      "Train Accuracy: 0.9807\n",
      "Train F1 (macro): 0.9797\n",
      "\n",
      "Val Loss: 1.8431\n",
      "Val Accuracy: 0.6031\n",
      "Val F1 (macro): 0.5883\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.0400\n",
      "Train Accuracy: 0.9807\n",
      "Train F1 (macro): 0.9798\n",
      "\n",
      "Val Loss: 2.1538\n",
      "Val Accuracy: 0.6367\n",
      "Val F1 (macro): 0.6244\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.0433\n",
      "Train Accuracy: 0.9795\n",
      "Train F1 (macro): 0.9785\n",
      "\n",
      "Val Loss: 2.5239\n",
      "Val Accuracy: 0.6731\n",
      "Val F1 (macro): 0.6529\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.0410\n",
      "Train Accuracy: 0.9819\n",
      "Train F1 (macro): 0.9810\n",
      "\n",
      "Val Loss: 2.1039\n",
      "Val Accuracy: 0.6446\n",
      "Val F1 (macro): 0.6345\n",
      "\n",
      "Test Loss: 0.4779\n",
      "Test Accuracy: 0.8083\n",
      "Test F1 (macro): 0.7652\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▂▂▃▄▅▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>train_f1_macro</td><td>▁▂▂▂▃▄▄▅▆▆▇▇▇█▇█████████████████████████</td></tr><tr><td>train_f1_weighted</td><td>▁▂▂▂▃▄▅▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_precision_macro</td><td>▁▂▂▂▂▄▄▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>train_recall_macro</td><td>▁▂▂▂▃▄▅▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>val_accuracy</td><td>▆█▇▇█▃▅▅▃▅▅▅▄▄▅▄▅▄▃▆▄▂▅▅▅▅▅▄▅▄▅▆▃▄▆▅▃▁▃▄</td></tr><tr><td>val_f1_macro</td><td>▁▇███▅▅▆▆▅▅▅▄▅▅▄▅▅▅▄▄▅▄▆▅▅▅▅▄▅▅▅▅▅▆▅▄▂▄▅</td></tr><tr><td>val_f1_weighted</td><td>▂▇███▃▆▅▃▅▅▄▄▅▄▃▄▅▅▃▄▂▅▅▅▅▅▄▅▄▅▆▄▄▆▅▃▁▄▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▄▃▄▄▅▃▄▅▄▄▅▅▄▆▆▆▅▅▆▆█▆▅▆▅▅▆▆</td></tr><tr><td>val_precision_macro</td><td>▇▇███▆▅▆▅▅▅▅▄▄▅▅▄▄▅▄▄▄▄▅▅▅▅▄▅▃▅▇▅▄▆▅▃▁▄▅</td></tr><tr><td>val_recall_macro</td><td>▁████▆▆▆▅▄▅▄▃▄▅▄▅▄▅▄▄▄▄▅▅▅▅▄▅▃▄▄▅▄▅▄▄▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>7e-05</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>scheduler</td><td></td></tr><tr><td>test_accuracy</td><td>0.80833</td></tr><tr><td>test_f1_macro</td><td>0.76523</td></tr><tr><td>test_f1_weighted</td><td>0.81557</td></tr><tr><td>test_loss</td><td>0.47794</td></tr><tr><td>test_precision_macro</td><td>0.75103</td></tr><tr><td>test_recall_macro</td><td>0.79235</td></tr><tr><td>train_accuracy</td><td>0.98193</td></tr><tr><td>train_f1_macro</td><td>0.98103</td></tr><tr><td>train_f1_weighted</td><td>0.98197</td></tr><tr><td>train_loss</td><td>0.04104</td></tr><tr><td>train_precision_macro</td><td>0.97909</td></tr><tr><td>train_recall_macro</td><td>0.98317</td></tr><tr><td>val_accuracy</td><td>0.64465</td></tr><tr><td>val_f1_macro</td><td>0.63454</td></tr><tr><td>val_f1_weighted</td><td>0.64838</td></tr><tr><td>val_loss</td><td>2.1039</td></tr><tr><td>val_precision_macro</td><td>0.63419</td></tr><tr><td>val_recall_macro</td><td>0.63998</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-1</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/grwyr31i' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/grwyr31i</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_131655-grwyr31i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mmrqw45x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.6777041298690144e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling: cls\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_last_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'roberta-sweep' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250518_133947-mmrqw45x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/mmrqw45x' target=\"_blank\">earnest-sweep-2</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/mmrqw45x' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/mmrqw45x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6459\n",
      "Train Accuracy: 0.6235\n",
      "Train F1 (macro): 0.6159\n",
      "\n",
      "Val Loss: 0.6299\n",
      "Val Accuracy: 0.6207\n",
      "Val F1 (macro): 0.6206\n",
      "\n",
      "New best model saved (F1: 0.6206, Acc: 0.6207)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6253\n",
      "Train Accuracy: 0.6418\n",
      "Train F1 (macro): 0.6334\n",
      "\n",
      "Val Loss: 0.6191\n",
      "Val Accuracy: 0.6623\n",
      "Val F1 (macro): 0.6571\n",
      "\n",
      "New best model saved (F1: 0.6571, Acc: 0.6623)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6185\n",
      "Train Accuracy: 0.6533\n",
      "Train F1 (macro): 0.6430\n",
      "\n",
      "Val Loss: 0.6148\n",
      "Val Accuracy: 0.6720\n",
      "Val F1 (macro): 0.6613\n",
      "\n",
      "New best model saved (F1: 0.6613, Acc: 0.6720)\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.6089\n",
      "Train Accuracy: 0.6602\n",
      "Train F1 (macro): 0.6498\n",
      "\n",
      "Val Loss: 0.6187\n",
      "Val Accuracy: 0.6902\n",
      "Val F1 (macro): 0.6702\n",
      "\n",
      "New best model saved (F1: 0.6702, Acc: 0.6902)\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.6022\n",
      "Train Accuracy: 0.6692\n",
      "Train F1 (macro): 0.6601\n",
      "\n",
      "Val Loss: 0.6009\n",
      "Val Accuracy: 0.6691\n",
      "Val F1 (macro): 0.6588\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.5974\n",
      "Train Accuracy: 0.6787\n",
      "Train F1 (macro): 0.6672\n",
      "\n",
      "Val Loss: 0.6067\n",
      "Val Accuracy: 0.6503\n",
      "Val F1 (macro): 0.6484\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.5873\n",
      "Train Accuracy: 0.6826\n",
      "Train F1 (macro): 0.6712\n",
      "\n",
      "Val Loss: 0.6066\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6327\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.5816\n",
      "Train Accuracy: 0.6765\n",
      "Train F1 (macro): 0.6646\n",
      "\n",
      "Val Loss: 0.6125\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6337\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.5716\n",
      "Train Accuracy: 0.6936\n",
      "Train F1 (macro): 0.6808\n",
      "\n",
      "Val Loss: 0.6122\n",
      "Val Accuracy: 0.6606\n",
      "Val F1 (macro): 0.6549\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.5702\n",
      "Train Accuracy: 0.6904\n",
      "Train F1 (macro): 0.6798\n",
      "\n",
      "Val Loss: 0.6093\n",
      "Val Accuracy: 0.6976\n",
      "Val F1 (macro): 0.6687\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.5558\n",
      "Train Accuracy: 0.6970\n",
      "Train F1 (macro): 0.6876\n",
      "\n",
      "Val Loss: 0.6408\n",
      "Val Accuracy: 0.6691\n",
      "Val F1 (macro): 0.6538\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.5455\n",
      "Train Accuracy: 0.7107\n",
      "Train F1 (macro): 0.7006\n",
      "\n",
      "Val Loss: 0.6720\n",
      "Val Accuracy: 0.6076\n",
      "Val F1 (macro): 0.6071\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.5353\n",
      "Train Accuracy: 0.7134\n",
      "Train F1 (macro): 0.7048\n",
      "\n",
      "Val Loss: 0.6405\n",
      "Val Accuracy: 0.5951\n",
      "Val F1 (macro): 0.5942\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.5104\n",
      "Train Accuracy: 0.7346\n",
      "Train F1 (macro): 0.7266\n",
      "\n",
      "Val Loss: 0.6825\n",
      "Val Accuracy: 0.6196\n",
      "Val F1 (macro): 0.6184\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.4999\n",
      "Train Accuracy: 0.7368\n",
      "Train F1 (macro): 0.7294\n",
      "\n",
      "Val Loss: 0.6970\n",
      "Val Accuracy: 0.6230\n",
      "Val F1 (macro): 0.6194\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.4783\n",
      "Train Accuracy: 0.7598\n",
      "Train F1 (macro): 0.7525\n",
      "\n",
      "Val Loss: 0.7116\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6305\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.4541\n",
      "Train Accuracy: 0.7710\n",
      "Train F1 (macro): 0.7634\n",
      "\n",
      "Val Loss: 0.7513\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6282\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.4341\n",
      "Train Accuracy: 0.7925\n",
      "Train F1 (macro): 0.7866\n",
      "\n",
      "Val Loss: 0.7885\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6278\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.4014\n",
      "Train Accuracy: 0.8103\n",
      "Train F1 (macro): 0.8046\n",
      "\n",
      "Val Loss: 0.8092\n",
      "Val Accuracy: 0.6663\n",
      "Val F1 (macro): 0.6515\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.3791\n",
      "Train Accuracy: 0.8167\n",
      "Train F1 (macro): 0.8104\n",
      "\n",
      "Val Loss: 0.8648\n",
      "Val Accuracy: 0.6526\n",
      "Val F1 (macro): 0.6394\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.3515\n",
      "Train Accuracy: 0.8364\n",
      "Train F1 (macro): 0.8313\n",
      "\n",
      "Val Loss: 0.9047\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6296\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.3257\n",
      "Train Accuracy: 0.8447\n",
      "Train F1 (macro): 0.8398\n",
      "\n",
      "Val Loss: 0.9609\n",
      "Val Accuracy: 0.6213\n",
      "Val F1 (macro): 0.6089\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.2963\n",
      "Train Accuracy: 0.8679\n",
      "Train F1 (macro): 0.8635\n",
      "\n",
      "Val Loss: 1.0956\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6261\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.2819\n",
      "Train Accuracy: 0.8721\n",
      "Train F1 (macro): 0.8674\n",
      "\n",
      "Val Loss: 1.1038\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6291\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.2544\n",
      "Train Accuracy: 0.8848\n",
      "Train F1 (macro): 0.8807\n",
      "\n",
      "Val Loss: 1.2890\n",
      "Val Accuracy: 0.6481\n",
      "Val F1 (macro): 0.6381\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.2373\n",
      "Train Accuracy: 0.8928\n",
      "Train F1 (macro): 0.8889\n",
      "\n",
      "Val Loss: 1.1743\n",
      "Val Accuracy: 0.6566\n",
      "Val F1 (macro): 0.6339\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.2294\n",
      "Train Accuracy: 0.8994\n",
      "Train F1 (macro): 0.8956\n",
      "\n",
      "Val Loss: 1.2427\n",
      "Val Accuracy: 0.6503\n",
      "Val F1 (macro): 0.6206\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.1993\n",
      "Train Accuracy: 0.9131\n",
      "Train F1 (macro): 0.9096\n",
      "\n",
      "Val Loss: 1.3208\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6322\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.1986\n",
      "Train Accuracy: 0.9172\n",
      "Train F1 (macro): 0.9138\n",
      "\n",
      "Val Loss: 1.3690\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6154\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.1866\n",
      "Train Accuracy: 0.9175\n",
      "Train F1 (macro): 0.9140\n",
      "\n",
      "Val Loss: 1.3712\n",
      "Val Accuracy: 0.6424\n",
      "Val F1 (macro): 0.6293\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.1816\n",
      "Train Accuracy: 0.9258\n",
      "Train F1 (macro): 0.9227\n",
      "\n",
      "Val Loss: 1.3256\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6364\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.1603\n",
      "Train Accuracy: 0.9348\n",
      "Train F1 (macro): 0.9319\n",
      "\n",
      "Val Loss: 1.4847\n",
      "Val Accuracy: 0.6054\n",
      "Val F1 (macro): 0.5956\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.1692\n",
      "Train Accuracy: 0.9329\n",
      "Train F1 (macro): 0.9299\n",
      "\n",
      "Val Loss: 1.3887\n",
      "Val Accuracy: 0.6549\n",
      "Val F1 (macro): 0.6372\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.1474\n",
      "Train Accuracy: 0.9407\n",
      "Train F1 (macro): 0.9379\n",
      "\n",
      "Val Loss: 1.4529\n",
      "Val Accuracy: 0.6287\n",
      "Val F1 (macro): 0.6071\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.1469\n",
      "Train Accuracy: 0.9404\n",
      "Train F1 (macro): 0.9377\n",
      "\n",
      "Val Loss: 1.4863\n",
      "Val Accuracy: 0.6395\n",
      "Val F1 (macro): 0.6162\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.1474\n",
      "Train Accuracy: 0.9407\n",
      "Train F1 (macro): 0.9379\n",
      "\n",
      "Val Loss: 1.4463\n",
      "Val Accuracy: 0.6304\n",
      "Val F1 (macro): 0.6139\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.1261\n",
      "Train Accuracy: 0.9480\n",
      "Train F1 (macro): 0.9456\n",
      "\n",
      "Val Loss: 1.9155\n",
      "Val Accuracy: 0.6287\n",
      "Val F1 (macro): 0.5965\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.1281\n",
      "Train Accuracy: 0.9495\n",
      "Train F1 (macro): 0.9470\n",
      "\n",
      "Val Loss: 1.6386\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6153\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.1151\n",
      "Train Accuracy: 0.9497\n",
      "Train F1 (macro): 0.9473\n",
      "\n",
      "Val Loss: 1.4983\n",
      "Val Accuracy: 0.6293\n",
      "Val F1 (macro): 0.6064\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.1131\n",
      "Train Accuracy: 0.9580\n",
      "Train F1 (macro): 0.9560\n",
      "\n",
      "Val Loss: 1.7506\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6116\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.1092\n",
      "Train Accuracy: 0.9536\n",
      "Train F1 (macro): 0.9513\n",
      "\n",
      "Val Loss: 1.7367\n",
      "Val Accuracy: 0.6185\n",
      "Val F1 (macro): 0.6011\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.1044\n",
      "Train Accuracy: 0.9583\n",
      "Train F1 (macro): 0.9562\n",
      "\n",
      "Val Loss: 1.7431\n",
      "Val Accuracy: 0.6424\n",
      "Val F1 (macro): 0.6165\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.0977\n",
      "Train Accuracy: 0.9636\n",
      "Train F1 (macro): 0.9618\n",
      "\n",
      "Val Loss: 1.8213\n",
      "Val Accuracy: 0.6156\n",
      "Val F1 (macro): 0.6088\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.1005\n",
      "Train Accuracy: 0.9587\n",
      "Train F1 (macro): 0.9568\n",
      "\n",
      "Val Loss: 1.7627\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6109\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.1039\n",
      "Train Accuracy: 0.9622\n",
      "Train F1 (macro): 0.9603\n",
      "\n",
      "Val Loss: 1.7694\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6193\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.0836\n",
      "Train Accuracy: 0.9683\n",
      "Train F1 (macro): 0.9666\n",
      "\n",
      "Val Loss: 1.9015\n",
      "Val Accuracy: 0.6150\n",
      "Val F1 (macro): 0.5999\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.0912\n",
      "Train Accuracy: 0.9629\n",
      "Train F1 (macro): 0.9611\n",
      "\n",
      "Val Loss: 2.0050\n",
      "Val Accuracy: 0.6315\n",
      "Val F1 (macro): 0.5966\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.0990\n",
      "Train Accuracy: 0.9602\n",
      "Train F1 (macro): 0.9583\n",
      "\n",
      "Val Loss: 1.6442\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6137\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.0875\n",
      "Train Accuracy: 0.9668\n",
      "Train F1 (macro): 0.9651\n",
      "\n",
      "Val Loss: 1.7938\n",
      "Val Accuracy: 0.6196\n",
      "Val F1 (macro): 0.6050\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.0808\n",
      "Train Accuracy: 0.9646\n",
      "Train F1 (macro): 0.9628\n",
      "\n",
      "Val Loss: 1.9556\n",
      "Val Accuracy: 0.6179\n",
      "Val F1 (macro): 0.6100\n",
      "\n",
      "Test Loss: 0.5318\n",
      "Test Accuracy: 0.8222\n",
      "Test F1 (macro): 0.7580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_f1_macro</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_f1_weighted</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_loss</td><td>████▇▇▇▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_precision_macro</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_recall_macro</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>val_accuracy</td><td>▃▆▆▇▆▄▅█▂▁▃▅▄▄▆▄▃▄▄▅▅▄▄▄▅▅▃▄▃▃▃▃▃▄▂▄▂▃▄▃</td></tr><tr><td>val_f1_macro</td><td>▃▇▇█▇▅▅▇█▆▁▃▄▄▄▅▄▂▄▄▅▃▅▃▄▁▅▃▃▁▂▃▂▃▂▃▂▁▃▂</td></tr><tr><td>val_f1_weighted</td><td>▂▆▇▆▅▄▆█▆▁▂▃▄▄▄▅▃▂▃▃▅▄▄▃▄▁▅▃▃▃▃▃▃▂▄▃▃▂▂▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅█▅▇▇▇▇▇▇█▆█</td></tr><tr><td>val_precision_macro</td><td>▅▆▆▆▆▅▆█▄▅▃▄▃▃▅▄▂▃▄▄▃▄▂▄▄▄▂▃▂▁▂▂▁▃▂▃▁▁▂▂</td></tr><tr><td>val_recall_macro</td><td>▆████▇▆██▇▅▅▅▄▄▇▅▆▃▅▆▅▃▅▃▅▂▅▂▁▂▃▂▃▃▄▂▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>6e-05</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>scheduler</td><td></td></tr><tr><td>test_accuracy</td><td>0.8222</td></tr><tr><td>test_f1_macro</td><td>0.75796</td></tr><tr><td>test_f1_weighted</td><td>0.82036</td></tr><tr><td>test_loss</td><td>0.53179</td></tr><tr><td>test_precision_macro</td><td>0.76364</td></tr><tr><td>test_recall_macro</td><td>0.75296</td></tr><tr><td>train_accuracy</td><td>0.9646</td></tr><tr><td>train_f1_macro</td><td>0.96283</td></tr><tr><td>train_f1_weighted</td><td>0.96467</td></tr><tr><td>train_loss</td><td>0.08078</td></tr><tr><td>train_precision_macro</td><td>0.96101</td></tr><tr><td>train_recall_macro</td><td>0.96484</td></tr><tr><td>val_accuracy</td><td>0.61788</td></tr><tr><td>val_f1_macro</td><td>0.61004</td></tr><tr><td>val_f1_weighted</td><td>0.62264</td></tr><tr><td>val_loss</td><td>1.95556</td></tr><tr><td>val_precision_macro</td><td>0.61187</td></tr><tr><td>val_recall_macro</td><td>0.61763</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-2</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/mmrqw45x' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/mmrqw45x</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_133947-mmrqw45x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f7wkw2ct with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.610627871731128e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling: cls\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_last_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'roberta-sweep' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250518_140104-f7wkw2ct</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/f7wkw2ct' target=\"_blank\">easy-sweep-3</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/f7wkw2ct' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/f7wkw2ct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6400\n",
      "Train Accuracy: 0.6238\n",
      "Train F1 (macro): 0.6202\n",
      "\n",
      "Val Loss: 0.6134\n",
      "Val Accuracy: 0.6726\n",
      "Val F1 (macro): 0.6605\n",
      "\n",
      "New best model saved (F1: 0.6605, Acc: 0.6726)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6201\n",
      "Train Accuracy: 0.6646\n",
      "Train F1 (macro): 0.6548\n",
      "\n",
      "Val Loss: 0.6342\n",
      "Val Accuracy: 0.5359\n",
      "Val F1 (macro): 0.5224\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6011\n",
      "Train Accuracy: 0.6680\n",
      "Train F1 (macro): 0.6585\n",
      "\n",
      "Val Loss: 0.6090\n",
      "Val Accuracy: 0.7050\n",
      "Val F1 (macro): 0.6585\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.5862\n",
      "Train Accuracy: 0.6777\n",
      "Train F1 (macro): 0.6680\n",
      "\n",
      "Val Loss: 0.6009\n",
      "Val Accuracy: 0.6686\n",
      "Val F1 (macro): 0.6619\n",
      "\n",
      "New best model saved (F1: 0.6619, Acc: 0.6686)\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.5703\n",
      "Train Accuracy: 0.6992\n",
      "Train F1 (macro): 0.6878\n",
      "\n",
      "Val Loss: 0.6297\n",
      "Val Accuracy: 0.5900\n",
      "Val F1 (macro): 0.5876\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.5574\n",
      "Train Accuracy: 0.7036\n",
      "Train F1 (macro): 0.6952\n",
      "\n",
      "Val Loss: 0.6369\n",
      "Val Accuracy: 0.7073\n",
      "Val F1 (macro): 0.6686\n",
      "\n",
      "New best model saved (F1: 0.6686, Acc: 0.7073)\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.5149\n",
      "Train Accuracy: 0.7400\n",
      "Train F1 (macro): 0.7318\n",
      "\n",
      "Val Loss: 0.6188\n",
      "Val Accuracy: 0.6418\n",
      "Val F1 (macro): 0.6401\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.5099\n",
      "Train Accuracy: 0.7458\n",
      "Train F1 (macro): 0.7376\n",
      "\n",
      "Val Loss: 0.6624\n",
      "Val Accuracy: 0.6936\n",
      "Val F1 (macro): 0.6373\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.4626\n",
      "Train Accuracy: 0.7764\n",
      "Train F1 (macro): 0.7698\n",
      "\n",
      "Val Loss: 0.8144\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6377\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.4411\n",
      "Train Accuracy: 0.7874\n",
      "Train F1 (macro): 0.7797\n",
      "\n",
      "Val Loss: 0.7033\n",
      "Val Accuracy: 0.6731\n",
      "Val F1 (macro): 0.6541\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.4014\n",
      "Train Accuracy: 0.8115\n",
      "Train F1 (macro): 0.8060\n",
      "\n",
      "Val Loss: 0.8381\n",
      "Val Accuracy: 0.6731\n",
      "Val F1 (macro): 0.6576\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.3597\n",
      "Train Accuracy: 0.8345\n",
      "Train F1 (macro): 0.8288\n",
      "\n",
      "Val Loss: 0.9332\n",
      "Val Accuracy: 0.6646\n",
      "Val F1 (macro): 0.6516\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.3133\n",
      "Train Accuracy: 0.8662\n",
      "Train F1 (macro): 0.8614\n",
      "\n",
      "Val Loss: 0.8505\n",
      "Val Accuracy: 0.6219\n",
      "Val F1 (macro): 0.6154\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.2789\n",
      "Train Accuracy: 0.8872\n",
      "Train F1 (macro): 0.8825\n",
      "\n",
      "Val Loss: 0.9218\n",
      "Val Accuracy: 0.6691\n",
      "Val F1 (macro): 0.6449\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.2462\n",
      "Train Accuracy: 0.8950\n",
      "Train F1 (macro): 0.8905\n",
      "\n",
      "Val Loss: 1.2106\n",
      "Val Accuracy: 0.6743\n",
      "Val F1 (macro): 0.6203\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.2136\n",
      "Train Accuracy: 0.9131\n",
      "Train F1 (macro): 0.9091\n",
      "\n",
      "Val Loss: 1.2603\n",
      "Val Accuracy: 0.6469\n",
      "Val F1 (macro): 0.6377\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.1959\n",
      "Train Accuracy: 0.9192\n",
      "Train F1 (macro): 0.9156\n",
      "\n",
      "Val Loss: 1.1407\n",
      "Val Accuracy: 0.6549\n",
      "Val F1 (macro): 0.6364\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.1789\n",
      "Train Accuracy: 0.9255\n",
      "Train F1 (macro): 0.9222\n",
      "\n",
      "Val Loss: 1.1861\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6321\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.1690\n",
      "Train Accuracy: 0.9368\n",
      "Train F1 (macro): 0.9339\n",
      "\n",
      "Val Loss: 1.3284\n",
      "Val Accuracy: 0.6731\n",
      "Val F1 (macro): 0.6521\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.1393\n",
      "Train Accuracy: 0.9409\n",
      "Train F1 (macro): 0.9381\n",
      "\n",
      "Val Loss: 1.5175\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6269\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.1236\n",
      "Train Accuracy: 0.9563\n",
      "Train F1 (macro): 0.9542\n",
      "\n",
      "Val Loss: 1.5091\n",
      "Val Accuracy: 0.6031\n",
      "Val F1 (macro): 0.6009\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.1062\n",
      "Train Accuracy: 0.9595\n",
      "Train F1 (macro): 0.9575\n",
      "\n",
      "Val Loss: 2.0639\n",
      "Val Accuracy: 0.6543\n",
      "Val F1 (macro): 0.6178\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.1121\n",
      "Train Accuracy: 0.9575\n",
      "Train F1 (macro): 0.9556\n",
      "\n",
      "Val Loss: 1.2838\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6177\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.1109\n",
      "Train Accuracy: 0.9565\n",
      "Train F1 (macro): 0.9545\n",
      "\n",
      "Val Loss: 1.3671\n",
      "Val Accuracy: 0.6475\n",
      "Val F1 (macro): 0.6295\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.0953\n",
      "Train Accuracy: 0.9619\n",
      "Train F1 (macro): 0.9601\n",
      "\n",
      "Val Loss: 1.7020\n",
      "Val Accuracy: 0.6498\n",
      "Val F1 (macro): 0.6193\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.0925\n",
      "Train Accuracy: 0.9612\n",
      "Train F1 (macro): 0.9593\n",
      "\n",
      "Val Loss: 1.9293\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6238\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.0919\n",
      "Train Accuracy: 0.9678\n",
      "Train F1 (macro): 0.9662\n",
      "\n",
      "Val Loss: 1.3673\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6185\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.0959\n",
      "Train Accuracy: 0.9636\n",
      "Train F1 (macro): 0.9618\n",
      "\n",
      "Val Loss: 1.9505\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6142\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.0834\n",
      "Train Accuracy: 0.9675\n",
      "Train F1 (macro): 0.9659\n",
      "\n",
      "Val Loss: 1.8226\n",
      "Val Accuracy: 0.6202\n",
      "Val F1 (macro): 0.6055\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.0798\n",
      "Train Accuracy: 0.9722\n",
      "Train F1 (macro): 0.9707\n",
      "\n",
      "Val Loss: 1.7798\n",
      "Val Accuracy: 0.6315\n",
      "Val F1 (macro): 0.6252\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.0685\n",
      "Train Accuracy: 0.9751\n",
      "Train F1 (macro): 0.9738\n",
      "\n",
      "Val Loss: 2.0197\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6149\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.0749\n",
      "Train Accuracy: 0.9707\n",
      "Train F1 (macro): 0.9693\n",
      "\n",
      "Val Loss: 1.6524\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6230\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.0588\n",
      "Train Accuracy: 0.9744\n",
      "Train F1 (macro): 0.9731\n",
      "\n",
      "Val Loss: 2.1964\n",
      "Val Accuracy: 0.6634\n",
      "Val F1 (macro): 0.6457\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.0689\n",
      "Train Accuracy: 0.9731\n",
      "Train F1 (macro): 0.9718\n",
      "\n",
      "Val Loss: 2.0449\n",
      "Val Accuracy: 0.6794\n",
      "Val F1 (macro): 0.6412\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.0869\n",
      "Train Accuracy: 0.9697\n",
      "Train F1 (macro): 0.9682\n",
      "\n",
      "Val Loss: 1.6655\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6256\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.0602\n",
      "Train Accuracy: 0.9763\n",
      "Train F1 (macro): 0.9751\n",
      "\n",
      "Val Loss: 1.8747\n",
      "Val Accuracy: 0.6521\n",
      "Val F1 (macro): 0.6228\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.0652\n",
      "Train Accuracy: 0.9756\n",
      "Train F1 (macro): 0.9743\n",
      "\n",
      "Val Loss: 1.9073\n",
      "Val Accuracy: 0.6674\n",
      "Val F1 (macro): 0.6368\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.0535\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9777\n",
      "\n",
      "Val Loss: 2.0408\n",
      "Val Accuracy: 0.6122\n",
      "Val F1 (macro): 0.5988\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.0619\n",
      "Train Accuracy: 0.9744\n",
      "Train F1 (macro): 0.9731\n",
      "\n",
      "Val Loss: 2.0161\n",
      "Val Accuracy: 0.6407\n",
      "Val F1 (macro): 0.6250\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.0715\n",
      "Train Accuracy: 0.9734\n",
      "Train F1 (macro): 0.9721\n",
      "\n",
      "Val Loss: 1.9213\n",
      "Val Accuracy: 0.6378\n",
      "Val F1 (macro): 0.6154\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.0576\n",
      "Train Accuracy: 0.9778\n",
      "Train F1 (macro): 0.9767\n",
      "\n",
      "Val Loss: 1.9094\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6228\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.0536\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9777\n",
      "\n",
      "Val Loss: 1.8622\n",
      "Val Accuracy: 0.6122\n",
      "Val F1 (macro): 0.6081\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.0562\n",
      "Train Accuracy: 0.9780\n",
      "Train F1 (macro): 0.9769\n",
      "\n",
      "Val Loss: 2.0041\n",
      "Val Accuracy: 0.6498\n",
      "Val F1 (macro): 0.6307\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.0443\n",
      "Train Accuracy: 0.9812\n",
      "Train F1 (macro): 0.9802\n",
      "\n",
      "Val Loss: 2.1470\n",
      "Val Accuracy: 0.6207\n",
      "Val F1 (macro): 0.6151\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.0518\n",
      "Train Accuracy: 0.9790\n",
      "Train F1 (macro): 0.9780\n",
      "\n",
      "Val Loss: 1.8949\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6279\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.0568\n",
      "Train Accuracy: 0.9753\n",
      "Train F1 (macro): 0.9741\n",
      "\n",
      "Val Loss: 1.8708\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6242\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.0538\n",
      "Train Accuracy: 0.9771\n",
      "Train F1 (macro): 0.9759\n",
      "\n",
      "Val Loss: 1.8685\n",
      "Val Accuracy: 0.6344\n",
      "Val F1 (macro): 0.6302\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.0467\n",
      "Train Accuracy: 0.9800\n",
      "Train F1 (macro): 0.9790\n",
      "\n",
      "Val Loss: 2.5959\n",
      "Val Accuracy: 0.6743\n",
      "Val F1 (macro): 0.6489\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.0584\n",
      "Train Accuracy: 0.9775\n",
      "Train F1 (macro): 0.9764\n",
      "\n",
      "Val Loss: 1.5879\n",
      "Val Accuracy: 0.6515\n",
      "Val F1 (macro): 0.6295\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.0423\n",
      "Train Accuracy: 0.9827\n",
      "Train F1 (macro): 0.9818\n",
      "\n",
      "Val Loss: 2.1292\n",
      "Val Accuracy: 0.6378\n",
      "Val F1 (macro): 0.6288\n",
      "\n",
      "Test Loss: 0.4159\n",
      "Test Accuracy: 0.8291\n",
      "Test F1 (macro): 0.7764\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▂▂▂▃▃▄▄▅▆▇▇▇▇▇██▇█████████████████████</td></tr><tr><td>train_f1_macro</td><td>▁▂▂▂▂▃▃▄▄▅▆▆▆▇▇▇▇▇██████████████████████</td></tr><tr><td>train_f1_weighted</td><td>▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>train_loss</td><td>███▇▇▇▆▆▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_precision_macro</td><td>▁▂▂▂▂▃▃▄▄▄▆▆▆▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>train_recall_macro</td><td>▁▂▂▂▂▃▃▄▄▅▆▆▆▇▇▇▇▇█▇████████████████████</td></tr><tr><td>val_accuracy</td><td>▇▁█▆▃▅█▅▇▇▅▇▇▆▆▇▄▆▅▆▅▅▅▄▅▅▆▇▅▆▄▅▅▅▄▅▅▅▇▅</td></tr><tr><td>val_f1_macro</td><td>█▁█▄█▇▇▇▇▇▇▆▇▆▆▆▅▆▆▆▆▆▅▅▆▇▇▆▆▆▆▅▆▅▆▆▆▆▇▆</td></tr><tr><td>val_f1_weighted</td><td>█▁█▇▄▆▇▇█▇▇▇▇▇▇▆▅▆▆▇▆▆▆▆▆▆▇▇▆▇▆▆▆▅▇▆▆▆▇▆</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▂▁▂▂▂▄▄▄▅▅▇▄▄▇▄▇▆▆▆█▇▆▇▇▇▇▇▇█▇▇▇█</td></tr><tr><td>val_precision_macro</td><td>▅▄█▆▅▅▇▄▅▅▂▄▅▄▄▅▃▂▃▂▃▃▂▂▁▃▄▅▃▃▁▃▂▃▃▃▃▄▅▃</td></tr><tr><td>val_recall_macro</td><td>▇▁▆█▅▇▅▆▆▇▃▅▃▅▄▄▃▂▃▄▄▃▂▂▄▃▅▅▄▃▁▃▃▃▄▄▄▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>7e-05</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>scheduler</td><td></td></tr><tr><td>test_accuracy</td><td>0.82914</td></tr><tr><td>test_f1_macro</td><td>0.77639</td></tr><tr><td>test_f1_weighted</td><td>0.83074</td></tr><tr><td>test_loss</td><td>0.41589</td></tr><tr><td>test_precision_macro</td><td>0.77152</td></tr><tr><td>test_recall_macro</td><td>0.7819</td></tr><tr><td>train_accuracy</td><td>0.98267</td></tr><tr><td>train_f1_macro</td><td>0.98176</td></tr><tr><td>train_f1_weighted</td><td>0.98268</td></tr><tr><td>train_loss</td><td>0.04227</td></tr><tr><td>train_precision_macro</td><td>0.98094</td></tr><tr><td>train_recall_macro</td><td>0.9826</td></tr><tr><td>val_accuracy</td><td>0.63781</td></tr><tr><td>val_f1_macro</td><td>0.62877</td></tr><tr><td>val_f1_weighted</td><td>0.64197</td></tr><tr><td>val_loss</td><td>2.12921</td></tr><tr><td>val_precision_macro</td><td>0.62913</td></tr><tr><td>val_recall_macro</td><td>0.63523</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-sweep-3</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/f7wkw2ct' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/f7wkw2ct</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_140104-f7wkw2ct/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: egtfr0rw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.08747411048867e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: roberta-base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling: attention_pooling\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_last_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'roberta-sweep' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250518_142305-egtfr0rw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/egtfr0rw' target=\"_blank\">prime-sweep-4</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/egtfr0rw' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/egtfr0rw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6499\n",
      "Train Accuracy: 0.6282\n",
      "Train F1 (macro): 0.6141\n",
      "\n",
      "Val Loss: 0.6492\n",
      "Val Accuracy: 0.6241\n",
      "Val F1 (macro): 0.6236\n",
      "\n",
      "New best model saved (F1: 0.6236, Acc: 0.6241)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6045\n",
      "Train Accuracy: 0.6807\n",
      "Train F1 (macro): 0.6645\n",
      "\n",
      "Val Loss: 0.6522\n",
      "Val Accuracy: 0.6691\n",
      "Val F1 (macro): 0.6612\n",
      "\n",
      "New best model saved (F1: 0.6612, Acc: 0.6691)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.5621\n",
      "Train Accuracy: 0.7195\n",
      "Train F1 (macro): 0.7056\n",
      "\n",
      "Val Loss: 0.6349\n",
      "Val Accuracy: 0.6948\n",
      "Val F1 (macro): 0.6674\n",
      "\n",
      "New best model saved (F1: 0.6674, Acc: 0.6948)\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.5028\n",
      "Train Accuracy: 0.7732\n",
      "Train F1 (macro): 0.7612\n",
      "\n",
      "Val Loss: 0.6872\n",
      "Val Accuracy: 0.6646\n",
      "Val F1 (macro): 0.6484\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.3920\n",
      "Train Accuracy: 0.8281\n",
      "Train F1 (macro): 0.8218\n",
      "\n",
      "Val Loss: 0.7173\n",
      "Val Accuracy: 0.6167\n",
      "Val F1 (macro): 0.6137\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.2792\n",
      "Train Accuracy: 0.8887\n",
      "Train F1 (macro): 0.8837\n",
      "\n",
      "Val Loss: 0.8899\n",
      "Val Accuracy: 0.6538\n",
      "Val F1 (macro): 0.6416\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.2082\n",
      "Train Accuracy: 0.9231\n",
      "Train F1 (macro): 0.9195\n",
      "\n",
      "Val Loss: 1.1762\n",
      "Val Accuracy: 0.6054\n",
      "Val F1 (macro): 0.6036\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.1602\n",
      "Train Accuracy: 0.9409\n",
      "Train F1 (macro): 0.9381\n",
      "\n",
      "Val Loss: 1.1592\n",
      "Val Accuracy: 0.6105\n",
      "Val F1 (macro): 0.6024\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.1235\n",
      "Train Accuracy: 0.9573\n",
      "Train F1 (macro): 0.9552\n",
      "\n",
      "Val Loss: 1.3454\n",
      "Val Accuracy: 0.6059\n",
      "Val F1 (macro): 0.6019\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.1059\n",
      "Train Accuracy: 0.9587\n",
      "Train F1 (macro): 0.9568\n",
      "\n",
      "Val Loss: 1.4992\n",
      "Val Accuracy: 0.6122\n",
      "Val F1 (macro): 0.6084\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.0840\n",
      "Train Accuracy: 0.9680\n",
      "Train F1 (macro): 0.9664\n",
      "\n",
      "Val Loss: 1.5811\n",
      "Val Accuracy: 0.6344\n",
      "Val F1 (macro): 0.6170\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.0755\n",
      "Train Accuracy: 0.9707\n",
      "Train F1 (macro): 0.9692\n",
      "\n",
      "Val Loss: 1.7669\n",
      "Val Accuracy: 0.6674\n",
      "Val F1 (macro): 0.6462\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.0694\n",
      "Train Accuracy: 0.9749\n",
      "Train F1 (macro): 0.9736\n",
      "\n",
      "Val Loss: 1.9185\n",
      "Val Accuracy: 0.6390\n",
      "Val F1 (macro): 0.6287\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.0669\n",
      "Train Accuracy: 0.9722\n",
      "Train F1 (macro): 0.9708\n",
      "\n",
      "Val Loss: 1.6874\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6235\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.0610\n",
      "Train Accuracy: 0.9756\n",
      "Train F1 (macro): 0.9743\n",
      "\n",
      "Val Loss: 1.7356\n",
      "Val Accuracy: 0.6674\n",
      "Val F1 (macro): 0.6484\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.0584\n",
      "Train Accuracy: 0.9780\n",
      "Train F1 (macro): 0.9768\n",
      "\n",
      "Val Loss: 1.9753\n",
      "Val Accuracy: 0.6486\n",
      "Val F1 (macro): 0.6387\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.0518\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9777\n",
      "\n",
      "Val Loss: 1.6554\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6278\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.0570\n",
      "Train Accuracy: 0.9768\n",
      "Train F1 (macro): 0.9756\n",
      "\n",
      "Val Loss: 1.8712\n",
      "Val Accuracy: 0.6503\n",
      "Val F1 (macro): 0.6341\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.0592\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9777\n",
      "\n",
      "Val Loss: 1.7856\n",
      "Val Accuracy: 0.6526\n",
      "Val F1 (macro): 0.6241\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.0440\n",
      "Train Accuracy: 0.9814\n",
      "Train F1 (macro): 0.9805\n",
      "\n",
      "Val Loss: 1.7947\n",
      "Val Accuracy: 0.6583\n",
      "Val F1 (macro): 0.6276\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.0453\n",
      "Train Accuracy: 0.9822\n",
      "Train F1 (macro): 0.9813\n",
      "\n",
      "Val Loss: 2.2594\n",
      "Val Accuracy: 0.6669\n",
      "Val F1 (macro): 0.6330\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.0414\n",
      "Train Accuracy: 0.9834\n",
      "Train F1 (macro): 0.9825\n",
      "\n",
      "Val Loss: 1.6120\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6282\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.0467\n",
      "Train Accuracy: 0.9792\n",
      "Train F1 (macro): 0.9781\n",
      "\n",
      "Val Loss: 1.7664\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6303\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.0467\n",
      "Train Accuracy: 0.9819\n",
      "Train F1 (macro): 0.9810\n",
      "\n",
      "Val Loss: 1.9964\n",
      "Val Accuracy: 0.6697\n",
      "Val F1 (macro): 0.6421\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.0448\n",
      "Train Accuracy: 0.9822\n",
      "Train F1 (macro): 0.9812\n",
      "\n",
      "Val Loss: 1.8570\n",
      "Val Accuracy: 0.6475\n",
      "Val F1 (macro): 0.6285\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.0495\n",
      "Train Accuracy: 0.9792\n",
      "Train F1 (macro): 0.9781\n",
      "\n",
      "Val Loss: 1.8462\n",
      "Val Accuracy: 0.6674\n",
      "Val F1 (macro): 0.6360\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.0356\n",
      "Train Accuracy: 0.9851\n",
      "Train F1 (macro): 0.9843\n",
      "\n",
      "Val Loss: 2.1266\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6305\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.0342\n",
      "Train Accuracy: 0.9834\n",
      "Train F1 (macro): 0.9826\n",
      "\n",
      "Val Loss: 1.9474\n",
      "Val Accuracy: 0.6315\n",
      "Val F1 (macro): 0.6210\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.0423\n",
      "Train Accuracy: 0.9819\n",
      "Train F1 (macro): 0.9810\n",
      "\n",
      "Val Loss: 1.9090\n",
      "Val Accuracy: 0.6549\n",
      "Val F1 (macro): 0.6433\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.0306\n",
      "Train Accuracy: 0.9839\n",
      "Train F1 (macro): 0.9831\n",
      "\n",
      "Val Loss: 2.1452\n",
      "Val Accuracy: 0.6367\n",
      "Val F1 (macro): 0.6153\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.0414\n",
      "Train Accuracy: 0.9824\n",
      "Train F1 (macro): 0.9815\n",
      "\n",
      "Val Loss: 2.1884\n",
      "Val Accuracy: 0.6697\n",
      "Val F1 (macro): 0.6413\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.0334\n",
      "Train Accuracy: 0.9858\n",
      "Train F1 (macro): 0.9851\n",
      "\n",
      "Val Loss: 2.2921\n",
      "Val Accuracy: 0.6748\n",
      "Val F1 (macro): 0.6376\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.0347\n",
      "Train Accuracy: 0.9851\n",
      "Train F1 (macro): 0.9843\n",
      "\n",
      "Val Loss: 2.0466\n",
      "Val Accuracy: 0.6680\n",
      "Val F1 (macro): 0.6335\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.0438\n",
      "Train Accuracy: 0.9846\n",
      "Train F1 (macro): 0.9838\n",
      "\n",
      "Val Loss: 2.0865\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6219\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.0458\n",
      "Train Accuracy: 0.9827\n",
      "Train F1 (macro): 0.9818\n",
      "\n",
      "Val Loss: 1.6309\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6235\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.0453\n",
      "Train Accuracy: 0.9841\n",
      "Train F1 (macro): 0.9833\n",
      "\n",
      "Val Loss: 2.0120\n",
      "Val Accuracy: 0.6634\n",
      "Val F1 (macro): 0.6421\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.0423\n",
      "Train Accuracy: 0.9836\n",
      "Train F1 (macro): 0.9828\n",
      "\n",
      "Val Loss: 1.9446\n",
      "Val Accuracy: 0.6481\n",
      "Val F1 (macro): 0.6353\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.0354\n",
      "Train Accuracy: 0.9854\n",
      "Train F1 (macro): 0.9846\n",
      "\n",
      "Val Loss: 1.9538\n",
      "Val Accuracy: 0.6617\n",
      "Val F1 (macro): 0.6492\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.0301\n",
      "Train Accuracy: 0.9861\n",
      "Train F1 (macro): 0.9854\n",
      "\n",
      "Val Loss: 2.0705\n",
      "Val Accuracy: 0.6686\n",
      "Val F1 (macro): 0.6521\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.0296\n",
      "Train Accuracy: 0.9844\n",
      "Train F1 (macro): 0.9836\n",
      "\n",
      "Val Loss: 2.3939\n",
      "Val Accuracy: 0.6811\n",
      "Val F1 (macro): 0.6589\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.0363\n",
      "Train Accuracy: 0.9817\n",
      "Train F1 (macro): 0.9808\n",
      "\n",
      "Val Loss: 2.1266\n",
      "Val Accuracy: 0.6669\n",
      "Val F1 (macro): 0.6330\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.0229\n",
      "Train Accuracy: 0.9883\n",
      "Train F1 (macro): 0.9877\n",
      "\n",
      "Val Loss: 2.5060\n",
      "Val Accuracy: 0.6646\n",
      "Val F1 (macro): 0.6482\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.0275\n",
      "Train Accuracy: 0.9875\n",
      "Train F1 (macro): 0.9869\n",
      "\n",
      "Val Loss: 2.6537\n",
      "Val Accuracy: 0.6606\n",
      "Val F1 (macro): 0.6400\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.0290\n",
      "Train Accuracy: 0.9861\n",
      "Train F1 (macro): 0.9854\n",
      "\n",
      "Val Loss: 2.4064\n",
      "Val Accuracy: 0.6441\n",
      "Val F1 (macro): 0.6346\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.0409\n",
      "Train Accuracy: 0.9844\n",
      "Train F1 (macro): 0.9836\n",
      "\n",
      "Val Loss: 1.6884\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6375\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.0260\n",
      "Train Accuracy: 0.9871\n",
      "Train F1 (macro): 0.9864\n",
      "\n",
      "Val Loss: 2.6112\n",
      "Val Accuracy: 0.6555\n",
      "Val F1 (macro): 0.6413\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.0368\n",
      "Train Accuracy: 0.9822\n",
      "Train F1 (macro): 0.9813\n",
      "\n",
      "Val Loss: 2.0023\n",
      "Val Accuracy: 0.6646\n",
      "Val F1 (macro): 0.6393\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.0256\n",
      "Train Accuracy: 0.9878\n",
      "Train F1 (macro): 0.9872\n",
      "\n",
      "Val Loss: 2.3222\n",
      "Val Accuracy: 0.6703\n",
      "Val F1 (macro): 0.6489\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.0269\n",
      "Train Accuracy: 0.9854\n",
      "Train F1 (macro): 0.9846\n",
      "\n",
      "Val Loss: 2.3459\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6220\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.0317\n",
      "Train Accuracy: 0.9858\n",
      "Train F1 (macro): 0.9851\n",
      "\n",
      "Val Loss: 2.7810\n",
      "Val Accuracy: 0.6572\n",
      "Val F1 (macro): 0.6295\n",
      "\n",
      "Test Loss: 0.4901\n",
      "Test Accuracy: 0.7858\n",
      "Test F1 (macro): 0.7431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▆▇▇▇████████████████████████████████</td></tr><tr><td>train_f1_macro</td><td>▁▂▃▄▅▇▇▇▇███████████████████████████████</td></tr><tr><td>train_f1_weighted</td><td>▁▂▃▄▆▇▇█████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▇▆▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_precision_macro</td><td>▁▂▃▄▅▇▇▇▇███████████████████████████████</td></tr><tr><td>train_recall_macro</td><td>▁▃▄▅▆▇▇▇████████████████████████████████</td></tr><tr><td>val_accuracy</td><td>▂▆█▆▂▁▁▂▃▆▃▆▄▄▅▅▆▄▅▆▆▄▃▅▃▆▆▃▃▆▅▆▇▆▆▄▅▆▆▅</td></tr><tr><td>val_f1_macro</td><td>▃▇█▆▂▁▁▁▂▃▄▃▆▅▄▃▄▄▄▅▅▄▃▅▂▅▄▃▃▅▆▇▄▆▅▅▅▅▆▄</td></tr><tr><td>val_f1_weighted</td><td>▂▇█▆▂▁▂▃▆▄▆▅▄▅▄▅▄▅▆▄▄▃▅▃▆▅▃▃▆▅▆▇▅▆▅▄▅▅▆▅</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▃▃▃▄▅▄▅▅▄▅▆▄▅▅▅▆▅▅▆▆▆▆▄▅▅▆▇▆▇█▄▇▅▇█</td></tr><tr><td>val_precision_macro</td><td>▅▇█▅▃▂▁▁▂▂▃▃▅▄▃▃▄▅▃▄▃▅▃▃▅▆▅▃▃▅▅▆▇▅▅▄▄▅▅▄</td></tr><tr><td>val_recall_macro</td><td>▆█▇▃▅▁▂▂▂▅▃▆▅▃▄▃▃▃▃▅▄▄▃▅▂▄▃▄▃▅▆▇▃▆▄▅▅▄▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>7e-05</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>scheduler</td><td></td></tr><tr><td>test_accuracy</td><td>0.78578</td></tr><tr><td>test_f1_macro</td><td>0.74309</td></tr><tr><td>test_f1_weighted</td><td>0.79549</td></tr><tr><td>test_loss</td><td>0.4901</td></tr><tr><td>test_precision_macro</td><td>0.72978</td></tr><tr><td>test_recall_macro</td><td>0.77616</td></tr><tr><td>train_accuracy</td><td>0.98584</td></tr><tr><td>train_f1_macro</td><td>0.98512</td></tr><tr><td>train_f1_weighted</td><td>0.98587</td></tr><tr><td>train_loss</td><td>0.0317</td></tr><tr><td>train_precision_macro</td><td>0.98345</td></tr><tr><td>train_recall_macro</td><td>0.98694</td></tr><tr><td>val_accuracy</td><td>0.65718</td></tr><tr><td>val_f1_macro</td><td>0.62949</td></tr><tr><td>val_f1_weighted</td><td>0.65256</td></tr><tr><td>val_loss</td><td>2.78102</td></tr><tr><td>val_precision_macro</td><td>0.63454</td></tr><tr><td>val_recall_macro</td><td>0.62747</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-sweep-4</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/egtfr0rw' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/egtfr0rw</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_142305-egtfr0rw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6tn4tw6m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.883329753059166e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling: cls\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_last_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'roberta-sweep' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250518_144552-6tn4tw6m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/6tn4tw6m' target=\"_blank\">expert-sweep-5</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/6tn4tw6m' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/6tn4tw6m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6507\n",
      "Train Accuracy: 0.6143\n",
      "Train F1 (macro): 0.6087\n",
      "\n",
      "Val Loss: 0.6275\n",
      "Val Accuracy: 0.6435\n",
      "Val F1 (macro): 0.6415\n",
      "\n",
      "New best model saved (F1: 0.6415, Acc: 0.6435)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6200\n",
      "Train Accuracy: 0.6584\n",
      "Train F1 (macro): 0.6498\n",
      "\n",
      "Val Loss: 0.6231\n",
      "Val Accuracy: 0.6703\n",
      "Val F1 (macro): 0.6636\n",
      "\n",
      "New best model saved (F1: 0.6636, Acc: 0.6703)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.5932\n",
      "Train Accuracy: 0.6904\n",
      "Train F1 (macro): 0.6798\n",
      "\n",
      "Val Loss: 0.6100\n",
      "Val Accuracy: 0.7039\n",
      "Val F1 (macro): 0.6818\n",
      "\n",
      "New best model saved (F1: 0.6818, Acc: 0.7039)\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.5719\n",
      "Train Accuracy: 0.6934\n",
      "Train F1 (macro): 0.6803\n",
      "\n",
      "Val Loss: 0.6170\n",
      "Val Accuracy: 0.6896\n",
      "Val F1 (macro): 0.6462\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.5420\n",
      "Train Accuracy: 0.7256\n",
      "Train F1 (macro): 0.7155\n",
      "\n",
      "Val Loss: 0.6347\n",
      "Val Accuracy: 0.6293\n",
      "Val F1 (macro): 0.6290\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.5107\n",
      "Train Accuracy: 0.7476\n",
      "Train F1 (macro): 0.7396\n",
      "\n",
      "Val Loss: 0.6862\n",
      "Val Accuracy: 0.6822\n",
      "Val F1 (macro): 0.6659\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.4745\n",
      "Train Accuracy: 0.7717\n",
      "Train F1 (macro): 0.7648\n",
      "\n",
      "Val Loss: 0.7436\n",
      "Val Accuracy: 0.6851\n",
      "Val F1 (macro): 0.6620\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.4145\n",
      "Train Accuracy: 0.7974\n",
      "Train F1 (macro): 0.7894\n",
      "\n",
      "Val Loss: 0.8713\n",
      "Val Accuracy: 0.6657\n",
      "Val F1 (macro): 0.6560\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.3944\n",
      "Train Accuracy: 0.8237\n",
      "Train F1 (macro): 0.8164\n",
      "\n",
      "Val Loss: 0.7715\n",
      "Val Accuracy: 0.6503\n",
      "Val F1 (macro): 0.6224\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.3094\n",
      "Train Accuracy: 0.8694\n",
      "Train F1 (macro): 0.8639\n",
      "\n",
      "Val Loss: 0.8512\n",
      "Val Accuracy: 0.6355\n",
      "Val F1 (macro): 0.6136\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.2527\n",
      "Train Accuracy: 0.9016\n",
      "Train F1 (macro): 0.8973\n",
      "\n",
      "Val Loss: 1.0494\n",
      "Val Accuracy: 0.6395\n",
      "Val F1 (macro): 0.6353\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.2074\n",
      "Train Accuracy: 0.9214\n",
      "Train F1 (macro): 0.9178\n",
      "\n",
      "Val Loss: 1.0734\n",
      "Val Accuracy: 0.6726\n",
      "Val F1 (macro): 0.6524\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.1712\n",
      "Train Accuracy: 0.9299\n",
      "Train F1 (macro): 0.9269\n",
      "\n",
      "Val Loss: 1.2235\n",
      "Val Accuracy: 0.6116\n",
      "Val F1 (macro): 0.6098\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.1512\n",
      "Train Accuracy: 0.9456\n",
      "Train F1 (macro): 0.9429\n",
      "\n",
      "Val Loss: 1.3764\n",
      "Val Accuracy: 0.6583\n",
      "Val F1 (macro): 0.6380\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.1311\n",
      "Train Accuracy: 0.9548\n",
      "Train F1 (macro): 0.9525\n",
      "\n",
      "Val Loss: 1.2837\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6138\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.1099\n",
      "Train Accuracy: 0.9619\n",
      "Train F1 (macro): 0.9599\n",
      "\n",
      "Val Loss: 1.4427\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6110\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.0939\n",
      "Train Accuracy: 0.9663\n",
      "Train F1 (macro): 0.9646\n",
      "\n",
      "Val Loss: 1.6997\n",
      "Val Accuracy: 0.6532\n",
      "Val F1 (macro): 0.6353\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.1151\n",
      "Train Accuracy: 0.9602\n",
      "Train F1 (macro): 0.9583\n",
      "\n",
      "Val Loss: 1.3820\n",
      "Val Accuracy: 0.6538\n",
      "Val F1 (macro): 0.6375\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.0910\n",
      "Train Accuracy: 0.9661\n",
      "Train F1 (macro): 0.9643\n",
      "\n",
      "Val Loss: 1.5689\n",
      "Val Accuracy: 0.6424\n",
      "Val F1 (macro): 0.6220\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.0659\n",
      "Train Accuracy: 0.9756\n",
      "Train F1 (macro): 0.9743\n",
      "\n",
      "Val Loss: 1.9165\n",
      "Val Accuracy: 0.6663\n",
      "Val F1 (macro): 0.6368\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.0976\n",
      "Train Accuracy: 0.9690\n",
      "Train F1 (macro): 0.9674\n",
      "\n",
      "Val Loss: 1.5058\n",
      "Val Accuracy: 0.6726\n",
      "Val F1 (macro): 0.6453\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.0787\n",
      "Train Accuracy: 0.9724\n",
      "Train F1 (macro): 0.9710\n",
      "\n",
      "Val Loss: 1.9336\n",
      "Val Accuracy: 0.6839\n",
      "Val F1 (macro): 0.6436\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.0848\n",
      "Train Accuracy: 0.9717\n",
      "Train F1 (macro): 0.9702\n",
      "\n",
      "Val Loss: 1.6908\n",
      "Val Accuracy: 0.6298\n",
      "Val F1 (macro): 0.6222\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.0671\n",
      "Train Accuracy: 0.9758\n",
      "Train F1 (macro): 0.9746\n",
      "\n",
      "Val Loss: 1.8793\n",
      "Val Accuracy: 0.6464\n",
      "Val F1 (macro): 0.6359\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.0735\n",
      "Train Accuracy: 0.9729\n",
      "Train F1 (macro): 0.9715\n",
      "\n",
      "Val Loss: 1.8001\n",
      "Val Accuracy: 0.6190\n",
      "Val F1 (macro): 0.6132\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.0677\n",
      "Train Accuracy: 0.9761\n",
      "Train F1 (macro): 0.9749\n",
      "\n",
      "Val Loss: 1.6379\n",
      "Val Accuracy: 0.6538\n",
      "Val F1 (macro): 0.6398\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.0876\n",
      "Train Accuracy: 0.9668\n",
      "Train F1 (macro): 0.9652\n",
      "\n",
      "Val Loss: 1.4904\n",
      "Val Accuracy: 0.6492\n",
      "Val F1 (macro): 0.6294\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.0609\n",
      "Train Accuracy: 0.9751\n",
      "Train F1 (macro): 0.9739\n",
      "\n",
      "Val Loss: 1.7153\n",
      "Val Accuracy: 0.6583\n",
      "Val F1 (macro): 0.6437\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.0597\n",
      "Train Accuracy: 0.9780\n",
      "Train F1 (macro): 0.9769\n",
      "\n",
      "Val Loss: 2.0257\n",
      "Val Accuracy: 0.6321\n",
      "Val F1 (macro): 0.6248\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.0577\n",
      "Train Accuracy: 0.9800\n",
      "Train F1 (macro): 0.9789\n",
      "\n",
      "Val Loss: 1.7454\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6201\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.0505\n",
      "Train Accuracy: 0.9810\n",
      "Train F1 (macro): 0.9800\n",
      "\n",
      "Val Loss: 1.9344\n",
      "Val Accuracy: 0.6190\n",
      "Val F1 (macro): 0.6163\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.0537\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9777\n",
      "\n",
      "Val Loss: 1.8823\n",
      "Val Accuracy: 0.6333\n",
      "Val F1 (macro): 0.6245\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.0680\n",
      "Train Accuracy: 0.9724\n",
      "Train F1 (macro): 0.9711\n",
      "\n",
      "Val Loss: 1.8104\n",
      "Val Accuracy: 0.6743\n",
      "Val F1 (macro): 0.6507\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.0474\n",
      "Train Accuracy: 0.9814\n",
      "Train F1 (macro): 0.9805\n",
      "\n",
      "Val Loss: 2.1624\n",
      "Val Accuracy: 0.6703\n",
      "Val F1 (macro): 0.6158\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.0571\n",
      "Train Accuracy: 0.9783\n",
      "Train F1 (macro): 0.9772\n",
      "\n",
      "Val Loss: 1.8930\n",
      "Val Accuracy: 0.6526\n",
      "Val F1 (macro): 0.6326\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.0540\n",
      "Train Accuracy: 0.9758\n",
      "Train F1 (macro): 0.9746\n",
      "\n",
      "Val Loss: 1.7913\n",
      "Val Accuracy: 0.6464\n",
      "Val F1 (macro): 0.6302\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.0496\n",
      "Train Accuracy: 0.9841\n",
      "Train F1 (macro): 0.9833\n",
      "\n",
      "Val Loss: 1.7550\n",
      "Val Accuracy: 0.6458\n",
      "Val F1 (macro): 0.6325\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.0532\n",
      "Train Accuracy: 0.9788\n",
      "Train F1 (macro): 0.9776\n",
      "\n",
      "Val Loss: 2.0710\n",
      "Val Accuracy: 0.6241\n",
      "Val F1 (macro): 0.6176\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.0520\n",
      "Train Accuracy: 0.9783\n",
      "Train F1 (macro): 0.9771\n",
      "\n",
      "Val Loss: 2.1694\n",
      "Val Accuracy: 0.6538\n",
      "Val F1 (macro): 0.6240\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.0538\n",
      "Train Accuracy: 0.9780\n",
      "Train F1 (macro): 0.9769\n",
      "\n",
      "Val Loss: 2.0388\n",
      "Val Accuracy: 0.6532\n",
      "Val F1 (macro): 0.6370\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.0438\n",
      "Train Accuracy: 0.9824\n",
      "Train F1 (macro): 0.9815\n",
      "\n",
      "Val Loss: 1.8419\n",
      "Val Accuracy: 0.6156\n",
      "Val F1 (macro): 0.6120\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.0449\n",
      "Train Accuracy: 0.9812\n",
      "Train F1 (macro): 0.9802\n",
      "\n",
      "Val Loss: 2.0688\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6196\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.0452\n",
      "Train Accuracy: 0.9783\n",
      "Train F1 (macro): 0.9772\n",
      "\n",
      "Val Loss: 2.0227\n",
      "Val Accuracy: 0.6418\n",
      "Val F1 (macro): 0.6335\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.0407\n",
      "Train Accuracy: 0.9834\n",
      "Train F1 (macro): 0.9826\n",
      "\n",
      "Val Loss: 2.2551\n",
      "Val Accuracy: 0.6179\n",
      "Val F1 (macro): 0.6112\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.0466\n",
      "Train Accuracy: 0.9790\n",
      "Train F1 (macro): 0.9780\n",
      "\n",
      "Val Loss: 1.8013\n",
      "Val Accuracy: 0.6572\n",
      "Val F1 (macro): 0.6454\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.0432\n",
      "Train Accuracy: 0.9800\n",
      "Train F1 (macro): 0.9790\n",
      "\n",
      "Val Loss: 1.9184\n",
      "Val Accuracy: 0.6464\n",
      "Val F1 (macro): 0.6343\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.0354\n",
      "Train Accuracy: 0.9824\n",
      "Train F1 (macro): 0.9815\n",
      "\n",
      "Val Loss: 2.1804\n",
      "Val Accuracy: 0.6418\n",
      "Val F1 (macro): 0.6191\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.0485\n",
      "Train Accuracy: 0.9790\n",
      "Train F1 (macro): 0.9779\n",
      "\n",
      "Val Loss: 1.9193\n",
      "Val Accuracy: 0.6344\n",
      "Val F1 (macro): 0.6247\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.0433\n",
      "Train Accuracy: 0.9800\n",
      "Train F1 (macro): 0.9789\n",
      "\n",
      "Val Loss: 2.5987\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6187\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.0410\n",
      "Train Accuracy: 0.9824\n",
      "Train F1 (macro): 0.9816\n",
      "\n",
      "Val Loss: 2.2135\n",
      "Val Accuracy: 0.6253\n",
      "Val F1 (macro): 0.6183\n",
      "\n",
      "Test Loss: 0.4228\n",
      "Test Accuracy: 0.8378\n",
      "Test F1 (macro): 0.7803\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▂▂▃▄▄▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>train_f1_macro</td><td>▁▂▂▂▄▅▆▆▇▇▇█████████████████████████████</td></tr><tr><td>train_f1_weighted</td><td>▁▂▂▂▃▄▄▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▅▄▄▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_precision_macro</td><td>▁▂▂▂▃▄▄▅▆▆▇▇████████████████████████████</td></tr><tr><td>train_recall_macro</td><td>▁▂▂▂▃▄▄▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>val_accuracy</td><td>▃▅█▇▂▇▅▄▃▃▁▅▂▄▄▅▆▆▂▄▄▄▅▃▂▆▅▄▄▄▄▄▁▂▃▄▄▃▃▂</td></tr><tr><td>val_f1_macro</td><td>▄▆█▅▃▆▅▂▁▃▁▄▁▁▃▂▄▄▄▂▁▄▄▂▂▂▅▂▃▃▂▂▄▁▂▁▄▃▂▂</td></tr><tr><td>val_f1_weighted</td><td>▃▆█▆▂▆▃▂▃▅▄▂▂▄▄▄▅▅▂▄▄▃▄▂▂▂▅▃▄▃▂▃▄▁▂▄▄▃▃▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▂▂▂▂▃▄▄▄▅▆▅▇▅▆▇▅▅▆▇▆▇▆█▇▆▇▇▆▇▇▆▇█▇█</td></tr><tr><td>val_precision_macro</td><td>▅▆█▇▅▆▅▂▁▄▂▃▁▃▃▄▅▆▂▃▃▃▄▂▂▂▅▅▃▃▂▃▃▂▂▁▃▂▂▂</td></tr><tr><td>val_recall_macro</td><td>▆▇█▄▆▆▆▂▁▅▃▁▁▃▄▃▄▄▃▄▄▃▄▃▃▃▅▁▃▃▃▂▄▂▂▂▅▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>current_lr</td><td>8e-05</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>scheduler</td><td></td></tr><tr><td>test_accuracy</td><td>0.83781</td></tr><tr><td>test_f1_macro</td><td>0.78028</td></tr><tr><td>test_f1_weighted</td><td>0.83655</td></tr><tr><td>test_loss</td><td>0.42276</td></tr><tr><td>test_precision_macro</td><td>0.78487</td></tr><tr><td>test_recall_macro</td><td>0.7761</td></tr><tr><td>train_accuracy</td><td>0.98242</td></tr><tr><td>train_f1_macro</td><td>0.98155</td></tr><tr><td>train_f1_weighted</td><td>0.98246</td></tr><tr><td>train_loss</td><td>0.04098</td></tr><tr><td>train_precision_macro</td><td>0.97951</td></tr><tr><td>train_recall_macro</td><td>0.9838</td></tr><tr><td>val_accuracy</td><td>0.62528</td></tr><tr><td>val_f1_macro</td><td>0.61827</td></tr><tr><td>val_f1_weighted</td><td>0.63006</td></tr><tr><td>val_loss</td><td>2.21347</td></tr><tr><td>val_precision_macro</td><td>0.62058</td></tr><tr><td>val_recall_macro</td><td>0.62694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-5</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/6tn4tw6m' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/6tn4tw6m</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250518_144552-6tn4tw6m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8hpq44co with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.318489020208586e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: roberta-base\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpooling: cls\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_last_layers: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'roberta-sweep' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250518_150840-8hpq44co</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/8hpq44co' target=\"_blank\">helpful-sweep-6</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/sweeps/grjxlksx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/8hpq44co' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-sweep/runs/8hpq44co</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6823\n",
      "Train Accuracy: 0.5388\n",
      "Train F1 (macro): 0.5365\n",
      "\n",
      "Val Loss: 0.6458\n",
      "Val Accuracy: 0.6293\n",
      "Val F1 (macro): 0.6262\n",
      "\n",
      "New best model saved (F1: 0.6262, Acc: 0.6293)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6206\n",
      "Train Accuracy: 0.6687\n",
      "Train F1 (macro): 0.6561\n",
      "\n",
      "Val Loss: 0.6303\n",
      "Val Accuracy: 0.6708\n",
      "Val F1 (macro): 0.6603\n",
      "\n",
      "New best model saved (F1: 0.6603, Acc: 0.6708)\n",
      "\n",
      "Epoch 3\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e4053-dd7f-4c1d-bdc8-f60c1e97846b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
