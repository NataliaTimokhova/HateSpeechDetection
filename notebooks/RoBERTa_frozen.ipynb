{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e76a0e7-e90e-457e-8dc4-81cc472f2f1e",
   "metadata": {},
   "source": [
    "The goal of this project is to use the pretrained RoBERTa transformer as a feature extractor with a costum classification head to determine if text messages are offensive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbb6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src/ to path (once, so imports work)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper_functions import AttentionPooling, HateSpeechDataset\n",
    "from helper_functions import train_model, test_model, get_class_distribution, oversample_dataset, undersample_dataset\n",
    "from models import CustomClassifier, LargeCustomClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33448265-13a5-44f5-9ba4-0fb9cc41448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data path: /Project/data/cleaned\n",
      "Processed data path: /Project/data/processed\n"
     ]
    }
   ],
   "source": [
    "from paths import DATA_CLEANED, DATA_PROCESSED\n",
    "print(\"Cleaned data path:\", DATA_CLEANED)\n",
    "print(\"Processed data path:\", DATA_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f24224-26ee-49a1-adf0-48e3e6d38544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040a974",
   "metadata": {},
   "source": [
    "## Using RoBERTa as a feature extractor with a costum classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4da52",
   "metadata": {},
   "source": [
    "Found this pretrained model online: cardiffnlp/twitter-roberta-base-sentiment-latest (https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "It is already pretrained on twitter messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc731c7",
   "metadata": {},
   "source": [
    "Define which pretrained model is used and initilise tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669dc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb86e8",
   "metadata": {},
   "source": [
    "## Load HASOC dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181465c-ef90-409f-9cb4-39f7db6f2e93",
   "metadata": {},
   "source": [
    "Define experiment scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479a3f53-d232-42b2-8dd3-169bce3efd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using the labels of the first task of the HASOC dataset, which is a binary classification\n",
    "label = \"task_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f76fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "clean_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_train_cleaned.tsv\", sep='\\t')\n",
    "# test_df = pd.read_csv(DATA_PROCESSED / \"hasoc_2019_en_test.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_CLEANED / \"hasoc_2019_en_test_cleaned.tsv\", sep='\\t')\n",
    "\n",
    "# Split clean dataset in training and validation set\n",
    "train_df, val_df = train_test_split(clean_df, test_size=0.3, random_state=42, stratify=clean_df[label])\n",
    "\n",
    "# Automatically map string labels to integers\n",
    "label_list = sorted(train_df[label].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "train_df[label] = train_df[label].map(label_map)\n",
    "val_df[label] = val_df[label].map(label_map)\n",
    "test_df[label] = test_df[label].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fb66be-035e-46e1-9e43-5de03957c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which technique to use to cope with data imbalance\n",
    "handling_imbalance = \"class_weighting\"\n",
    "# when choosing 'class_weighting' dataset is not touched but classes gets weighted depending on label/class distribution\n",
    "\n",
    "if handling_imbalance == 'oversampling':\n",
    "    # Oversample dataset\n",
    "    train_df = oversample_dataset(train_df, label)\n",
    "    # val_df = oversample_dataset(val_df, label) # over and undersampling only useful for training dataset\n",
    "    # test_df = oversample_dataset(test_df, label)\n",
    "elif handling_imbalance == 'undersampling':\n",
    "    # Undersample dataset\n",
    "    train_df = undersample_dataset(train_df, label)\n",
    "    # val_df = undersample_dataset(val_df, label)\n",
    "    # test_df = undersample_dataset(test_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae20628-d358-4fe0-95fd-fb79e925436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2513, 0: 1583}\n"
     ]
    }
   ],
   "source": [
    "# Create PyTorch Datasets and DataLoaders\n",
    "train_dataset = HateSpeechDataset(train_df, tokenizer, label=label)\n",
    "val_dataset = HateSpeechDataset(val_df, tokenizer, label=label)\n",
    "test_dataset = HateSpeechDataset(test_df, tokenizer, label=label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "print(get_class_distribution(train_df, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197592e6-249f-4274-97a2-ca3625e089f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_df[label]),\n",
    "    y=train_df[label]\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd402e6",
   "metadata": {},
   "source": [
    "## Training and evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456ec3ec-d7e1-47ad-a9f1-57dac6011ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 20:41:44.859010: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-14 20:41:44.874597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747248104.896962   64354 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747248104.902963   64354 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747248104.917859   64354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747248104.917874   64354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747248104.917876   64354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747248104.917877   64354 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-14 20:41:44.924137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Decide what pooling to use (cls, mean or attention_pooling)\n",
    "pooling = \"mean\"\n",
    "\n",
    "# Initialize model\n",
    "model = LargeCustomClassifier(model_name, class_weights_tensor, device, pooling=pooling).to(device)\n",
    "\n",
    "\n",
    "# Set learning rate\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Optimizer only for the classification head\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=learning_rate)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5445349-d36a-4138-bc0f-f2dd004fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatalia-timokhova-v\u001b[0m (\u001b[33mnatalia-timokhova-v-lule-university-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Project/notebooks/wandb/run-20250514_204148-mbzjss4h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mbzjss4h' target=\"_blank\">playful-wildflower-40</a></strong> to <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mbzjss4h' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mbzjss4h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mbzjss4h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2415d13990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"roberta-classifier\", config={\n",
    "    \"model\": model_name,\n",
    "    \"frozen_base\": True,\n",
    "    \"pooling\": pooling,\n",
    "    \"classifier_head\": model.__class__.__name__,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": learning_rate,\n",
    "    \"handling_imbalance\": handling_imbalance\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781a9824-c9d1-44a9-ae3a-70399e220e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training Loss: 0.6780\n",
      "Train Accuracy: 0.5862\n",
      "Train F1 (macro): 0.5632\n",
      "\n",
      "Val Loss: 0.6640\n",
      "Val Accuracy: 0.5438\n",
      "Val F1 (macro): 0.5404\n",
      "\n",
      "New best model saved (F1: 0.5404, Acc: 0.5438)\n",
      "\n",
      "Epoch 2\n",
      "Training Loss: 0.6452\n",
      "Train Accuracy: 0.6262\n",
      "Train F1 (macro): 0.6158\n",
      "\n",
      "Val Loss: 0.6384\n",
      "Val Accuracy: 0.6304\n",
      "Val F1 (macro): 0.6256\n",
      "\n",
      "New best model saved (F1: 0.6256, Acc: 0.6304)\n",
      "\n",
      "Epoch 3\n",
      "Training Loss: 0.6287\n",
      "Train Accuracy: 0.6472\n",
      "Train F1 (macro): 0.6357\n",
      "\n",
      "Val Loss: 0.6387\n",
      "Val Accuracy: 0.6036\n",
      "Val F1 (macro): 0.6036\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Training Loss: 0.6179\n",
      "Train Accuracy: 0.6638\n",
      "Train F1 (macro): 0.6532\n",
      "\n",
      "Val Loss: 0.6269\n",
      "Val Accuracy: 0.6674\n",
      "Val F1 (macro): 0.6577\n",
      "\n",
      "New best model saved (F1: 0.6577, Acc: 0.6674)\n",
      "\n",
      "Epoch 5\n",
      "Training Loss: 0.6136\n",
      "Train Accuracy: 0.6660\n",
      "Train F1 (macro): 0.6546\n",
      "\n",
      "Val Loss: 0.6316\n",
      "Val Accuracy: 0.6202\n",
      "Val F1 (macro): 0.6190\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.6120\n",
      "Train Accuracy: 0.6611\n",
      "Train F1 (macro): 0.6509\n",
      "\n",
      "Val Loss: 0.6308\n",
      "Val Accuracy: 0.6760\n",
      "Val F1 (macro): 0.6431\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Training Loss: 0.6051\n",
      "Train Accuracy: 0.6697\n",
      "Train F1 (macro): 0.6579\n",
      "\n",
      "Val Loss: 0.6304\n",
      "Val Accuracy: 0.6196\n",
      "Val F1 (macro): 0.6188\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Training Loss: 0.5978\n",
      "Train Accuracy: 0.6760\n",
      "Train F1 (macro): 0.6655\n",
      "\n",
      "Val Loss: 0.6235\n",
      "Val Accuracy: 0.6526\n",
      "Val F1 (macro): 0.6476\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Training Loss: 0.5966\n",
      "Train Accuracy: 0.6726\n",
      "Train F1 (macro): 0.6628\n",
      "\n",
      "Val Loss: 0.6276\n",
      "Val Accuracy: 0.6680\n",
      "Val F1 (macro): 0.6436\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training Loss: 0.5985\n",
      "Train Accuracy: 0.6736\n",
      "Train F1 (macro): 0.6615\n",
      "\n",
      "Val Loss: 0.6230\n",
      "Val Accuracy: 0.6669\n",
      "Val F1 (macro): 0.6553\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.5915\n",
      "Train Accuracy: 0.6826\n",
      "Train F1 (macro): 0.6720\n",
      "\n",
      "Val Loss: 0.6272\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6259\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Training Loss: 0.5842\n",
      "Train Accuracy: 0.6785\n",
      "Train F1 (macro): 0.6687\n",
      "\n",
      "Val Loss: 0.6408\n",
      "Val Accuracy: 0.5957\n",
      "Val F1 (macro): 0.5956\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Training Loss: 0.5845\n",
      "Train Accuracy: 0.6802\n",
      "Train F1 (macro): 0.6691\n",
      "\n",
      "Val Loss: 0.6244\n",
      "Val Accuracy: 0.6566\n",
      "Val F1 (macro): 0.6465\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Training Loss: 0.5811\n",
      "Train Accuracy: 0.6929\n",
      "Train F1 (macro): 0.6822\n",
      "\n",
      "Val Loss: 0.6241\n",
      "Val Accuracy: 0.6543\n",
      "Val F1 (macro): 0.6427\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Training Loss: 0.5738\n",
      "Train Accuracy: 0.6985\n",
      "Train F1 (macro): 0.6885\n",
      "\n",
      "Val Loss: 0.6262\n",
      "Val Accuracy: 0.6572\n",
      "Val F1 (macro): 0.6451\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.5694\n",
      "Train Accuracy: 0.7078\n",
      "Train F1 (macro): 0.6970\n",
      "\n",
      "Val Loss: 0.6399\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6280\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Training Loss: 0.5617\n",
      "Train Accuracy: 0.7056\n",
      "Train F1 (macro): 0.6962\n",
      "\n",
      "Val Loss: 0.6344\n",
      "Val Accuracy: 0.6543\n",
      "Val F1 (macro): 0.6443\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Training Loss: 0.5594\n",
      "Train Accuracy: 0.7075\n",
      "Train F1 (macro): 0.6991\n",
      "\n",
      "Val Loss: 0.6316\n",
      "Val Accuracy: 0.6532\n",
      "Val F1 (macro): 0.6357\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Training Loss: 0.5615\n",
      "Train Accuracy: 0.7065\n",
      "Train F1 (macro): 0.6966\n",
      "\n",
      "Val Loss: 0.6399\n",
      "Val Accuracy: 0.6669\n",
      "Val F1 (macro): 0.6495\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Training Loss: 0.5496\n",
      "Train Accuracy: 0.7190\n",
      "Train F1 (macro): 0.7087\n",
      "\n",
      "Val Loss: 0.6365\n",
      "Val Accuracy: 0.6213\n",
      "Val F1 (macro): 0.6168\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.5418\n",
      "Train Accuracy: 0.7229\n",
      "Train F1 (macro): 0.7146\n",
      "\n",
      "Val Loss: 0.6378\n",
      "Val Accuracy: 0.6264\n",
      "Val F1 (macro): 0.6200\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Training Loss: 0.5399\n",
      "Train Accuracy: 0.7241\n",
      "Train F1 (macro): 0.7150\n",
      "\n",
      "Val Loss: 0.6393\n",
      "Val Accuracy: 0.6333\n",
      "Val F1 (macro): 0.6237\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Training Loss: 0.5279\n",
      "Train Accuracy: 0.7346\n",
      "Train F1 (macro): 0.7274\n",
      "\n",
      "Val Loss: 0.6462\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6218\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Training Loss: 0.5215\n",
      "Train Accuracy: 0.7349\n",
      "Train F1 (macro): 0.7264\n",
      "\n",
      "Val Loss: 0.6441\n",
      "Val Accuracy: 0.6344\n",
      "Val F1 (macro): 0.6276\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Training Loss: 0.5215\n",
      "Train Accuracy: 0.7412\n",
      "Train F1 (macro): 0.7331\n",
      "\n",
      "Val Loss: 0.6467\n",
      "Val Accuracy: 0.6190\n",
      "Val F1 (macro): 0.6166\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.5116\n",
      "Train Accuracy: 0.7507\n",
      "Train F1 (macro): 0.7425\n",
      "\n",
      "Val Loss: 0.6567\n",
      "Val Accuracy: 0.6167\n",
      "Val F1 (macro): 0.6139\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Training Loss: 0.5037\n",
      "Train Accuracy: 0.7424\n",
      "Train F1 (macro): 0.7362\n",
      "\n",
      "Val Loss: 0.6546\n",
      "Val Accuracy: 0.6224\n",
      "Val F1 (macro): 0.6183\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Training Loss: 0.4949\n",
      "Train Accuracy: 0.7576\n",
      "Train F1 (macro): 0.7503\n",
      "\n",
      "Val Loss: 0.6720\n",
      "Val Accuracy: 0.6464\n",
      "Val F1 (macro): 0.6241\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Training Loss: 0.4837\n",
      "Train Accuracy: 0.7649\n",
      "Train F1 (macro): 0.7575\n",
      "\n",
      "Val Loss: 0.6813\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6241\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Training Loss: 0.4874\n",
      "Train Accuracy: 0.7612\n",
      "Train F1 (macro): 0.7541\n",
      "\n",
      "Val Loss: 0.6638\n",
      "Val Accuracy: 0.6213\n",
      "Val F1 (macro): 0.6162\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.4743\n",
      "Train Accuracy: 0.7690\n",
      "Train F1 (macro): 0.7621\n",
      "\n",
      "Val Loss: 0.6865\n",
      "Val Accuracy: 0.6395\n",
      "Val F1 (macro): 0.6219\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Training Loss: 0.4558\n",
      "Train Accuracy: 0.7834\n",
      "Train F1 (macro): 0.7764\n",
      "\n",
      "Val Loss: 0.7040\n",
      "Val Accuracy: 0.6167\n",
      "Val F1 (macro): 0.6145\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Training Loss: 0.4597\n",
      "Train Accuracy: 0.7837\n",
      "Train F1 (macro): 0.7766\n",
      "\n",
      "Val Loss: 0.6982\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6206\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Training Loss: 0.4454\n",
      "Train Accuracy: 0.7874\n",
      "Train F1 (macro): 0.7815\n",
      "\n",
      "Val Loss: 0.7495\n",
      "Val Accuracy: 0.6515\n",
      "Val F1 (macro): 0.6183\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Training Loss: 0.4413\n",
      "Train Accuracy: 0.7932\n",
      "Train F1 (macro): 0.7866\n",
      "\n",
      "Val Loss: 0.6980\n",
      "Val Accuracy: 0.6270\n",
      "Val F1 (macro): 0.6196\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.4228\n",
      "Train Accuracy: 0.7988\n",
      "Train F1 (macro): 0.7930\n",
      "\n",
      "Val Loss: 0.7179\n",
      "Val Accuracy: 0.6065\n",
      "Val F1 (macro): 0.6042\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Training Loss: 0.4284\n",
      "Train Accuracy: 0.7986\n",
      "Train F1 (macro): 0.7922\n",
      "\n",
      "Val Loss: 0.7129\n",
      "Val Accuracy: 0.5962\n",
      "Val F1 (macro): 0.5952\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Training Loss: 0.4157\n",
      "Train Accuracy: 0.8076\n",
      "Train F1 (macro): 0.8014\n",
      "\n",
      "Val Loss: 0.7475\n",
      "Val Accuracy: 0.6321\n",
      "Val F1 (macro): 0.6195\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Training Loss: 0.4043\n",
      "Train Accuracy: 0.8132\n",
      "Train F1 (macro): 0.8078\n",
      "\n",
      "Val Loss: 0.7527\n",
      "Val Accuracy: 0.6384\n",
      "Val F1 (macro): 0.6239\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Training Loss: 0.3982\n",
      "Train Accuracy: 0.8191\n",
      "Train F1 (macro): 0.8131\n",
      "\n",
      "Val Loss: 0.7779\n",
      "Val Accuracy: 0.6401\n",
      "Val F1 (macro): 0.6237\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.3860\n",
      "Train Accuracy: 0.8218\n",
      "Train F1 (macro): 0.8158\n",
      "\n",
      "Val Loss: 0.7679\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6303\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Training Loss: 0.3892\n",
      "Train Accuracy: 0.8230\n",
      "Train F1 (macro): 0.8176\n",
      "\n",
      "Val Loss: 0.7698\n",
      "Val Accuracy: 0.6099\n",
      "Val F1 (macro): 0.6077\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Training Loss: 0.3790\n",
      "Train Accuracy: 0.8359\n",
      "Train F1 (macro): 0.8302\n",
      "\n",
      "Val Loss: 0.7866\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6200\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Training Loss: 0.3713\n",
      "Train Accuracy: 0.8298\n",
      "Train F1 (macro): 0.8241\n",
      "\n",
      "Val Loss: 0.8010\n",
      "Val Accuracy: 0.6657\n",
      "Val F1 (macro): 0.6391\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Training Loss: 0.3673\n",
      "Train Accuracy: 0.8345\n",
      "Train F1 (macro): 0.8287\n",
      "\n",
      "Val Loss: 0.8154\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6232\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.3544\n",
      "Train Accuracy: 0.8455\n",
      "Train F1 (macro): 0.8401\n",
      "\n",
      "Val Loss: 0.8437\n",
      "Val Accuracy: 0.6509\n",
      "Val F1 (macro): 0.6292\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Training Loss: 0.3449\n",
      "Train Accuracy: 0.8411\n",
      "Train F1 (macro): 0.8355\n",
      "\n",
      "Val Loss: 0.8104\n",
      "Val Accuracy: 0.6128\n",
      "Val F1 (macro): 0.6106\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Training Loss: 0.3416\n",
      "Train Accuracy: 0.8472\n",
      "Train F1 (macro): 0.8418\n",
      "\n",
      "Val Loss: 0.8390\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6268\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Training Loss: 0.3304\n",
      "Train Accuracy: 0.8577\n",
      "Train F1 (macro): 0.8527\n",
      "\n",
      "Val Loss: 0.8461\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6270\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.3221\n",
      "Train Accuracy: 0.8621\n",
      "Train F1 (macro): 0.8568\n",
      "\n",
      "Val Loss: 0.8652\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6251\n",
      "\n",
      "\n",
      "Epoch 51\n",
      "Training Loss: 0.3077\n",
      "Train Accuracy: 0.8689\n",
      "Train F1 (macro): 0.8640\n",
      "\n",
      "Val Loss: 0.8822\n",
      "Val Accuracy: 0.5974\n",
      "Val F1 (macro): 0.5948\n",
      "\n",
      "\n",
      "Epoch 52\n",
      "Training Loss: 0.3148\n",
      "Train Accuracy: 0.8616\n",
      "Train F1 (macro): 0.8569\n",
      "\n",
      "Val Loss: 0.8807\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6152\n",
      "\n",
      "\n",
      "Epoch 53\n",
      "Training Loss: 0.3043\n",
      "Train Accuracy: 0.8743\n",
      "Train F1 (macro): 0.8696\n",
      "\n",
      "Val Loss: 0.8854\n",
      "Val Accuracy: 0.6315\n",
      "Val F1 (macro): 0.6185\n",
      "\n",
      "\n",
      "Epoch 54\n",
      "Training Loss: 0.2957\n",
      "Train Accuracy: 0.8694\n",
      "Train F1 (macro): 0.8649\n",
      "\n",
      "Val Loss: 0.8634\n",
      "Val Accuracy: 0.6407\n",
      "Val F1 (macro): 0.6296\n",
      "\n",
      "\n",
      "Epoch 55\n",
      "Training Loss: 0.2878\n",
      "Train Accuracy: 0.8735\n",
      "Train F1 (macro): 0.8685\n",
      "\n",
      "Val Loss: 0.9465\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6209\n",
      "\n",
      "\n",
      "Epoch 56\n",
      "Training Loss: 0.2846\n",
      "Train Accuracy: 0.8809\n",
      "Train F1 (macro): 0.8761\n",
      "\n",
      "Val Loss: 0.9079\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6307\n",
      "\n",
      "\n",
      "Epoch 57\n",
      "Training Loss: 0.2745\n",
      "Train Accuracy: 0.8828\n",
      "Train F1 (macro): 0.8783\n",
      "\n",
      "Val Loss: 0.9427\n",
      "Val Accuracy: 0.6236\n",
      "Val F1 (macro): 0.6156\n",
      "\n",
      "\n",
      "Epoch 58\n",
      "Training Loss: 0.2751\n",
      "Train Accuracy: 0.8821\n",
      "Train F1 (macro): 0.8777\n",
      "\n",
      "Val Loss: 0.9480\n",
      "Val Accuracy: 0.6469\n",
      "Val F1 (macro): 0.6330\n",
      "\n",
      "\n",
      "Epoch 59\n",
      "Training Loss: 0.2642\n",
      "Train Accuracy: 0.8872\n",
      "Train F1 (macro): 0.8829\n",
      "\n",
      "Val Loss: 0.9822\n",
      "Val Accuracy: 0.6350\n",
      "Val F1 (macro): 0.6230\n",
      "\n",
      "\n",
      "Epoch 60\n",
      "Training Loss: 0.2678\n",
      "Train Accuracy: 0.8879\n",
      "Train F1 (macro): 0.8834\n",
      "\n",
      "Val Loss: 0.9847\n",
      "Val Accuracy: 0.6492\n",
      "Val F1 (macro): 0.6335\n",
      "\n",
      "\n",
      "Epoch 61\n",
      "Training Loss: 0.2554\n",
      "Train Accuracy: 0.8943\n",
      "Train F1 (macro): 0.8901\n",
      "\n",
      "Val Loss: 0.9872\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6205\n",
      "\n",
      "\n",
      "Epoch 62\n",
      "Training Loss: 0.2561\n",
      "Train Accuracy: 0.8887\n",
      "Train F1 (macro): 0.8845\n",
      "\n",
      "Val Loss: 0.9708\n",
      "Val Accuracy: 0.6395\n",
      "Val F1 (macro): 0.6266\n",
      "\n",
      "\n",
      "Epoch 63\n",
      "Training Loss: 0.2509\n",
      "Train Accuracy: 0.8972\n",
      "Train F1 (macro): 0.8931\n",
      "\n",
      "Val Loss: 1.0512\n",
      "Val Accuracy: 0.6555\n",
      "Val F1 (macro): 0.6230\n",
      "\n",
      "\n",
      "Epoch 64\n",
      "Training Loss: 0.2377\n",
      "Train Accuracy: 0.9011\n",
      "Train F1 (macro): 0.8968\n",
      "\n",
      "Val Loss: 0.9704\n",
      "Val Accuracy: 0.6048\n",
      "Val F1 (macro): 0.6029\n",
      "\n",
      "\n",
      "Epoch 65\n",
      "Training Loss: 0.2410\n",
      "Train Accuracy: 0.9014\n",
      "Train F1 (macro): 0.8975\n",
      "\n",
      "Val Loss: 0.9911\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6249\n",
      "\n",
      "\n",
      "Epoch 66\n",
      "Training Loss: 0.2412\n",
      "Train Accuracy: 0.9006\n",
      "Train F1 (macro): 0.8965\n",
      "\n",
      "Val Loss: 0.9902\n",
      "Val Accuracy: 0.6418\n",
      "Val F1 (macro): 0.6260\n",
      "\n",
      "\n",
      "Epoch 67\n",
      "Training Loss: 0.2336\n",
      "Train Accuracy: 0.9028\n",
      "Train F1 (macro): 0.8990\n",
      "\n",
      "Val Loss: 1.0662\n",
      "Val Accuracy: 0.6424\n",
      "Val F1 (macro): 0.6202\n",
      "\n",
      "\n",
      "Epoch 68\n",
      "Training Loss: 0.2104\n",
      "Train Accuracy: 0.9150\n",
      "Train F1 (macro): 0.9113\n",
      "\n",
      "Val Loss: 1.0322\n",
      "Val Accuracy: 0.6088\n",
      "Val F1 (macro): 0.6033\n",
      "\n",
      "\n",
      "Epoch 69\n",
      "Training Loss: 0.2375\n",
      "Train Accuracy: 0.8989\n",
      "Train F1 (macro): 0.8949\n",
      "\n",
      "Val Loss: 1.0816\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6126\n",
      "\n",
      "\n",
      "Epoch 70\n",
      "Training Loss: 0.2144\n",
      "Train Accuracy: 0.9087\n",
      "Train F1 (macro): 0.9048\n",
      "\n",
      "Val Loss: 1.0991\n",
      "Val Accuracy: 0.6384\n",
      "Val F1 (macro): 0.6172\n",
      "\n",
      "\n",
      "Epoch 71\n",
      "Training Loss: 0.2204\n",
      "Train Accuracy: 0.9094\n",
      "Train F1 (macro): 0.9055\n",
      "\n",
      "Val Loss: 1.0566\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6153\n",
      "\n",
      "\n",
      "Epoch 72\n",
      "Training Loss: 0.2246\n",
      "Train Accuracy: 0.9094\n",
      "Train F1 (macro): 0.9057\n",
      "\n",
      "Val Loss: 1.1059\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6160\n",
      "\n",
      "\n",
      "Epoch 73\n",
      "Training Loss: 0.2169\n",
      "Train Accuracy: 0.9124\n",
      "Train F1 (macro): 0.9085\n",
      "\n",
      "Val Loss: 1.0493\n",
      "Val Accuracy: 0.6304\n",
      "Val F1 (macro): 0.6242\n",
      "\n",
      "\n",
      "Epoch 74\n",
      "Training Loss: 0.2110\n",
      "Train Accuracy: 0.9102\n",
      "Train F1 (macro): 0.9064\n",
      "\n",
      "Val Loss: 1.0960\n",
      "Val Accuracy: 0.6429\n",
      "Val F1 (macro): 0.6222\n",
      "\n",
      "\n",
      "Epoch 75\n",
      "Training Loss: 0.2085\n",
      "Train Accuracy: 0.9153\n",
      "Train F1 (macro): 0.9115\n",
      "\n",
      "Val Loss: 1.0824\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6119\n",
      "\n",
      "\n",
      "Epoch 76\n",
      "Training Loss: 0.2053\n",
      "Train Accuracy: 0.9097\n",
      "Train F1 (macro): 0.9057\n",
      "\n",
      "Val Loss: 1.0809\n",
      "Val Accuracy: 0.6213\n",
      "Val F1 (macro): 0.6133\n",
      "\n",
      "\n",
      "Epoch 77\n",
      "Training Loss: 0.1996\n",
      "Train Accuracy: 0.9194\n",
      "Train F1 (macro): 0.9160\n",
      "\n",
      "Val Loss: 1.1682\n",
      "Val Accuracy: 0.6481\n",
      "Val F1 (macro): 0.6183\n",
      "\n",
      "\n",
      "Epoch 78\n",
      "Training Loss: 0.1881\n",
      "Train Accuracy: 0.9246\n",
      "Train F1 (macro): 0.9212\n",
      "\n",
      "Val Loss: 1.1791\n",
      "Val Accuracy: 0.6276\n",
      "Val F1 (macro): 0.6165\n",
      "\n",
      "\n",
      "Epoch 79\n",
      "Training Loss: 0.1992\n",
      "Train Accuracy: 0.9133\n",
      "Train F1 (macro): 0.9096\n",
      "\n",
      "Val Loss: 1.1151\n",
      "Val Accuracy: 0.6338\n",
      "Val F1 (macro): 0.6165\n",
      "\n",
      "\n",
      "Epoch 80\n",
      "Training Loss: 0.1933\n",
      "Train Accuracy: 0.9224\n",
      "Train F1 (macro): 0.9188\n",
      "\n",
      "Val Loss: 1.1861\n",
      "Val Accuracy: 0.6407\n",
      "Val F1 (macro): 0.6207\n",
      "\n",
      "\n",
      "Epoch 81\n",
      "Training Loss: 0.1976\n",
      "Train Accuracy: 0.9150\n",
      "Train F1 (macro): 0.9114\n",
      "\n",
      "Val Loss: 1.1892\n",
      "Val Accuracy: 0.6327\n",
      "Val F1 (macro): 0.6070\n",
      "\n",
      "\n",
      "Epoch 82\n",
      "Training Loss: 0.1950\n",
      "Train Accuracy: 0.9226\n",
      "Train F1 (macro): 0.9192\n",
      "\n",
      "Val Loss: 1.1593\n",
      "Val Accuracy: 0.6407\n",
      "Val F1 (macro): 0.6219\n",
      "\n",
      "\n",
      "Epoch 83\n",
      "Training Loss: 0.1879\n",
      "Train Accuracy: 0.9287\n",
      "Train F1 (macro): 0.9255\n",
      "\n",
      "Val Loss: 1.1657\n",
      "Val Accuracy: 0.6378\n",
      "Val F1 (macro): 0.6257\n",
      "\n",
      "\n",
      "Epoch 84\n",
      "Training Loss: 0.1794\n",
      "Train Accuracy: 0.9253\n",
      "Train F1 (macro): 0.9219\n",
      "\n",
      "Val Loss: 1.1551\n",
      "Val Accuracy: 0.6367\n",
      "Val F1 (macro): 0.6192\n",
      "\n",
      "\n",
      "Epoch 85\n",
      "Training Loss: 0.1820\n",
      "Train Accuracy: 0.9241\n",
      "Train F1 (macro): 0.9210\n",
      "\n",
      "Val Loss: 1.1813\n",
      "Val Accuracy: 0.6390\n",
      "Val F1 (macro): 0.6208\n",
      "\n",
      "\n",
      "Epoch 86\n",
      "Training Loss: 0.1823\n",
      "Train Accuracy: 0.9260\n",
      "Train F1 (macro): 0.9229\n",
      "\n",
      "Val Loss: 1.2386\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6112\n",
      "\n",
      "\n",
      "Epoch 87\n",
      "Training Loss: 0.1780\n",
      "Train Accuracy: 0.9294\n",
      "Train F1 (macro): 0.9263\n",
      "\n",
      "Val Loss: 1.1601\n",
      "Val Accuracy: 0.6293\n",
      "Val F1 (macro): 0.6202\n",
      "\n",
      "\n",
      "Epoch 88\n",
      "Training Loss: 0.1804\n",
      "Train Accuracy: 0.9263\n",
      "Train F1 (macro): 0.9229\n",
      "\n",
      "Val Loss: 1.2145\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6175\n",
      "\n",
      "\n",
      "Epoch 89\n",
      "Training Loss: 0.1832\n",
      "Train Accuracy: 0.9255\n",
      "Train F1 (macro): 0.9223\n",
      "\n",
      "Val Loss: 1.1615\n",
      "Val Accuracy: 0.6310\n",
      "Val F1 (macro): 0.6202\n",
      "\n",
      "\n",
      "Epoch 90\n",
      "Training Loss: 0.1770\n",
      "Train Accuracy: 0.9270\n",
      "Train F1 (macro): 0.9236\n",
      "\n",
      "Val Loss: 1.2622\n",
      "Val Accuracy: 0.6287\n",
      "Val F1 (macro): 0.6103\n",
      "\n",
      "\n",
      "Epoch 91\n",
      "Training Loss: 0.1722\n",
      "Train Accuracy: 0.9329\n",
      "Train F1 (macro): 0.9299\n",
      "\n",
      "Val Loss: 1.3113\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6174\n",
      "\n",
      "\n",
      "Epoch 92\n",
      "Training Loss: 0.1747\n",
      "Train Accuracy: 0.9277\n",
      "Train F1 (macro): 0.9244\n",
      "\n",
      "Val Loss: 1.2308\n",
      "Val Accuracy: 0.6412\n",
      "Val F1 (macro): 0.6163\n",
      "\n",
      "\n",
      "Epoch 93\n",
      "Training Loss: 0.1691\n",
      "Train Accuracy: 0.9299\n",
      "Train F1 (macro): 0.9268\n",
      "\n",
      "Val Loss: 1.2053\n",
      "Val Accuracy: 0.6196\n",
      "Val F1 (macro): 0.6077\n",
      "\n",
      "\n",
      "Epoch 94\n",
      "Training Loss: 0.1660\n",
      "Train Accuracy: 0.9333\n",
      "Train F1 (macro): 0.9304\n",
      "\n",
      "Val Loss: 1.2501\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6191\n",
      "\n",
      "\n",
      "Epoch 95\n",
      "Training Loss: 0.1720\n",
      "Train Accuracy: 0.9321\n",
      "Train F1 (macro): 0.9290\n",
      "\n",
      "Val Loss: 1.2437\n",
      "Val Accuracy: 0.6372\n",
      "Val F1 (macro): 0.6183\n",
      "\n",
      "\n",
      "Epoch 96\n",
      "Training Loss: 0.1679\n",
      "Train Accuracy: 0.9324\n",
      "Train F1 (macro): 0.9294\n",
      "\n",
      "Val Loss: 1.2047\n",
      "Val Accuracy: 0.6361\n",
      "Val F1 (macro): 0.6238\n",
      "\n",
      "\n",
      "Epoch 97\n",
      "Training Loss: 0.1660\n",
      "Train Accuracy: 0.9375\n",
      "Train F1 (macro): 0.9346\n",
      "\n",
      "Val Loss: 1.2768\n",
      "Val Accuracy: 0.6219\n",
      "Val F1 (macro): 0.6166\n",
      "\n",
      "\n",
      "Epoch 98\n",
      "Training Loss: 0.1574\n",
      "Train Accuracy: 0.9419\n",
      "Train F1 (macro): 0.9392\n",
      "\n",
      "Val Loss: 1.2538\n",
      "Val Accuracy: 0.6281\n",
      "Val F1 (macro): 0.6197\n",
      "\n",
      "\n",
      "Epoch 99\n",
      "Training Loss: 0.1709\n",
      "Train Accuracy: 0.9353\n",
      "Train F1 (macro): 0.9323\n",
      "\n",
      "Val Loss: 1.3037\n",
      "Val Accuracy: 0.6481\n",
      "Val F1 (macro): 0.6240\n",
      "\n",
      "\n",
      "Epoch 100\n",
      "Training Loss: 0.1564\n",
      "Train Accuracy: 0.9380\n",
      "Train F1 (macro): 0.9352\n",
      "\n",
      "Val Loss: 1.3022\n",
      "Val Accuracy: 0.6355\n",
      "Val F1 (macro): 0.6156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, optimizer, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b4b0a",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c821845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5469\n",
      "Test Accuracy: 0.7728\n",
      "Test F1 (macro): 0.7304\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>test_f1_weighted</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_precision_macro</td><td>▁</td></tr><tr><td>test_recall_macro</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_f1_macro</td><td>▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_f1_weighted</td><td>▁▂▂▂▂▂▃▃▃▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>█████▇▇▇▇▇▆▆▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train_precision_macro</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇█▇▇█▇█▇████████</td></tr><tr><td>train_recall_macro</td><td>▁▁▁▂▂▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>val_accuracy</td><td>▄▂█▃▇▇▃▅▅▄▁▅▅▅▆▃▆▆▅▅▅▇▂▅▅▄▅▅▄▄▅▄▄▄▄▅▃▅▄▅</td></tr><tr><td>val_f1_macro</td><td>▁▃▇▃██▇▇█▃▄▃▃▄▃▂▄▆▅▂▅▄▅▅▄▄▂▃▄▄▃▃▃▄▃▂▃▄▃▄</td></tr><tr><td>val_f1_weighted</td><td>▄▃█▇▄▇▇▃▄▂▅▅▃▅▂▄▁▂▅▅▄▅▄▆▅▁▄▅▂▄▄▅▄▅▄▄▃▅▄▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▅▆▇▇▇▇▇█▇▇▇██</td></tr><tr><td>val_precision_macro</td><td>█▅▅█▆▇▃▄▄▃▄▃▄▄▂▃▃▆▃▄▄▄▄▁▃▂▁▃▂▃▂▂▃▁▃▃▂▃▃▃</td></tr><tr><td>val_recall_macro</td><td>▅▄█▅██▆▄▅▄▅▄▄▃▄▂▃▄▄▂▃▅▃▅▄▃▂▂▂▂▃▃▁▃▃▂▂▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>test_accuracy</td><td>0.77277</td></tr><tr><td>test_f1_macro</td><td>0.73042</td></tr><tr><td>test_f1_weighted</td><td>0.78389</td></tr><tr><td>test_loss</td><td>0.54688</td></tr><tr><td>test_precision_macro</td><td>0.71828</td></tr><tr><td>test_recall_macro</td><td>0.76633</td></tr><tr><td>train_accuracy</td><td>0.93799</td></tr><tr><td>train_f1_macro</td><td>0.93524</td></tr><tr><td>train_f1_weighted</td><td>0.93827</td></tr><tr><td>train_loss</td><td>0.15645</td></tr><tr><td>train_precision_macro</td><td>0.93177</td></tr><tr><td>train_recall_macro</td><td>0.93964</td></tr><tr><td>val_accuracy</td><td>0.63554</td></tr><tr><td>val_f1_macro</td><td>0.61559</td></tr><tr><td>val_f1_weighted</td><td>0.63554</td></tr><tr><td>val_loss</td><td>1.30217</td></tr><tr><td>val_precision_macro</td><td>0.61559</td></tr><tr><td>val_recall_macro</td><td>0.61559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">playful-wildflower-40</strong> at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mbzjss4h' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier/runs/mbzjss4h</a><br> View project at: <a href='https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier' target=\"_blank\">https://wandb.ai/natalia-timokhova-v-lule-university-of-technology/roberta-classifier</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250514_204148-mbzjss4h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7304151495680731, 'accuracy': 0.7727666955767563}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_model.pt\", weights_only=True))\n",
    "# Test model on test set\n",
    "test_model(model, test_loader, device, phase = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1a15d-c616-4a6d-bf68-c39a2c924782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
